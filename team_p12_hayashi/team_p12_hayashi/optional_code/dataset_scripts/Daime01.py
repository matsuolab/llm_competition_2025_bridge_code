#　-*- coding: utf-8 -*-
import sys
import os
import re
import struct
import binascii
import numpy as np
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# # -------------------------------------------------------
# # -------------------------------------------------------
# import pyarrow as pa
# import pyarrow.parquet as pq
# import pathlib

# # ==== 設定 ====
# # csv_path = "AIME2024_Q.csv"  # 変換するCSVファイル名
# # csv_path = "AIME2024_QwFullH.csv"
# # csv_path = "AIME2024_QwHalfH.csv"
# csv_path = "AIME2024_QwOneH.csv"
# SYSTEM_PROMPT = ""           # 例: "You are a helpful math expert. Show final answer in <answer> tags."
# ADD_THINK_TAGS = True        # Trueなら<think>…</think><answer>…</answer>を付与
# GEN_ID = False               # CSVにID列が無い場合、自動でbasename-連番のidを生成
# # ==============

# # 出力ファイル名
# fname = csv_path[:-4]
# parquet_path = fname + ".parquet"

# # CSV読み込み
# df = pd.read_csv(csv_path)

# # 必須列チェック
# required_columns = {"Question", "Answer"}
# if not required_columns.issubset(df.columns):
#     raise ValueError(f"CSV file must contain the following columns: {required_columns}")

# # 欠損除去
# df = df.dropna(subset=["Question", "Answer"]).reset_index(drop=True)

# # messages列作成
# def build_messages(q: str, a: str):
#     q = str(q).strip()
#     a = str(a).strip()
#     if ADD_THINK_TAGS:
#         a = f"<think></think><answer>{a}</answer>"
#     msgs = []
#     if SYSTEM_PROMPT:
#         msgs.append({"role": "system", "content": SYSTEM_PROMPT})
#     msgs.append({"role": "user", "content": q})
#     msgs.append({"role": "assistant", "content": a})
#     return msgs

# df["messages"] = [build_messages(q, a) for q, a in zip(df["Question"], df["Answer"])]

# # ID列の扱い
# stem = pathlib.Path(csv_path).stem
# if "ID" in df.columns:
#     df = df.rename(columns={"ID": "id"})
# elif GEN_ID:
#     df["id"] = [f"{stem}-{i:06d}" for i in range(len(df))]

# # 保存用データフレーム
# cols = ["messages"]
# if "id" in df.columns:
#     cols = ["id"] + cols
# out_df = df[cols].copy()

# # Parquetに保存
# table = pa.Table.from_pandas(out_df, preserve_index=False)
# pq.write_table(table, parquet_path)

# print(f"Parquet file saved to: {parquet_path}, rows={len(out_df)}")
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq
import pathlib

# ==== 設定 ====
# csv_path = "AIME2024_Q.csv"  # 変換するCSVファイル名
csv_path = "AIME2024_QwFullH_x16.csv"
# csv_path = "AIME2024_QwHalfH_x16.csv"
# csv_path = "AIME2024_QwOneH_x16.csv"
# csv_path = "AIME2025_Q.csv"
SYSTEM_PROMPT = ""
ADD_THINK_TAGS = True   # Trueなら<think>…</think><answer>…</answer>を付与
GEN_ID = False          # CSVにID列が無い場合、自動でbasename-連番のidを生成
# ==============

fname = csv_path[:-4]
parquet_path = fname + ".parquet"

# CSV読み込み
df = pd.read_csv(csv_path)

# 必須列チェック
required_columns = {"Question", "Answer"}
if not required_columns.issubset(df.columns):
    raise ValueError(f"CSV file must contain: {required_columns}")

# 欠損除去
df = df.dropna(subset=["Question", "Answer"]).reset_index(drop=True)

# messages列作成
def build_messages(q: str, a: str, think_text: str = ""):
    q = str(q).strip()
    a = str(a).strip()
    think_text = str(think_text).strip() if think_text else ""

    if ADD_THINK_TAGS:
        if think_text:
            a = f"<think>{think_text}</think><answer>{a}</answer>"
        else:
            a = f"<think></think><answer>{a}</answer>"
    msgs = []
    if SYSTEM_PROMPT:
        msgs.append({"role": "system", "content": SYSTEM_PROMPT})
    msgs.append({"role": "user", "content": q})
    msgs.append({"role": "assistant", "content": a})
    return msgs

# Think列があれば利用
if "Think" in df.columns:
    df["messages"] = [
        build_messages(q, a, t)
        for q, a, t in zip(df["Question"], df["Answer"], df["Think"])
    ]
else:
    df["messages"] = [
        build_messages(q, a)
        for q, a in zip(df["Question"], df["Answer"])
    ]

# ID列処理
stem = pathlib.Path(csv_path).stem
if "ID" in df.columns:
    df = df.rename(columns={"ID": "id"})
elif GEN_ID:
    df["id"] = [f"{stem}-{i:06d}" for i in range(len(df))]

# 保存用データフレーム
cols = ["messages"]
if "id" in df.columns:
    cols = ["id"] + cols
out_df = df[cols].copy()

# Parquet保存
table = pa.Table.from_pandas(out_df, preserve_index=False)
pq.write_table(table, parquet_path)

print(f"Parquet file saved to: {parquet_path}, rows={len(out_df)}")
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------
# # -------------------------------------------------------

