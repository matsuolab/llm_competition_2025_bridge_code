vllm:
  tensor_parallel_size: 1
  max_model_len: 4096
  gpu_memory_utilization: 0.9
  dtype: auto
  quantization: fp8
  trust_remote_code: false
  enable_chunked_prefill: false
  batch_size: 16384
  max_num_batched_tokens: 32768
models:
- Qwen/Qwen3-30B-A3B-FP8
datasets:
  default_mappings:
    question_field: question
    answer_field: answer
  dataset_specific: {}
  repositories:
  - LLMcompe-Team-Watanabe/Bhawna_ChroniclingAmericaQA_preprocess
  - LLMcompe-Team-Watanabe/agriculture-qa-english-only_preprocess
  - LLMcompe-Team-Watanabe/exLong-dataset_preprocess
output:
  base_dir: ./results/engineer
  format: json
  include_metadata: true
  save_raw_responses: true
  save_per_dataset: true
evaluation:
  max_questions: null
logging:
  level: INFO
  format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
dataset_repositories: []
