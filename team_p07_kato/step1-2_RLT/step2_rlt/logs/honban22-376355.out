no change     /home/appli/miniconda3/24.7.1-py311/condabin/conda
no change     /home/appli/miniconda3/24.7.1-py311/bin/conda
no change     /home/appli/miniconda3/24.7.1-py311/bin/conda-env
no change     /home/appli/miniconda3/24.7.1-py311/bin/activate
no change     /home/appli/miniconda3/24.7.1-py311/bin/deactivate
no change     /home/appli/miniconda3/24.7.1-py311/etc/profile.d/conda.sh
no change     /home/appli/miniconda3/24.7.1-py311/etc/fish/conf.d/conda.fish
no change     /home/appli/miniconda3/24.7.1-py311/shell/condabin/Conda.psm1
no change     /home/appli/miniconda3/24.7.1-py311/shell/condabin/conda-hook.ps1
no change     /home/appli/miniconda3/24.7.1-py311/lib/python3.11/site-packages/xontrib/conda.xsh
no change     /home/appli/miniconda3/24.7.1-py311/etc/profile.d/conda.csh
no change     /home/Competition2025/P07/P07U001/.bashrc
No action taken.
============================
vllm_host: osk-gpu70
num_vllm_clients: 8
deepspeed: deepspeed_zero3.yaml
============================
============================
vllm_server * 8 OK
============================
[2025-08-18 21:11:11,335] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0818 21:11:17.225000 3236078 site-packages/torch/distributed/run.py:792] 
W0818 21:11:17.225000 3236078 site-packages/torch/distributed/run.py:792] *****************************************
W0818 21:11:17.225000 3236078 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0818 21:11:17.225000 3236078 site-packages/torch/distributed/run.py:792] *****************************************
[2025-08-18 21:11:29,102] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-18 21:11:29,645] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-18 21:11:29,699] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-18 21:11:29,944] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-18 21:11:29,948] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-18 21:11:29,979] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-18 21:11:29,994] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-18 21:11:30,156] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-18 21:11:46,985][__main__][INFO] - Configuration:
save_final_model: true
save_strategy: steps
save_steps: 2
push_to_hub: false
tags: null
call_post_training: null
logging_strategy: steps
logging_steps: 1
report_to: wandb
wandb_project: honban_step2_rlt
wandb_group_name: ${data_log_name}/${model_log_name}
wandb_run_name: ${trainer_log_name}
results_dir: /home/Competition2025/P07/shareP07/share_model/step2_rlt
exp_name: ${now:%Y.%m.%d}${now:%H%M%S}
output_dir: ${results_dir}/Qwen3-14B-step2-deepmath103k-bs${train_batch_size}
resume_from: ${output_dir}
seed: 42
model_log_name: qwen3-14b
model_name_or_path: llm-compe-2025-kato/Qwen3-14B-Step1-Bespoke17k-ep1
tokenizer_name_or_path: ${model_name_or_path}
model_args:
  _target_: hydra_utils.trl.ModelConfig
  model_name_or_path: ${model_name_or_path}
  trust_remote_code: true
  use_peft: ${use_peft}
  load_in_4bit: ${load_in_4bit}
  model_revision: main
  torch_dtype: bfloat16
  attn_implementation: flash_attention_2
use_peft: false
load_in_4bit: false
tokenizer:
  _target_: hydra_utils.transformers.AutoTokenizer.from_pretrained
  pretrained_model_name_or_path: ${tokenizer_name_or_path}
  trust_remote_code: true
  padding_side: left
  model_revision: ${model_args.model_revision}
unsafe_tokenizer_loading: false
make_tokenizer_fn:
  _target_: hydra_utils.fix_pad_token
  tokenizer: ${tokenizer}
  model_name: ${model_name_or_path}
  unsafe: ${unsafe_tokenizer_loading}
peft_config:
  _target_: hydra_utils.trl.get_peft_config
  model_args: ${model_args}
data_log_name: stage2_data
dataset_id_or_path: Nishi0923/DeepMath-103K-Bespoke-Filtered-Pilot-5K
dataset_local_directory: ${dataset_id_or_path}
make_dataset_fn:
  dataset_id_or_path: ${dataset_id_or_path}
  dataset_local_directory: ${dataset_local_directory}
  model_name_or_path: ${model_name_or_path}
  _target_: custom_data.sft_data.load_formatted_sft_dataset
  process_line_fn:
    _target_: custom_data.teacher_data.get_process_line_fn
    dataset_id_or_path: ${dataset_id_or_path}
    system_prompt_style: ${system_prompt_style}
    return_student_prompt_info: ${return_student_prompt_info}
    add_text_completions: ${add_text_completions}
  completion_only_training: ${completion_only_training}
  custom_start_of_response: ${custom_start_of_response}
  keep_columns: ${keep_columns}
  add_dataset_indices: ${add_dataset_indices}
dataset_configs:
- all
completion_only_training: false
custom_start_of_response:
  _target_: custom_data.teacher_data.get_teacher_data_mask_delimiter
  system_prompt_style: ${system_prompt_style}
  mask_teacher_answer: ${mask_teacher_answer}
  dataset_id_or_path: ${dataset_id_or_path}
keep_columns: null
add_dataset_indices: false
system_prompt_style: stratos
mask_teacher_answer: true
return_student_prompt_info: true
add_text_completions: false
max_steps: -1
num_train_epochs: 1.0
train_batch_size: 512
per_device_train_batch_size: 1
gradient_accumulation_steps: ???
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  _target_: builtins.dict
  use_reentrant: false
learning_rate: 1.0e-06
weight_decay: 0
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1.0e-08
max_grad_norm: 1.0
lr_scheduler_type: constant
lr_scheduler_kwargs: null
warmup_ratio: 0.03
bf16: true
tf32: true
ddp_timeout: 18000
trainer_log_name: teacher_grpo_rw_${reward_log_name}
trainer_args:
  _target_: trainers.GRPOConfig
  output_dir: ${output_dir}
  max_steps: ${max_steps}
  num_train_epochs: ${num_train_epochs}
  per_device_train_batch_size: ${per_device_train_batch_size}
  gradient_accumulation_steps: ${gradient_accumulation_steps}
  gradient_checkpointing: ${gradient_checkpointing}
  gradient_checkpointing_kwargs: ${gradient_checkpointing_kwargs}
  learning_rate: ${learning_rate}
  weight_decay: ${weight_decay}
  adam_beta1: ${adam_beta1}
  adam_beta2: ${adam_beta2}
  adam_epsilon: ${adam_epsilon}
  max_grad_norm: ${max_grad_norm}
  lr_scheduler_type: ${lr_scheduler_type}
  lr_scheduler_kwargs: ${lr_scheduler_kwargs}
  warmup_ratio: ${warmup_ratio}
  logging_strategy: ${logging_strategy}
  logging_steps: ${logging_steps}
  save_strategy: ${save_strategy}
  save_steps: ${save_steps}
  report_to: ${report_to}
  run_name: ${wandb_run_name}
  bf16: ${bf16}
  tf32: ${tf32}
  seed: ${seed}
  ddp_timeout: ${ddp_timeout}
  model_init_kwargs: ${model_init_kwargs}
  remove_unused_columns: ${remove_unused_columns}
  max_prompt_length: ${max_prompt_length}
  num_generations: ${num_generations}
  max_completion_length: ${max_completion_length}
  shuffle_generation_inputs: ${shuffle_generation_inputs}
  ds3_gather_for_generation: ${ds3_gather_for_generation}
  temperature: ${temperature}
  top_p: ${top_p}
  top_k: ${top_k}
  min_p: ${min_p}
  repetition_penalty: ${repetition_penalty}
  generation_aggregation_steps: ${generation_aggregation_steps}
  use_vllm: ${use_vllm}
  vllm_device: ${vllm_device}
  vllm_gpu_memory_utilization: ${vllm_gpu_memory_utilization}
  vllm_dtype: ${vllm_dtype}
  vllm_max_model_len: ${vllm_max_model_len}
  use_ray: ${use_ray}
  ray_share_training_devices: ${ray_share_training_devices}
  ray_tensor_parallelism: ${ray_tensor_parallelism}
  ray_data_parallelism: ${ray_data_parallelism}
  ray_no_memory_duplication: ${ray_no_memory_duplication}
  enable_prefix_caching: ${enable_prefix_caching}
  enforce_eager: ${enforce_eager}
  vllm_sleep_level: ${vllm_sleep_level}
  use_vllm_server: ${use_vllm_server}
  vllm_host: ${vllm_host}
  vllm_port: ${vllm_port}
  vllm_group_port: ${vllm_group_port}
  num_vllm_clients: ${num_vllm_clients}
  beta: ${beta}
  reward_weights: ${reward_weights}
  sync_ref_model: ${sync_ref_model}
  ref_model_mixup_alpha: ${ref_model_mixup_alpha}
  ref_model_sync_steps: ${ref_model_sync_steps}
  log_completions: ${log_completions}
  save_completions_probability: ${save_completions_probability}
  artificial_epochs: ${artificial_epochs}
  backprop_accumulation_steps: ${backprop_accumulation_steps}
  backprop_accumulation_micro_batch_size: ${backprop_accumulation_micro_batch_size}
  offload_untrained_models: ${offload_untrained_models}
  unbias_log_probabilities: ${unbias_log_probabilities}
  activate_debugging_logs: ${activate_debugging_logs}
  push_to_hub: ${push_to_hub}
trainer:
  _target_: trainers.TeacherGRPOTrainer
  model: ${model_name_or_path}
  args: ${trainer_args}
  peft_config: ${peft_config}
  reward_funcs: ${reward_fns}
  student_model: ${student_model}
  use_reference_teacher_model: ${use_reference_teacher_model}
  student_model_init_kwargs: ${student_model_init_kwargs}
  logging_prob: ${logging_prob}
  disable_student_offloading: ${disable_student_offloading}
artificial_epochs: 1
num_generations: 128
beta: 0.04
model_init_kwargs: null
remove_unused_columns: false
max_prompt_length: 16384
max_completion_length: 16384
shuffle_generation_inputs: true
ds3_gather_for_generation: true
temperature: 0.7
top_p: 1.0
top_k: null
min_p: null
repetition_penalty: 1.0
generation_aggregation_steps: 64
use_vllm: false
vllm_device: auto
vllm_gpu_memory_utilization: 0.9
vllm_dtype: auto
vllm_max_model_len: null
use_ray: false
ray_share_training_devices: false
ray_tensor_parallelism: 1
ray_data_parallelism: null
ray_no_memory_duplication: false
vllm_sleep_level: 0
enable_prefix_caching: false
enforce_eager: true
use_vllm_server: true
vllm_host: osk-gpu70
vllm_port: 8765
vllm_group_port: 51216
num_vllm_clients: 8
reward_weights: null
sync_ref_model: true
ref_model_mixup_alpha: 0.9
ref_model_sync_steps: 64
backprop_accumulation_steps: null
backprop_accumulation_micro_batch_size: null
offload_untrained_models: false
unbias_log_probabilities: true
log_completions: false
save_completions_probability: 0.1
activate_debugging_logs: false
reward_log_name: student_solution_kl_reg
answer_log_prob_coeff:
- 1
- 0.01
kl_penalty_reward_coeff:
- 3
- 0.03
normalize_log_prob_fn: null
clip_log_prob: 100000
normalize_kl_fn: null
clip_kl: 100000
reduction_log_prob_fn:
- mean
- min
reduction_kl_fn:
- mean
- max
use_schulman_kl_estimation: false
not_matched_penalty: -1.0
unbias_teacher_log_probs: true
unbias_student_log_probs_temp: 0.7
include_teacher_think_entropy: true
correct_generation_coeff: 0.0
correct_generation_rollouts: 8
student_generation_kwargs: {}
student_generation_check_stategy: ground_truth
formatting_sub_rewards: []
evaluate_refined_solution: false
teacher_reward:
  _target_: trainers.TeacherKLBasedReward
  student_model: null
  teacher_model: null
  tokenizer: null
  answer_log_prob_coeff: ${answer_log_prob_coeff}
  kl_penalty_reward_coeff: ${kl_penalty_reward_coeff}
  normalize_log_prob_fn: ${normalize_log_prob_fn}
  clip_log_prob: ${clip_log_prob}
  normalize_kl_fn: ${normalize_kl_fn}
  clip_kl: ${clip_kl}
  reduction_log_prob_fn: ${reduction_log_prob_fn}
  reduction_kl_fn: ${reduction_kl_fn}
  use_schulman_kl_estimation: ${use_schulman_kl_estimation}
  not_matched_penalty: ${not_matched_penalty}
  unbias_teacher_log_probs: ${unbias_teacher_log_probs}
  unbias_student_log_probs_temp: ${unbias_student_log_probs_temp}
  include_teacher_think_entropy: ${include_teacher_think_entropy}
  correct_generation_coeff: ${correct_generation_coeff}
  correct_generation_rollouts: ${correct_generation_rollouts}
  generation_kwargs: ${student_generation_kwargs}
  generation_check_stategy: ${student_generation_check_stategy}
  formatting_sub_rewards: ${formatting_sub_rewards}
  evaluate_refined_solution: ${evaluate_refined_solution}
reward_fns:
  _target_: hydra_utils.wrap_as_list
  teacher_reward: ${teacher_reward}
logging_prob: 0.1
student_model: Qwen/Qwen3-14B
use_reference_teacher_model: false
student_model_init_kwargs: null
disable_student_offloading: false
do_eval: true
eval_strategy: steps
eval_steps: 2
wandb_entity: llm-compe-2025-kato
log_ctx_name: gr${num_generations}_${max_prompt_length}ctx_${max_completion_length}gen

[2025-08-18 21:11:46,986][__main__][INFO] - Accumulation steps 64 ----
[2025-08-18 21:11:48,760][__main__][INFO] - Configuration:
save_final_model: true
save_strategy: steps
save_steps: 2
push_to_hub: false
tags: null
call_post_training: null
logging_strategy: steps
logging_steps: 1
report_to: wandb
wandb_project: honban_step2_rlt
wandb_group_name: ${data_log_name}/${model_log_name}
wandb_run_name: ${trainer_log_name}
results_dir: /home/Competition2025/P07/shareP07/share_model/step2_rlt
exp_name: ${now:%Y.%m.%d}${now:%H%M%S}
output_dir: ${results_dir}/Qwen3-14B-step2-deepmath103k-bs${train_batch_size}
resume_from: ${output_dir}
seed: 42
model_log_name: qwen3-14b
model_name_or_path: llm-compe-2025-kato/Qwen3-14B-Step1-Bespoke17k-ep1
tokenizer_name_or_path: ${model_name_or_path}
model_args:
  _target_: hydra_utils.trl.ModelConfig
  model_name_or_path: ${model_name_or_path}
  trust_remote_code: true
  use_peft: ${use_peft}
  load_in_4bit: ${load_in_4bit}
  model_revision: main
  torch_dtype: bfloat16
  attn_implementation: flash_attention_2
use_peft: false
load_in_4bit: false
tokenizer:
  _target_: hydra_utils.transformers.AutoTokenizer.from_pretrained
  pretrained_model_name_or_path: ${tokenizer_name_or_path}
  trust_remote_code: true
  padding_side: left
  model_revision: ${model_args.model_revision}
unsafe_tokenizer_loading: false
make_tokenizer_fn:
  _target_: hydra_utils.fix_pad_token
  tokenizer: ${tokenizer}
  model_name: ${model_name_or_path}
  unsafe: ${unsafe_tokenizer_loading}
peft_config:
  _target_: hydra_utils.trl.get_peft_config
  model_args: ${model_args}
data_log_name: stage2_data
dataset_id_or_path: Nishi0923/DeepMath-103K-Bespoke-Filtered-Pilot-5K
dataset_local_directory: ${dataset_id_or_path}
make_dataset_fn:
  dataset_id_or_path: ${dataset_id_or_path}
  dataset_local_directory: ${dataset_local_directory}
  model_name_or_path: ${model_name_or_path}
  _target_: custom_data.sft_data.load_formatted_sft_dataset
  process_line_fn:
    _target_: custom_data.teacher_data.get_process_line_fn
    dataset_id_or_path: ${dataset_id_or_path}
    system_prompt_style: ${system_prompt_style}
    return_student_prompt_info: ${return_student_prompt_info}
    add_text_completions: ${add_text_completions}
  completion_only_training: ${completion_only_training}
  custom_start_of_response: ${custom_start_of_response}
  keep_columns: ${keep_columns}
  add_dataset_indices: ${add_dataset_indices}
dataset_configs:
- all
completion_only_training: false
custom_start_of_response:
  _target_: custom_data.teacher_data.get_teacher_data_mask_delimiter
  system_prompt_style: ${system_prompt_style}
  mask_teacher_answer: ${mask_teacher_answer}
  dataset_id_or_path: ${dataset_id_or_path}
keep_columns: null
add_dataset_indices: false
system_prompt_style: stratos
mask_teacher_answer: true
return_student_prompt_info: true
add_text_completions: false
max_steps: -1
num_train_epochs: 1.0
train_batch_size: 512
per_device_train_batch_size: 1
gradient_accumulation_steps: ???
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  _target_: builtins.dict
  use_reentrant: false
learning_rate: 1.0e-06
weight_decay: 0
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1.0e-08
max_grad_norm: 1.0
lr_scheduler_type: constant
lr_scheduler_kwargs: null
warmup_ratio: 0.03
bf16: true
tf32: true
ddp_timeout: 18000
trainer_log_name: teacher_grpo_rw_${reward_log_name}
trainer_args:
  _target_: trainers.GRPOConfig
  output_dir: ${output_dir}
  max_steps: ${max_steps}
  num_train_epochs: ${num_train_epochs}
  per_device_train_batch_size: ${per_device_train_batch_size}
  gradient_accumulation_steps: ${gradient_accumulation_steps}
  gradient_checkpointing: ${gradient_checkpointing}
  gradient_checkpointing_kwargs: ${gradient_checkpointing_kwargs}
  learning_rate: ${learning_rate}
  weight_decay: ${weight_decay}
  adam_beta1: ${adam_beta1}
  adam_beta2: ${adam_beta2}
  adam_epsilon: ${adam_epsilon}
  max_grad_norm: ${max_grad_norm}
  lr_scheduler_type: ${lr_scheduler_type}
  lr_scheduler_kwargs: ${lr_scheduler_kwargs}
  warmup_ratio: ${warmup_ratio}
  logging_strategy: ${logging_strategy}
  logging_steps: ${logging_steps}
  save_strategy: ${save_strategy}
  save_steps: ${save_steps}
  report_to: ${report_to}
  run_name: ${wandb_run_name}
  bf16: ${bf16}
  tf32: ${tf32}
  seed: ${seed}
  ddp_timeout: ${ddp_timeout}
  model_init_kwargs: ${model_init_kwargs}
  remove_unused_columns: ${remove_unused_columns}
  max_prompt_length: ${max_prompt_length}
  num_generations: ${num_generations}
  max_completion_length: ${max_completion_length}
  shuffle_generation_inputs: ${shuffle_generation_inputs}
  ds3_gather_for_generation: ${ds3_gather_for_generation}
  temperature: ${temperature}
  top_p: ${top_p}
  top_k: ${top_k}
  min_p: ${min_p}
  repetition_penalty: ${repetition_penalty}
  generation_aggregation_steps: ${generation_aggregation_steps}
  use_vllm: ${use_vllm}
  vllm_device: ${vllm_device}
  vllm_gpu_memory_utilization: ${vllm_gpu_memory_utilization}
  vllm_dtype: ${vllm_dtype}
  vllm_max_model_len: ${vllm_max_model_len}
  use_ray: ${use_ray}
  ray_share_training_devices: ${ray_share_training_devices}
  ray_tensor_parallelism: ${ray_tensor_parallelism}
  ray_data_parallelism: ${ray_data_parallelism}
  ray_no_memory_duplication: ${ray_no_memory_duplication}
  enable_prefix_caching: ${enable_prefix_caching}
  enforce_eager: ${enforce_eager}
  vllm_sleep_level: ${vllm_sleep_level}
  use_vllm_server: ${use_vllm_server}
  vllm_host: ${vllm_host}
  vllm_port: ${vllm_port}
  vllm_group_port: ${vllm_group_port}
  num_vllm_clients: ${num_vllm_clients}
  beta: ${beta}
  reward_weights: ${reward_weights}
  sync_ref_model: ${sync_ref_model}
  ref_model_mixup_alpha: ${ref_model_mixup_alpha}
  ref_model_sync_steps: ${ref_model_sync_steps}
  log_completions: ${log_completions}
  save_completions_probability: ${save_completions_probability}
  artificial_epochs: ${artificial_epochs}
  backprop_accumulation_steps: ${backprop_accumulation_steps}
  backprop_accumulation_micro_batch_size: ${backprop_accumulation_micro_batch_size}
  offload_untrained_models: ${offload_untrained_models}
  unbias_log_probabilities: ${unbias_log_probabilities}
  activate_debugging_logs: ${activate_debugging_logs}
  push_to_hub: ${push_to_hub}
trainer:
  _target_: trainers.TeacherGRPOTrainer
  model: ${model_name_or_path}
  args: ${trainer_args}
  peft_config: ${peft_config}
  reward_funcs: ${reward_fns}
  student_model: ${student_model}
  use_reference_teacher_model: ${use_reference_teacher_model}
  student_model_init_kwargs: ${student_model_init_kwargs}
  logging_prob: ${logging_prob}
  disable_student_offloading: ${disable_student_offloading}
artificial_epochs: 1
num_generations: 128
beta: 0.04
model_init_kwargs: null
remove_unused_columns: false
max_prompt_length: 16384
max_completion_length: 16384
shuffle_generation_inputs: true
ds3_gather_for_generation: true
temperature: 0.7
top_p: 1.0
top_k: null
min_p: null
repetition_penalty: 1.0
generation_aggregation_steps: 64
use_vllm: false
vllm_device: auto
vllm_gpu_memory_utilization: 0.9
vllm_dtype: auto
vllm_max_model_len: null
use_ray: false
ray_share_training_devices: false
ray_tensor_parallelism: 1
ray_data_parallelism: null
ray_no_memory_duplication: false
vllm_sleep_level: 0
enable_prefix_caching: false
enforce_eager: true
use_vllm_server: true
vllm_host: osk-gpu70
vllm_port: 8765
vllm_group_port: 51216
num_vllm_clients: 8
reward_weights: null
sync_ref_model: true
ref_model_mixup_alpha: 0.9
ref_model_sync_steps: 64
backprop_accumulation_steps: null
backprop_accumulation_micro_batch_size: null
offload_untrained_models: false
unbias_log_probabilities: true
log_completions: false
save_completions_probability: 0.1
activate_debugging_logs: false
reward_log_name: student_solution_kl_reg
answer_log_prob_coeff:
- 1
- 0.01
kl_penalty_reward_coeff:
- 3
- 0.03
normalize_log_prob_fn: null
clip_log_prob: 100000
normalize_kl_fn: null
clip_kl: 100000
reduction_log_prob_fn:
- mean
- min
reduction_kl_fn:
- mean
- max
use_schulman_kl_estimation: false
not_matched_penalty: -1.0
unbias_teacher_log_probs: true
unbias_student_log_probs_temp: 0.7
include_teacher_think_entropy: true
correct_generation_coeff: 0.0
correct_generation_rollouts: 8
student_generation_kwargs: {}
student_generation_check_stategy: ground_truth
formatting_sub_rewards: []
evaluate_refined_solution: false
teacher_reward:
  _target_: trainers.TeacherKLBasedReward
  student_model: null
  teacher_model: null
  tokenizer: null
  answer_log_prob_coeff: ${answer_log_prob_coeff}
  kl_penalty_reward_coeff: ${kl_penalty_reward_coeff}
  normalize_log_prob_fn: ${normalize_log_prob_fn}
  clip_log_prob: ${clip_log_prob}
  normalize_kl_fn: ${normalize_kl_fn}
  clip_kl: ${clip_kl}
  reduction_log_prob_fn: ${reduction_log_prob_fn}
  reduction_kl_fn: ${reduction_kl_fn}
  use_schulman_kl_estimation: ${use_schulman_kl_estimation}
  not_matched_penalty: ${not_matched_penalty}
  unbias_teacher_log_probs: ${unbias_teacher_log_probs}
  unbias_student_log_probs_temp: ${unbias_student_log_probs_temp}
  include_teacher_think_entropy: ${include_teacher_think_entropy}
  correct_generation_coeff: ${correct_generation_coeff}
  correct_generation_rollouts: ${correct_generation_rollouts}
  generation_kwargs: ${student_generation_kwargs}
  generation_check_stategy: ${student_generation_check_stategy}
  formatting_sub_rewards: ${formatting_sub_rewards}
  evaluate_refined_solution: ${evaluate_refined_solution}
reward_fns:
  _target_: hydra_utils.wrap_as_list
  teacher_reward: ${teacher_reward}
logging_prob: 0.1
student_model: Qwen/Qwen3-14B
use_reference_teacher_model: false
student_model_init_kwargs: null
disable_student_offloading: false
do_eval: true
eval_strategy: steps
eval_steps: 2
wandb_entity: llm-compe-2025-kato
log_ctx_name: gr${num_generations}_${max_prompt_length}ctx_${max_completion_length}gen

[2025-08-18 21:11:48,760][__main__][INFO] - Accumulation steps 64 ----
[2025-08-18 21:11:49,258][__main__][INFO] - Configuration:
save_final_model: true
save_strategy: steps
save_steps: 2
push_to_hub: false
tags: null
call_post_training: null
logging_strategy: steps
logging_steps: 1
report_to: wandb
wandb_project: honban_step2_rlt
wandb_group_name: ${data_log_name}/${model_log_name}
wandb_run_name: ${trainer_log_name}
results_dir: /home/Competition2025/P07/shareP07/share_model/step2_rlt
exp_name: ${now:%Y.%m.%d}${now:%H%M%S}
output_dir: ${results_dir}/Qwen3-14B-step2-deepmath103k-bs${train_batch_size}
resume_from: ${output_dir}
seed: 42
model_log_name: qwen3-14b
model_name_or_path: llm-compe-2025-kato/Qwen3-14B-Step1-Bespoke17k-ep1
tokenizer_name_or_path: ${model_name_or_path}
model_args:
  _target_: hydra_utils.trl.ModelConfig
  model_name_or_path: ${model_name_or_path}
  trust_remote_code: true
  use_peft: ${use_peft}
  load_in_4bit: ${load_in_4bit}
  model_revision: main
  torch_dtype: bfloat16
  attn_implementation: flash_attention_2
use_peft: false
load_in_4bit: false
tokenizer:
  _target_: hydra_utils.transformers.AutoTokenizer.from_pretrained
  pretrained_model_name_or_path: ${tokenizer_name_or_path}
  trust_remote_code: true
  padding_side: left
  model_revision: ${model_args.model_revision}
unsafe_tokenizer_loading: false
make_tokenizer_fn:
  _target_: hydra_utils.fix_pad_token
  tokenizer: ${tokenizer}
  model_name: ${model_name_or_path}
  unsafe: ${unsafe_tokenizer_loading}
peft_config:
  _target_: hydra_utils.trl.get_peft_config
  model_args: ${model_args}
data_log_name: stage2_data
dataset_id_or_path: Nishi0923/DeepMath-103K-Bespoke-Filtered-Pilot-5K
dataset_local_directory: ${dataset_id_or_path}
make_dataset_fn:
  dataset_id_or_path: ${dataset_id_or_path}
  dataset_local_directory: ${dataset_local_directory}
  model_name_or_path: ${model_name_or_path}
  _target_: custom_data.sft_data.load_formatted_sft_dataset
  process_line_fn:
    _target_: custom_data.teacher_data.get_process_line_fn
    dataset_id_or_path: ${dataset_id_or_path}
    system_prompt_style: ${system_prompt_style}
    return_student_prompt_info: ${return_student_prompt_info}
    add_text_completions: ${add_text_completions}
  completion_only_training: ${completion_only_training}
  custom_start_of_response: ${custom_start_of_response}
  keep_columns: ${keep_columns}
  add_dataset_indices: ${add_dataset_indices}
dataset_configs:
- all
completion_only_training: false
custom_start_of_response:
  _target_: custom_data.teacher_data.get_teacher_data_mask_delimiter
  system_prompt_style: ${system_prompt_style}
  mask_teacher_answer: ${mask_teacher_answer}
  dataset_id_or_path: ${dataset_id_or_path}
keep_columns: null
add_dataset_indices: false
system_prompt_style: stratos
mask_teacher_answer: true
return_student_prompt_info: true
add_text_completions: false
max_steps: -1
num_train_epochs: 1.0
train_batch_size: 512
per_device_train_batch_size: 1
gradient_accumulation_steps: ???
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  _target_: builtins.dict
  use_reentrant: false
learning_rate: 1.0e-06
weight_decay: 0
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1.0e-08
max_grad_norm: 1.0
lr_scheduler_type: constant
lr_scheduler_kwargs: null
warmup_ratio: 0.03
bf16: true
tf32: true
ddp_timeout: 18000
trainer_log_name: teacher_grpo_rw_${reward_log_name}
trainer_args:
  _target_: trainers.GRPOConfig
  output_dir: ${output_dir}
  max_steps: ${max_steps}
  num_train_epochs: ${num_train_epochs}
  per_device_train_batch_size: ${per_device_train_batch_size}
  gradient_accumulation_steps: ${gradient_accumulation_steps}
  gradient_checkpointing: ${gradient_checkpointing}
  gradient_checkpointing_kwargs: ${gradient_checkpointing_kwargs}
  learning_rate: ${learning_rate}
  weight_decay: ${weight_decay}
  adam_beta1: ${adam_beta1}
  adam_beta2: ${adam_beta2}
  adam_epsilon: ${adam_epsilon}
  max_grad_norm: ${max_grad_norm}
  lr_scheduler_type: ${lr_scheduler_type}
  lr_scheduler_kwargs: ${lr_scheduler_kwargs}
  warmup_ratio: ${warmup_ratio}
  logging_strategy: ${logging_strategy}
  logging_steps: ${logging_steps}
  save_strategy: ${save_strategy}
  save_steps: ${save_steps}
  report_to: ${report_to}
  run_name: ${wandb_run_name}
  bf16: ${bf16}
  tf32: ${tf32}
  seed: ${seed}
  ddp_timeout: ${ddp_timeout}
  model_init_kwargs: ${model_init_kwargs}
  remove_unused_columns: ${remove_unused_columns}
  max_prompt_length: ${max_prompt_length}
  num_generations: ${num_generations}
  max_completion_length: ${max_completion_length}
  shuffle_generation_inputs: ${shuffle_generation_inputs}
  ds3_gather_for_generation: ${ds3_gather_for_generation}
  temperature: ${temperature}
  top_p: ${top_p}
  top_k: ${top_k}
  min_p: ${min_p}
  repetition_penalty: ${repetition_penalty}
  generation_aggregation_steps: ${generation_aggregation_steps}
  use_vllm: ${use_vllm}
  vllm_device: ${vllm_device}
  vllm_gpu_memory_utilization: ${vllm_gpu_memory_utilization}
  vllm_dtype: ${vllm_dtype}
  vllm_max_model_len: ${vllm_max_model_len}
  use_ray: ${use_ray}
  ray_share_training_devices: ${ray_share_training_devices}
  ray_tensor_parallelism: ${ray_tensor_parallelism}
  ray_data_parallelism: ${ray_data_parallelism}
  ray_no_memory_duplication: ${ray_no_memory_duplication}
  enable_prefix_caching: ${enable_prefix_caching}
  enforce_eager: ${enforce_eager}
  vllm_sleep_level: ${vllm_sleep_level}
  use_vllm_server: ${use_vllm_server}
  vllm_host: ${vllm_host}
  vllm_port: ${vllm_port}
  vllm_group_port: ${vllm_group_port}
  num_vllm_clients: ${num_vllm_clients}
  beta: ${beta}
  reward_weights: ${reward_weights}
  sync_ref_model: ${sync_ref_model}
  ref_model_mixup_alpha: ${ref_model_mixup_alpha}
  ref_model_sync_steps: ${ref_model_sync_steps}
  log_completions: ${log_completions}
  save_completions_probability: ${save_completions_probability}
  artificial_epochs: ${artificial_epochs}
  backprop_accumulation_steps: ${backprop_accumulation_steps}
  backprop_accumulation_micro_batch_size: ${backprop_accumulation_micro_batch_size}
  offload_untrained_models: ${offload_untrained_models}
  unbias_log_probabilities: ${unbias_log_probabilities}
  activate_debugging_logs: ${activate_debugging_logs}
  push_to_hub: ${push_to_hub}
trainer:
  _target_: trainers.TeacherGRPOTrainer
  model: ${model_name_or_path}
  args: ${trainer_args}
  peft_config: ${peft_config}
  reward_funcs: ${reward_fns}
  student_model: ${student_model}
  use_reference_teacher_model: ${use_reference_teacher_model}
  student_model_init_kwargs: ${student_model_init_kwargs}
  logging_prob: ${logging_prob}
  disable_student_offloading: ${disable_student_offloading}
artificial_epochs: 1
num_generations: 128
beta: 0.04
model_init_kwargs: null
remove_unused_columns: false
max_prompt_length: 16384
max_completion_length: 16384
shuffle_generation_inputs: true
ds3_gather_for_generation: true
temperature: 0.7
top_p: 1.0
top_k: null
min_p: null
repetition_penalty: 1.0
generation_aggregation_steps: 64
use_vllm: false
vllm_device: auto
vllm_gpu_memory_utilization: 0.9
vllm_dtype: auto
vllm_max_model_len: null
use_ray: false
ray_share_training_devices: false
ray_tensor_parallelism: 1
ray_data_parallelism: null
ray_no_memory_duplication: false
vllm_sleep_level: 0
enable_prefix_caching: false
enforce_eager: true
use_vllm_server: true
vllm_host: osk-gpu70
vllm_port: 8765
vllm_group_port: 51216
num_vllm_clients: 8
reward_weights: null
sync_ref_model: true
ref_model_mixup_alpha: 0.9
ref_model_sync_steps: 64
backprop_accumulation_steps: null
backprop_accumulation_micro_batch_size: null
offload_untrained_models: false
unbias_log_probabilities: true
log_completions: false
save_completions_probability: 0.1
activate_debugging_logs: false
reward_log_name: student_solution_kl_reg
answer_log_prob_coeff:
- 1
- 0.01
kl_penalty_reward_coeff:
- 3
- 0.03
normalize_log_prob_fn: null
clip_log_prob: 100000
normalize_kl_fn: null
clip_kl: 100000
reduction_log_prob_fn:
- mean
- min
reduction_kl_fn:
- mean
- max
use_schulman_kl_estimation: false
not_matched_penalty: -1.0
unbias_teacher_log_probs: true
unbias_student_log_probs_temp: 0.7
include_teacher_think_entropy: true
correct_generation_coeff: 0.0
correct_generation_rollouts: 8
student_generation_kwargs: {}
student_generation_check_stategy: ground_truth
formatting_sub_rewards: []
evaluate_refined_solution: false
teacher_reward:
  _target_: trainers.TeacherKLBasedReward
  student_model: null
  teacher_model: null
  tokenizer: null
  answer_log_prob_coeff: ${answer_log_prob_coeff}
  kl_penalty_reward_coeff: ${kl_penalty_reward_coeff}
  normalize_log_prob_fn: ${normalize_log_prob_fn}
  clip_log_prob: ${clip_log_prob}
  normalize_kl_fn: ${normalize_kl_fn}
  clip_kl: ${clip_kl}
  reduction_log_prob_fn: ${reduction_log_prob_fn}
  reduction_kl_fn: ${reduction_kl_fn}
  use_schulman_kl_estimation: ${use_schulman_kl_estimation}
  not_matched_penalty: ${not_matched_penalty}
  unbias_teacher_log_probs: ${unbias_teacher_log_probs}
  unbias_student_log_probs_temp: ${unbias_student_log_probs_temp}
  include_teacher_think_entropy: ${include_teacher_think_entropy}
  correct_generation_coeff: ${correct_generation_coeff}
  correct_generation_rollouts: ${correct_generation_rollouts}
  generation_kwargs: ${student_generation_kwargs}
  generation_check_stategy: ${student_generation_check_stategy}
  formatting_sub_rewards: ${formatting_sub_rewards}
  evaluate_refined_solution: ${evaluate_refined_solution}
reward_fns:
  _target_: hydra_utils.wrap_as_list
  teacher_reward: ${teacher_reward}
logging_prob: 0.1
student_model: Qwen/Qwen3-14B
use_reference_teacher_model: false
student_model_init_kwargs: null
disable_student_offloading: false
do_eval: true
eval_strategy: steps
eval_steps: 2
wandb_entity: llm-compe-2025-kato
log_ctx_name: gr${num_generations}_${max_prompt_length}ctx_${max_completion_length}gen

[2025-08-18 21:11:49,258][__main__][INFO] - Accumulation steps 64 ----
[2025-08-18 21:11:49,310][__main__][INFO] - Configuration:
save_final_model: true
save_strategy: steps
save_steps: 2
push_to_hub: false
tags: null
call_post_training: null
logging_strategy: steps
logging_steps: 1
report_to: wandb
wandb_project: honban_step2_rlt
wandb_group_name: ${data_log_name}/${model_log_name}
wandb_run_name: ${trainer_log_name}
results_dir: /home/Competition2025/P07/shareP07/share_model/step2_rlt
exp_name: ${now:%Y.%m.%d}${now:%H%M%S}
output_dir: ${results_dir}/Qwen3-14B-step2-deepmath103k-bs${train_batch_size}
resume_from: ${output_dir}
seed: 42
model_log_name: qwen3-14b
model_name_or_path: llm-compe-2025-kato/Qwen3-14B-Step1-Bespoke17k-ep1
tokenizer_name_or_path: ${model_name_or_path}
model_args:
  _target_: hydra_utils.trl.ModelConfig
  model_name_or_path: ${model_name_or_path}
  trust_remote_code: true
  use_peft: ${use_peft}
  load_in_4bit: ${load_in_4bit}
  model_revision: main
  torch_dtype: bfloat16
  attn_implementation: flash_attention_2
use_peft: false
load_in_4bit: false
tokenizer:
  _target_: hydra_utils.transformers.AutoTokenizer.from_pretrained
  pretrained_model_name_or_path: ${tokenizer_name_or_path}
  trust_remote_code: true
  padding_side: left
  model_revision: ${model_args.model_revision}
unsafe_tokenizer_loading: false
make_tokenizer_fn:
  _target_: hydra_utils.fix_pad_token
  tokenizer: ${tokenizer}
  model_name: ${model_name_or_path}
  unsafe: ${unsafe_tokenizer_loading}
peft_config:
  _target_: hydra_utils.trl.get_peft_config
  model_args: ${model_args}
data_log_name: stage2_data
dataset_id_or_path: Nishi0923/DeepMath-103K-Bespoke-Filtered-Pilot-5K
dataset_local_directory: ${dataset_id_or_path}
make_dataset_fn:
  dataset_id_or_path: ${dataset_id_or_path}
  dataset_local_directory: ${dataset_local_directory}
  model_name_or_path: ${model_name_or_path}
  _target_: custom_data.sft_data.load_formatted_sft_dataset
  process_line_fn:
    _target_: custom_data.teacher_data.get_process_line_fn
    dataset_id_or_path: ${dataset_id_or_path}
    system_prompt_style: ${system_prompt_style}
    return_student_prompt_info: ${return_student_prompt_info}
    add_text_completions: ${add_text_completions}
  completion_only_training: ${completion_only_training}
  custom_start_of_response: ${custom_start_of_response}
  keep_columns: ${keep_columns}
  add_dataset_indices: ${add_dataset_indices}
dataset_configs:
- all
completion_only_training: false
custom_start_of_response:
  _target_: custom_data.teacher_data.get_teacher_data_mask_delimiter
  system_prompt_style: ${system_prompt_style}
  mask_teacher_answer: ${mask_teacher_answer}
  dataset_id_or_path: ${dataset_id_or_path}
keep_columns: null
add_dataset_indices: false
system_prompt_style: stratos
mask_teacher_answer: true
return_student_prompt_info: true
add_text_completions: false
max_steps: -1
num_train_epochs: 1.0
train_batch_size: 512
per_device_train_batch_size: 1
gradient_accumulation_steps: ???
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  _target_: builtins.dict
  use_reentrant: false
learning_rate: 1.0e-06
weight_decay: 0
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1.0e-08
max_grad_norm: 1.0
lr_scheduler_type: constant
lr_scheduler_kwargs: null
warmup_ratio: 0.03
bf16: true
tf32: true
ddp_timeout: 18000
trainer_log_name: teacher_grpo_rw_${reward_log_name}
trainer_args:
  _target_: trainers.GRPOConfig
  output_dir: ${output_dir}
  max_steps: ${max_steps}
  num_train_epochs: ${num_train_epochs}
  per_device_train_batch_size: ${per_device_train_batch_size}
  gradient_accumulation_steps: ${gradient_accumulation_steps}
  gradient_checkpointing: ${gradient_checkpointing}
  gradient_checkpointing_kwargs: ${gradient_checkpointing_kwargs}
  learning_rate: ${learning_rate}
  weight_decay: ${weight_decay}
  adam_beta1: ${adam_beta1}
  adam_beta2: ${adam_beta2}
  adam_epsilon: ${adam_epsilon}
  max_grad_norm: ${max_grad_norm}
  lr_scheduler_type: ${lr_scheduler_type}
  lr_scheduler_kwargs: ${lr_scheduler_kwargs}
  warmup_ratio: ${warmup_ratio}
  logging_strategy: ${logging_strategy}
  logging_steps: ${logging_steps}
  save_strategy: ${save_strategy}
  save_steps: ${save_steps}
  report_to: ${report_to}
  run_name: ${wandb_run_name}
  bf16: ${bf16}
  tf32: ${tf32}
  seed: ${seed}
  ddp_timeout: ${ddp_timeout}
  model_init_kwargs: ${model_init_kwargs}
  remove_unused_columns: ${remove_unused_columns}
  max_prompt_length: ${max_prompt_length}
  num_generations: ${num_generations}
  max_completion_length: ${max_completion_length}
  shuffle_generation_inputs: ${shuffle_generation_inputs}
  ds3_gather_for_generation: ${ds3_gather_for_generation}
  temperature: ${temperature}
  top_p: ${top_p}
  top_k: ${top_k}
  min_p: ${min_p}
  repetition_penalty: ${repetition_penalty}
  generation_aggregation_steps: ${generation_aggregation_steps}
  use_vllm: ${use_vllm}
  vllm_device: ${vllm_device}
  vllm_gpu_memory_utilization: ${vllm_gpu_memory_utilization}
  vllm_dtype: ${vllm_dtype}
  vllm_max_model_len: ${vllm_max_model_len}
  use_ray: ${use_ray}
  ray_share_training_devices: ${ray_share_training_devices}
  ray_tensor_parallelism: ${ray_tensor_parallelism}
  ray_data_parallelism: ${ray_data_parallelism}
  ray_no_memory_duplication: ${ray_no_memory_duplication}
  enable_prefix_caching: ${enable_prefix_caching}
  enforce_eager: ${enforce_eager}
  vllm_sleep_level: ${vllm_sleep_level}
  use_vllm_server: ${use_vllm_server}
  vllm_host: ${vllm_host}
  vllm_port: ${vllm_port}
  vllm_group_port: ${vllm_group_port}
  num_vllm_clients: ${num_vllm_clients}
  beta: ${beta}
  reward_weights: ${reward_weights}
  sync_ref_model: ${sync_ref_model}
  ref_model_mixup_alpha: ${ref_model_mixup_alpha}
  ref_model_sync_steps: ${ref_model_sync_steps}
  log_completions: ${log_completions}
  save_completions_probability: ${save_completions_probability}
  artificial_epochs: ${artificial_epochs}
  backprop_accumulation_steps: ${backprop_accumulation_steps}
  backprop_accumulation_micro_batch_size: ${backprop_accumulation_micro_batch_size}
  offload_untrained_models: ${offload_untrained_models}
  unbias_log_probabilities: ${unbias_log_probabilities}
  activate_debugging_logs: ${activate_debugging_logs}
  push_to_hub: ${push_to_hub}
trainer:
  _target_: trainers.TeacherGRPOTrainer
  model: ${model_name_or_path}
  args: ${trainer_args}
  peft_config: ${peft_config}
  reward_funcs: ${reward_fns}
  student_model: ${student_model}
  use_reference_teacher_model: ${use_reference_teacher_model}
  student_model_init_kwargs: ${student_model_init_kwargs}
  logging_prob: ${logging_prob}
  disable_student_offloading: ${disable_student_offloading}
artificial_epochs: 1
num_generations: 128
beta: 0.04
model_init_kwargs: null
remove_unused_columns: false
max_prompt_length: 16384
max_completion_length: 16384
shuffle_generation_inputs: true
ds3_gather_for_generation: true
temperature: 0.7
top_p: 1.0
top_k: null
min_p: null
repetition_penalty: 1.0
generation_aggregation_steps: 64
use_vllm: false
vllm_device: auto
vllm_gpu_memory_utilization: 0.9
vllm_dtype: auto
vllm_max_model_len: null
use_ray: false
ray_share_training_devices: false
ray_tensor_parallelism: 1
ray_data_parallelism: null
ray_no_memory_duplication: false
vllm_sleep_level: 0
enable_prefix_caching: false
enforce_eager: true
use_vllm_server: true
vllm_host: osk-gpu70
vllm_port: 8765
vllm_group_port: 51216
num_vllm_clients: 8
reward_weights: null
sync_ref_model: true
ref_model_mixup_alpha: 0.9
ref_model_sync_steps: 64
backprop_accumulation_steps: null
backprop_accumulation_micro_batch_size: null
offload_untrained_models: false
unbias_log_probabilities: true
log_completions: false
save_completions_probability: 0.1
activate_debugging_logs: false
reward_log_name: student_solution_kl_reg
answer_log_prob_coeff:
- 1
- 0.01
kl_penalty_reward_coeff:
- 3
- 0.03
normalize_log_prob_fn: null
clip_log_prob: 100000
normalize_kl_fn: null
clip_kl: 100000
reduction_log_prob_fn:
- mean
- min
reduction_kl_fn:
- mean
- max
use_schulman_kl_estimation: false
not_matched_penalty: -1.0
unbias_teacher_log_probs: true
unbias_student_log_probs_temp: 0.7
include_teacher_think_entropy: true
correct_generation_coeff: 0.0
correct_generation_rollouts: 8
student_generation_kwargs: {}
student_generation_check_stategy: ground_truth
formatting_sub_rewards: []
evaluate_refined_solution: false
teacher_reward:
  _target_: trainers.TeacherKLBasedReward
  student_model: null
  teacher_model: null
  tokenizer: null
  answer_log_prob_coeff: ${answer_log_prob_coeff}
  kl_penalty_reward_coeff: ${kl_penalty_reward_coeff}
  normalize_log_prob_fn: ${normalize_log_prob_fn}
  clip_log_prob: ${clip_log_prob}
  normalize_kl_fn: ${normalize_kl_fn}
  clip_kl: ${clip_kl}
  reduction_log_prob_fn: ${reduction_log_prob_fn}
  reduction_kl_fn: ${reduction_kl_fn}
  use_schulman_kl_estimation: ${use_schulman_kl_estimation}
  not_matched_penalty: ${not_matched_penalty}
  unbias_teacher_log_probs: ${unbias_teacher_log_probs}
  unbias_student_log_probs_temp: ${unbias_student_log_probs_temp}
  include_teacher_think_entropy: ${include_teacher_think_entropy}
  correct_generation_coeff: ${correct_generation_coeff}
  correct_generation_rollouts: ${correct_generation_rollouts}
  generation_kwargs: ${student_generation_kwargs}
  generation_check_stategy: ${student_generation_check_stategy}
  formatting_sub_rewards: ${formatting_sub_rewards}
  evaluate_refined_solution: ${evaluate_refined_solution}
reward_fns:
  _target_: hydra_utils.wrap_as_list
  teacher_reward: ${teacher_reward}
logging_prob: 0.1
student_model: Qwen/Qwen3-14B
use_reference_teacher_model: false
student_model_init_kwargs: null
disable_student_offloading: false
do_eval: true
eval_strategy: steps
eval_steps: 2
wandb_entity: llm-compe-2025-kato
log_ctx_name: gr${num_generations}_${max_prompt_length}ctx_${max_completion_length}gen

[2025-08-18 21:11:49,310][__main__][INFO] - Accumulation steps 64 ----
[2025-08-18 21:11:49,378][__main__][INFO] - Configuration:
save_final_model: true
save_strategy: steps
save_steps: 2
push_to_hub: false
tags: null
call_post_training: null
logging_strategy: steps
logging_steps: 1
report_to: wandb
wandb_project: honban_step2_rlt
wandb_group_name: ${data_log_name}/${model_log_name}
wandb_run_name: ${trainer_log_name}
results_dir: /home/Competition2025/P07/shareP07/share_model/step2_rlt
exp_name: ${now:%Y.%m.%d}${now:%H%M%S}
output_dir: ${results_dir}/Qwen3-14B-step2-deepmath103k-bs${train_batch_size}
resume_from: ${output_dir}
seed: 42
model_log_name: qwen3-14b
model_name_or_path: llm-compe-2025-kato/Qwen3-14B-Step1-Bespoke17k-ep1
tokenizer_name_or_path: ${model_name_or_path}
model_args:
  _target_: hydra_utils.trl.ModelConfig
  model_name_or_path: ${model_name_or_path}
  trust_remote_code: true
  use_peft: ${use_peft}
  load_in_4bit: ${load_in_4bit}
  model_revision: main
  torch_dtype: bfloat16
  attn_implementation: flash_attention_2
use_peft: false
load_in_4bit: false
tokenizer:
  _target_: hydra_utils.transformers.AutoTokenizer.from_pretrained
  pretrained_model_name_or_path: ${tokenizer_name_or_path}
  trust_remote_code: true
  padding_side: left
  model_revision: ${model_args.model_revision}
unsafe_tokenizer_loading: false
make_tokenizer_fn:
  _target_: hydra_utils.fix_pad_token
  tokenizer: ${tokenizer}
  model_name: ${model_name_or_path}
  unsafe: ${unsafe_tokenizer_loading}
peft_config:
  _target_: hydra_utils.trl.get_peft_config
  model_args: ${model_args}
data_log_name: stage2_data
dataset_id_or_path: Nishi0923/DeepMath-103K-Bespoke-Filtered-Pilot-5K
dataset_local_directory: ${dataset_id_or_path}
make_dataset_fn:
  dataset_id_or_path: ${dataset_id_or_path}
  dataset_local_directory: ${dataset_local_directory}
  model_name_or_path: ${model_name_or_path}
  _target_: custom_data.sft_data.load_formatted_sft_dataset
  process_line_fn:
    _target_: custom_data.teacher_data.get_process_line_fn
    dataset_id_or_path: ${dataset_id_or_path}
    system_prompt_style: ${system_prompt_style}
    return_student_prompt_info: ${return_student_prompt_info}
    add_text_completions: ${add_text_completions}
  completion_only_training: ${completion_only_training}
  custom_start_of_response: ${custom_start_of_response}
  keep_columns: ${keep_columns}
  add_dataset_indices: ${add_dataset_indices}
dataset_configs:
- all
completion_only_training: false
custom_start_of_response:
  _target_: custom_data.teacher_data.get_teacher_data_mask_delimiter
  system_prompt_style: ${system_prompt_style}
  mask_teacher_answer: ${mask_teacher_answer}
  dataset_id_or_path: ${dataset_id_or_path}
keep_columns: null
add_dataset_indices: false
system_prompt_style: stratos
mask_teacher_answer: true
return_student_prompt_info: true
add_text_completions: false
max_steps: -1
num_train_epochs: 1.0
train_batch_size: 512
per_device_train_batch_size: 1
gradient_accumulation_steps: ???
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  _target_: builtins.dict
  use_reentrant: false
learning_rate: 1.0e-06
weight_decay: 0
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1.0e-08
max_grad_norm: 1.0
lr_scheduler_type: constant
lr_scheduler_kwargs: null
warmup_ratio: 0.03
bf16: true
tf32: true
ddp_timeout: 18000
trainer_log_name: teacher_grpo_rw_${reward_log_name}
trainer_args:
  _target_: trainers.GRPOConfig
  output_dir: ${output_dir}
  max_steps: ${max_steps}
  num_train_epochs: ${num_train_epochs}
  per_device_train_batch_size: ${per_device_train_batch_size}
  gradient_accumulation_steps: ${gradient_accumulation_steps}
  gradient_checkpointing: ${gradient_checkpointing}
  gradient_checkpointing_kwargs: ${gradient_checkpointing_kwargs}
  learning_rate: ${learning_rate}
  weight_decay: ${weight_decay}
  adam_beta1: ${adam_beta1}
  adam_beta2: ${adam_beta2}
  adam_epsilon: ${adam_epsilon}
  max_grad_norm: ${max_grad_norm}
  lr_scheduler_type: ${lr_scheduler_type}
  lr_scheduler_kwargs: ${lr_scheduler_kwargs}
  warmup_ratio: ${warmup_ratio}
  logging_strategy: ${logging_strategy}
  logging_steps: ${logging_steps}
  save_strategy: ${save_strategy}
  save_steps: ${save_steps}
  report_to: ${report_to}
  run_name: ${wandb_run_name}
  bf16: ${bf16}
  tf32: ${tf32}
  seed: ${seed}
  ddp_timeout: ${ddp_timeout}
  model_init_kwargs: ${model_init_kwargs}
  remove_unused_columns: ${remove_unused_columns}
  max_prompt_length: ${max_prompt_length}
  num_generations: ${num_generations}
  max_completion_length: ${max_completion_length}
  shuffle_generation_inputs: ${shuffle_generation_inputs}
  ds3_gather_for_generation: ${ds3_gather_for_generation}
  temperature: ${temperature}
  top_p: ${top_p}
  top_k: ${top_k}
  min_p: ${min_p}
  repetition_penalty: ${repetition_penalty}
  generation_aggregation_steps: ${generation_aggregation_steps}
  use_vllm: ${use_vllm}
  vllm_device: ${vllm_device}
  vllm_gpu_memory_utilization: ${vllm_gpu_memory_utilization}
  vllm_dtype: ${vllm_dtype}
  vllm_max_model_len: ${vllm_max_model_len}
  use_ray: ${use_ray}
  ray_share_training_devices: ${ray_share_training_devices}
  ray_tensor_parallelism: ${ray_tensor_parallelism}
  ray_data_parallelism: ${ray_data_parallelism}
  ray_no_memory_duplication: ${ray_no_memory_duplication}
  enable_prefix_caching: ${enable_prefix_caching}
  enforce_eager: ${enforce_eager}
  vllm_sleep_level: ${vllm_sleep_level}
  use_vllm_server: ${use_vllm_server}
  vllm_host: ${vllm_host}
  vllm_port: ${vllm_port}
  vllm_group_port: ${vllm_group_port}
  num_vllm_clients: ${num_vllm_clients}
  beta: ${beta}
  reward_weights: ${reward_weights}
  sync_ref_model: ${sync_ref_model}
  ref_model_mixup_alpha: ${ref_model_mixup_alpha}
  ref_model_sync_steps: ${ref_model_sync_steps}
  log_completions: ${log_completions}
  save_completions_probability: ${save_completions_probability}
  artificial_epochs: ${artificial_epochs}
  backprop_accumulation_steps: ${backprop_accumulation_steps}
  backprop_accumulation_micro_batch_size: ${backprop_accumulation_micro_batch_size}
  offload_untrained_models: ${offload_untrained_models}
  unbias_log_probabilities: ${unbias_log_probabilities}
  activate_debugging_logs: ${activate_debugging_logs}
  push_to_hub: ${push_to_hub}
trainer:
  _target_: trainers.TeacherGRPOTrainer
  model: ${model_name_or_path}
  args: ${trainer_args}
  peft_config: ${peft_config}
  reward_funcs: ${reward_fns}
  student_model: ${student_model}
  use_reference_teacher_model: ${use_reference_teacher_model}
  student_model_init_kwargs: ${student_model_init_kwargs}
  logging_prob: ${logging_prob}
  disable_student_offloading: ${disable_student_offloading}
artificial_epochs: 1
num_generations: 128
beta: 0.04
model_init_kwargs: null
remove_unused_columns: false
max_prompt_length: 16384
max_completion_length: 16384
shuffle_generation_inputs: true
ds3_gather_for_generation: true
temperature: 0.7
top_p: 1.0
top_k: null
min_p: null
repetition_penalty: 1.0
generation_aggregation_steps: 64
use_vllm: false
vllm_device: auto
vllm_gpu_memory_utilization: 0.9
vllm_dtype: auto
vllm_max_model_len: null
use_ray: false
ray_share_training_devices: false
ray_tensor_parallelism: 1
ray_data_parallelism: null
ray_no_memory_duplication: false
vllm_sleep_level: 0
enable_prefix_caching: false
enforce_eager: true
use_vllm_server: true
vllm_host: osk-gpu70
vllm_port: 8765
vllm_group_port: 51216
num_vllm_clients: 8
reward_weights: null
sync_ref_model: true
ref_model_mixup_alpha: 0.9
ref_model_sync_steps: 64
backprop_accumulation_steps: null
backprop_accumulation_micro_batch_size: null
offload_untrained_models: false
unbias_log_probabilities: true
log_completions: false
save_completions_probability: 0.1
activate_debugging_logs: false
reward_log_name: student_solution_kl_reg
answer_log_prob_coeff:
- 1
- 0.01
kl_penalty_reward_coeff:
- 3
- 0.03
normalize_log_prob_fn: null
clip_log_prob: 100000
normalize_kl_fn: null
clip_kl: 100000
reduction_log_prob_fn:
- mean
- min
reduction_kl_fn:
- mean
- max
use_schulman_kl_estimation: false
not_matched_penalty: -1.0
unbias_teacher_log_probs: true
unbias_student_log_probs_temp: 0.7
include_teacher_think_entropy: true
correct_generation_coeff: 0.0
correct_generation_rollouts: 8
student_generation_kwargs: {}
student_generation_check_stategy: ground_truth
formatting_sub_rewards: []
evaluate_refined_solution: false
teacher_reward:
  _target_: trainers.TeacherKLBasedReward
  student_model: null
  teacher_model: null
  tokenizer: null
  answer_log_prob_coeff: ${answer_log_prob_coeff}
  kl_penalty_reward_coeff: ${kl_penalty_reward_coeff}
  normalize_log_prob_fn: ${normalize_log_prob_fn}
  clip_log_prob: ${clip_log_prob}
  normalize_kl_fn: ${normalize_kl_fn}
  clip_kl: ${clip_kl}
  reduction_log_prob_fn: ${reduction_log_prob_fn}
  reduction_kl_fn: ${reduction_kl_fn}
  use_schulman_kl_estimation: ${use_schulman_kl_estimation}
  not_matched_penalty: ${not_matched_penalty}
  unbias_teacher_log_probs: ${unbias_teacher_log_probs}
  unbias_student_log_probs_temp: ${unbias_student_log_probs_temp}
  include_teacher_think_entropy: ${include_teacher_think_entropy}
  correct_generation_coeff: ${correct_generation_coeff}
  correct_generation_rollouts: ${correct_generation_rollouts}
  generation_kwargs: ${student_generation_kwargs}
  generation_check_stategy: ${student_generation_check_stategy}
  formatting_sub_rewards: ${formatting_sub_rewards}
  evaluate_refined_solution: ${evaluate_refined_solution}
reward_fns:
  _target_: hydra_utils.wrap_as_list
  teacher_reward: ${teacher_reward}
logging_prob: 0.1
student_model: Qwen/Qwen3-14B
use_reference_teacher_model: false
student_model_init_kwargs: null
disable_student_offloading: false
do_eval: true
eval_strategy: steps
eval_steps: 2
wandb_entity: llm-compe-2025-kato
log_ctx_name: gr${num_generations}_${max_prompt_length}ctx_${max_completion_length}gen

[2025-08-18 21:11:49,379][__main__][INFO] - Accumulation steps 64 ----
[2025-08-18 21:11:49,499][__main__][INFO] - Configuration:
save_final_model: true
save_strategy: steps
save_steps: 2
push_to_hub: false
tags: null
call_post_training: null
logging_strategy: steps
logging_steps: 1
report_to: wandb
wandb_project: honban_step2_rlt
wandb_group_name: ${data_log_name}/${model_log_name}
wandb_run_name: ${trainer_log_name}
results_dir: /home/Competition2025/P07/shareP07/share_model/step2_rlt
exp_name: ${now:%Y.%m.%d}${now:%H%M%S}
output_dir: ${results_dir}/Qwen3-14B-step2-deepmath103k-bs${train_batch_size}
resume_from: ${output_dir}
seed: 42
model_log_name: qwen3-14b
model_name_or_path: llm-compe-2025-kato/Qwen3-14B-Step1-Bespoke17k-ep1
tokenizer_name_or_path: ${model_name_or_path}
model_args:
  _target_: hydra_utils.trl.ModelConfig
  model_name_or_path: ${model_name_or_path}
  trust_remote_code: true
  use_peft: ${use_peft}
  load_in_4bit: ${load_in_4bit}
  model_revision: main
  torch_dtype: bfloat16
  attn_implementation: flash_attention_2
use_peft: false
load_in_4bit: false
tokenizer:
  _target_: hydra_utils.transformers.AutoTokenizer.from_pretrained
  pretrained_model_name_or_path: ${tokenizer_name_or_path}
  trust_remote_code: true
  padding_side: left
  model_revision: ${model_args.model_revision}
unsafe_tokenizer_loading: false
make_tokenizer_fn:
  _target_: hydra_utils.fix_pad_token
  tokenizer: ${tokenizer}
  model_name: ${model_name_or_path}
  unsafe: ${unsafe_tokenizer_loading}
peft_config:
  _target_: hydra_utils.trl.get_peft_config
  model_args: ${model_args}
data_log_name: stage2_data
dataset_id_or_path: Nishi0923/DeepMath-103K-Bespoke-Filtered-Pilot-5K
dataset_local_directory: ${dataset_id_or_path}
make_dataset_fn:
  dataset_id_or_path: ${dataset_id_or_path}
  dataset_local_directory: ${dataset_local_directory}
  model_name_or_path: ${model_name_or_path}
  _target_: custom_data.sft_data.load_formatted_sft_dataset
  process_line_fn:
    _target_: custom_data.teacher_data.get_process_line_fn
    dataset_id_or_path: ${dataset_id_or_path}
    system_prompt_style: ${system_prompt_style}
    return_student_prompt_info: ${return_student_prompt_info}
    add_text_completions: ${add_text_completions}
  completion_only_training: ${completion_only_training}
  custom_start_of_response: ${custom_start_of_response}
  keep_columns: ${keep_columns}
  add_dataset_indices: ${add_dataset_indices}
dataset_configs:
- all
completion_only_training: false
custom_start_of_response:
  _target_: custom_data.teacher_data.get_teacher_data_mask_delimiter
  system_prompt_style: ${system_prompt_style}
  mask_teacher_answer: ${mask_teacher_answer}
  dataset_id_or_path: ${dataset_id_or_path}
keep_columns: null
add_dataset_indices: false
system_prompt_style: stratos
mask_teacher_answer: true
return_student_prompt_info: true
add_text_completions: false
max_steps: -1
num_train_epochs: 1.0
train_batch_size: 512
per_device_train_batch_size: 1
gradient_accumulation_steps: ???
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  _target_: builtins.dict
  use_reentrant: false
learning_rate: 1.0e-06
weight_decay: 0
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1.0e-08
max_grad_norm: 1.0
lr_scheduler_type: constant
lr_scheduler_kwargs: null
warmup_ratio: 0.03
bf16: true
tf32: true
ddp_timeout: 18000
trainer_log_name: teacher_grpo_rw_${reward_log_name}
trainer_args:
  _target_: trainers.GRPOConfig
  output_dir: ${output_dir}
  max_steps: ${max_steps}
  num_train_epochs: ${num_train_epochs}
  per_device_train_batch_size: ${per_device_train_batch_size}
  gradient_accumulation_steps: ${gradient_accumulation_steps}
  gradient_checkpointing: ${gradient_checkpointing}
  gradient_checkpointing_kwargs: ${gradient_checkpointing_kwargs}
  learning_rate: ${learning_rate}
  weight_decay: ${weight_decay}
  adam_beta1: ${adam_beta1}
  adam_beta2: ${adam_beta2}
  adam_epsilon: ${adam_epsilon}
  max_grad_norm: ${max_grad_norm}
  lr_scheduler_type: ${lr_scheduler_type}
  lr_scheduler_kwargs: ${lr_scheduler_kwargs}
  warmup_ratio: ${warmup_ratio}
  logging_strategy: ${logging_strategy}
  logging_steps: ${logging_steps}
  save_strategy: ${save_strategy}
  save_steps: ${save_steps}
  report_to: ${report_to}
  run_name: ${wandb_run_name}
  bf16: ${bf16}
  tf32: ${tf32}
  seed: ${seed}
  ddp_timeout: ${ddp_timeout}
  model_init_kwargs: ${model_init_kwargs}
  remove_unused_columns: ${remove_unused_columns}
  max_prompt_length: ${max_prompt_length}
  num_generations: ${num_generations}
  max_completion_length: ${max_completion_length}
  shuffle_generation_inputs: ${shuffle_generation_inputs}
  ds3_gather_for_generation: ${ds3_gather_for_generation}
  temperature: ${temperature}
  top_p: ${top_p}
  top_k: ${top_k}
  min_p: ${min_p}
  repetition_penalty: ${repetition_penalty}
  generation_aggregation_steps: ${generation_aggregation_steps}
  use_vllm: ${use_vllm}
  vllm_device: ${vllm_device}
  vllm_gpu_memory_utilization: ${vllm_gpu_memory_utilization}
  vllm_dtype: ${vllm_dtype}
  vllm_max_model_len: ${vllm_max_model_len}
  use_ray: ${use_ray}
  ray_share_training_devices: ${ray_share_training_devices}
  ray_tensor_parallelism: ${ray_tensor_parallelism}
  ray_data_parallelism: ${ray_data_parallelism}
  ray_no_memory_duplication: ${ray_no_memory_duplication}
  enable_prefix_caching: ${enable_prefix_caching}
  enforce_eager: ${enforce_eager}
  vllm_sleep_level: ${vllm_sleep_level}
  use_vllm_server: ${use_vllm_server}
  vllm_host: ${vllm_host}
  vllm_port: ${vllm_port}
  vllm_group_port: ${vllm_group_port}
  num_vllm_clients: ${num_vllm_clients}
  beta: ${beta}
  reward_weights: ${reward_weights}
  sync_ref_model: ${sync_ref_model}
  ref_model_mixup_alpha: ${ref_model_mixup_alpha}
  ref_model_sync_steps: ${ref_model_sync_steps}
  log_completions: ${log_completions}
  save_completions_probability: ${save_completions_probability}
  artificial_epochs: ${artificial_epochs}
  backprop_accumulation_steps: ${backprop_accumulation_steps}
  backprop_accumulation_micro_batch_size: ${backprop_accumulation_micro_batch_size}
  offload_untrained_models: ${offload_untrained_models}
  unbias_log_probabilities: ${unbias_log_probabilities}
  activate_debugging_logs: ${activate_debugging_logs}
  push_to_hub: ${push_to_hub}
trainer:
  _target_: trainers.TeacherGRPOTrainer
  model: ${model_name_or_path}
  args: ${trainer_args}
  peft_config: ${peft_config}
  reward_funcs: ${reward_fns}
  student_model: ${student_model}
  use_reference_teacher_model: ${use_reference_teacher_model}
  student_model_init_kwargs: ${student_model_init_kwargs}
  logging_prob: ${logging_prob}
  disable_student_offloading: ${disable_student_offloading}
artificial_epochs: 1
num_generations: 128
beta: 0.04
model_init_kwargs: null
remove_unused_columns: false
max_prompt_length: 16384
max_completion_length: 16384
shuffle_generation_inputs: true
ds3_gather_for_generation: true
temperature: 0.7
top_p: 1.0
top_k: null
min_p: null
repetition_penalty: 1.0
generation_aggregation_steps: 64
use_vllm: false
vllm_device: auto
vllm_gpu_memory_utilization: 0.9
vllm_dtype: auto
vllm_max_model_len: null
use_ray: false
ray_share_training_devices: false
ray_tensor_parallelism: 1
ray_data_parallelism: null
ray_no_memory_duplication: false
vllm_sleep_level: 0
enable_prefix_caching: false
enforce_eager: true
use_vllm_server: true
vllm_host: osk-gpu70
vllm_port: 8765
vllm_group_port: 51216
num_vllm_clients: 8
reward_weights: null
sync_ref_model: true
ref_model_mixup_alpha: 0.9
ref_model_sync_steps: 64
backprop_accumulation_steps: null
backprop_accumulation_micro_batch_size: null
offload_untrained_models: false
unbias_log_probabilities: true
log_completions: false
save_completions_probability: 0.1
activate_debugging_logs: false
reward_log_name: student_solution_kl_reg
answer_log_prob_coeff:
- 1
- 0.01
kl_penalty_reward_coeff:
- 3
- 0.03
normalize_log_prob_fn: null
clip_log_prob: 100000
normalize_kl_fn: null
clip_kl: 100000
reduction_log_prob_fn:
- mean
- min
reduction_kl_fn:
- mean
- max
use_schulman_kl_estimation: false
not_matched_penalty: -1.0
unbias_teacher_log_probs: true
unbias_student_log_probs_temp: 0.7
include_teacher_think_entropy: true
correct_generation_coeff: 0.0
correct_generation_rollouts: 8
student_generation_kwargs: {}
student_generation_check_stategy: ground_truth
formatting_sub_rewards: []
evaluate_refined_solution: false
teacher_reward:
  _target_: trainers.TeacherKLBasedReward
  student_model: null
  teacher_model: null
  tokenizer: null
  answer_log_prob_coeff: ${answer_log_prob_coeff}
  kl_penalty_reward_coeff: ${kl_penalty_reward_coeff}
  normalize_log_prob_fn: ${normalize_log_prob_fn}
  clip_log_prob: ${clip_log_prob}
  normalize_kl_fn: ${normalize_kl_fn}
  clip_kl: ${clip_kl}
  reduction_log_prob_fn: ${reduction_log_prob_fn}
  reduction_kl_fn: ${reduction_kl_fn}
  use_schulman_kl_estimation: ${use_schulman_kl_estimation}
  not_matched_penalty: ${not_matched_penalty}
  unbias_teacher_log_probs: ${unbias_teacher_log_probs}
  unbias_student_log_probs_temp: ${unbias_student_log_probs_temp}
  include_teacher_think_entropy: ${include_teacher_think_entropy}
  correct_generation_coeff: ${correct_generation_coeff}
  correct_generation_rollouts: ${correct_generation_rollouts}
  generation_kwargs: ${student_generation_kwargs}
  generation_check_stategy: ${student_generation_check_stategy}
  formatting_sub_rewards: ${formatting_sub_rewards}
  evaluate_refined_solution: ${evaluate_refined_solution}
reward_fns:
  _target_: hydra_utils.wrap_as_list
  teacher_reward: ${teacher_reward}
logging_prob: 0.1
student_model: Qwen/Qwen3-14B
use_reference_teacher_model: false
student_model_init_kwargs: null
disable_student_offloading: false
do_eval: true
eval_strategy: steps
eval_steps: 2
wandb_entity: llm-compe-2025-kato
log_ctx_name: gr${num_generations}_${max_prompt_length}ctx_${max_completion_length}gen

[2025-08-18 21:11:49,500][__main__][INFO] - Accumulation steps 64 ----
[2025-08-18 21:11:49,545][__main__][INFO] - Configuration:
save_final_model: true
save_strategy: steps
save_steps: 2
push_to_hub: false
tags: null
call_post_training: null
logging_strategy: steps
logging_steps: 1
report_to: wandb
wandb_project: honban_step2_rlt
wandb_group_name: ${data_log_name}/${model_log_name}
wandb_run_name: ${trainer_log_name}
results_dir: /home/Competition2025/P07/shareP07/share_model/step2_rlt
exp_name: ${now:%Y.%m.%d}${now:%H%M%S}
output_dir: ${results_dir}/Qwen3-14B-step2-deepmath103k-bs${train_batch_size}
resume_from: ${output_dir}
seed: 42
model_log_name: qwen3-14b
model_name_or_path: llm-compe-2025-kato/Qwen3-14B-Step1-Bespoke17k-ep1
tokenizer_name_or_path: ${model_name_or_path}
model_args:
  _target_: hydra_utils.trl.ModelConfig
  model_name_or_path: ${model_name_or_path}
  trust_remote_code: true
  use_peft: ${use_peft}
  load_in_4bit: ${load_in_4bit}
  model_revision: main
  torch_dtype: bfloat16
  attn_implementation: flash_attention_2
use_peft: false
load_in_4bit: false
tokenizer:
  _target_: hydra_utils.transformers.AutoTokenizer.from_pretrained
  pretrained_model_name_or_path: ${tokenizer_name_or_path}
  trust_remote_code: true
  padding_side: left
  model_revision: ${model_args.model_revision}
unsafe_tokenizer_loading: false
make_tokenizer_fn:
  _target_: hydra_utils.fix_pad_token
  tokenizer: ${tokenizer}
  model_name: ${model_name_or_path}
  unsafe: ${unsafe_tokenizer_loading}
peft_config:
  _target_: hydra_utils.trl.get_peft_config
  model_args: ${model_args}
data_log_name: stage2_data
dataset_id_or_path: Nishi0923/DeepMath-103K-Bespoke-Filtered-Pilot-5K
dataset_local_directory: ${dataset_id_or_path}
make_dataset_fn:
  dataset_id_or_path: ${dataset_id_or_path}
  dataset_local_directory: ${dataset_local_directory}
  model_name_or_path: ${model_name_or_path}
  _target_: custom_data.sft_data.load_formatted_sft_dataset
  process_line_fn:
    _target_: custom_data.teacher_data.get_process_line_fn
    dataset_id_or_path: ${dataset_id_or_path}
    system_prompt_style: ${system_prompt_style}
    return_student_prompt_info: ${return_student_prompt_info}
    add_text_completions: ${add_text_completions}
  completion_only_training: ${completion_only_training}
  custom_start_of_response: ${custom_start_of_response}
  keep_columns: ${keep_columns}
  add_dataset_indices: ${add_dataset_indices}
dataset_configs:
- all
completion_only_training: false
custom_start_of_response:
  _target_: custom_data.teacher_data.get_teacher_data_mask_delimiter
  system_prompt_style: ${system_prompt_style}
  mask_teacher_answer: ${mask_teacher_answer}
  dataset_id_or_path: ${dataset_id_or_path}
keep_columns: null
add_dataset_indices: false
system_prompt_style: stratos
mask_teacher_answer: true
return_student_prompt_info: true
add_text_completions: false
max_steps: -1
num_train_epochs: 1.0
train_batch_size: 512
per_device_train_batch_size: 1
gradient_accumulation_steps: ???
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  _target_: builtins.dict
  use_reentrant: false
learning_rate: 1.0e-06
weight_decay: 0
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1.0e-08
max_grad_norm: 1.0
lr_scheduler_type: constant
lr_scheduler_kwargs: null
warmup_ratio: 0.03
bf16: true
tf32: true
ddp_timeout: 18000
trainer_log_name: teacher_grpo_rw_${reward_log_name}
trainer_args:
  _target_: trainers.GRPOConfig
  output_dir: ${output_dir}
  max_steps: ${max_steps}
  num_train_epochs: ${num_train_epochs}
  per_device_train_batch_size: ${per_device_train_batch_size}
  gradient_accumulation_steps: ${gradient_accumulation_steps}
  gradient_checkpointing: ${gradient_checkpointing}
  gradient_checkpointing_kwargs: ${gradient_checkpointing_kwargs}
  learning_rate: ${learning_rate}
  weight_decay: ${weight_decay}
  adam_beta1: ${adam_beta1}
  adam_beta2: ${adam_beta2}
  adam_epsilon: ${adam_epsilon}
  max_grad_norm: ${max_grad_norm}
  lr_scheduler_type: ${lr_scheduler_type}
  lr_scheduler_kwargs: ${lr_scheduler_kwargs}
  warmup_ratio: ${warmup_ratio}
  logging_strategy: ${logging_strategy}
  logging_steps: ${logging_steps}
  save_strategy: ${save_strategy}
  save_steps: ${save_steps}
  report_to: ${report_to}
  run_name: ${wandb_run_name}
  bf16: ${bf16}
  tf32: ${tf32}
  seed: ${seed}
  ddp_timeout: ${ddp_timeout}
  model_init_kwargs: ${model_init_kwargs}
  remove_unused_columns: ${remove_unused_columns}
  max_prompt_length: ${max_prompt_length}
  num_generations: ${num_generations}
  max_completion_length: ${max_completion_length}
  shuffle_generation_inputs: ${shuffle_generation_inputs}
  ds3_gather_for_generation: ${ds3_gather_for_generation}
  temperature: ${temperature}
  top_p: ${top_p}
  top_k: ${top_k}
  min_p: ${min_p}
  repetition_penalty: ${repetition_penalty}
  generation_aggregation_steps: ${generation_aggregation_steps}
  use_vllm: ${use_vllm}
  vllm_device: ${vllm_device}
  vllm_gpu_memory_utilization: ${vllm_gpu_memory_utilization}
  vllm_dtype: ${vllm_dtype}
  vllm_max_model_len: ${vllm_max_model_len}
  use_ray: ${use_ray}
  ray_share_training_devices: ${ray_share_training_devices}
  ray_tensor_parallelism: ${ray_tensor_parallelism}
  ray_data_parallelism: ${ray_data_parallelism}
  ray_no_memory_duplication: ${ray_no_memory_duplication}
  enable_prefix_caching: ${enable_prefix_caching}
  enforce_eager: ${enforce_eager}
  vllm_sleep_level: ${vllm_sleep_level}
  use_vllm_server: ${use_vllm_server}
  vllm_host: ${vllm_host}
  vllm_port: ${vllm_port}
  vllm_group_port: ${vllm_group_port}
  num_vllm_clients: ${num_vllm_clients}
  beta: ${beta}
  reward_weights: ${reward_weights}
  sync_ref_model: ${sync_ref_model}
  ref_model_mixup_alpha: ${ref_model_mixup_alpha}
  ref_model_sync_steps: ${ref_model_sync_steps}
  log_completions: ${log_completions}
  save_completions_probability: ${save_completions_probability}
  artificial_epochs: ${artificial_epochs}
  backprop_accumulation_steps: ${backprop_accumulation_steps}
  backprop_accumulation_micro_batch_size: ${backprop_accumulation_micro_batch_size}
  offload_untrained_models: ${offload_untrained_models}
  unbias_log_probabilities: ${unbias_log_probabilities}
  activate_debugging_logs: ${activate_debugging_logs}
  push_to_hub: ${push_to_hub}
trainer:
  _target_: trainers.TeacherGRPOTrainer
  model: ${model_name_or_path}
  args: ${trainer_args}
  peft_config: ${peft_config}
  reward_funcs: ${reward_fns}
  student_model: ${student_model}
  use_reference_teacher_model: ${use_reference_teacher_model}
  student_model_init_kwargs: ${student_model_init_kwargs}
  logging_prob: ${logging_prob}
  disable_student_offloading: ${disable_student_offloading}
artificial_epochs: 1
num_generations: 128
beta: 0.04
model_init_kwargs: null
remove_unused_columns: false
max_prompt_length: 16384
max_completion_length: 16384
shuffle_generation_inputs: true
ds3_gather_for_generation: true
temperature: 0.7
top_p: 1.0
top_k: null
min_p: null
repetition_penalty: 1.0
generation_aggregation_steps: 64
use_vllm: false
vllm_device: auto
vllm_gpu_memory_utilization: 0.9
vllm_dtype: auto
vllm_max_model_len: null
use_ray: false
ray_share_training_devices: false
ray_tensor_parallelism: 1
ray_data_parallelism: null
ray_no_memory_duplication: false
vllm_sleep_level: 0
enable_prefix_caching: false
enforce_eager: true
use_vllm_server: true
vllm_host: osk-gpu70
vllm_port: 8765
vllm_group_port: 51216
num_vllm_clients: 8
reward_weights: null
sync_ref_model: true
ref_model_mixup_alpha: 0.9
ref_model_sync_steps: 64
backprop_accumulation_steps: null
backprop_accumulation_micro_batch_size: null
offload_untrained_models: false
unbias_log_probabilities: true
log_completions: false
save_completions_probability: 0.1
activate_debugging_logs: false
reward_log_name: student_solution_kl_reg
answer_log_prob_coeff:
- 1
- 0.01
kl_penalty_reward_coeff:
- 3
- 0.03
normalize_log_prob_fn: null
clip_log_prob: 100000
normalize_kl_fn: null
clip_kl: 100000
reduction_log_prob_fn:
- mean
- min
reduction_kl_fn:
- mean
- max
use_schulman_kl_estimation: false
not_matched_penalty: -1.0
unbias_teacher_log_probs: true
unbias_student_log_probs_temp: 0.7
include_teacher_think_entropy: true
correct_generation_coeff: 0.0
correct_generation_rollouts: 8
student_generation_kwargs: {}
student_generation_check_stategy: ground_truth
formatting_sub_rewards: []
evaluate_refined_solution: false
teacher_reward:
  _target_: trainers.TeacherKLBasedReward
  student_model: null
  teacher_model: null
  tokenizer: null
  answer_log_prob_coeff: ${answer_log_prob_coeff}
  kl_penalty_reward_coeff: ${kl_penalty_reward_coeff}
  normalize_log_prob_fn: ${normalize_log_prob_fn}
  clip_log_prob: ${clip_log_prob}
  normalize_kl_fn: ${normalize_kl_fn}
  clip_kl: ${clip_kl}
  reduction_log_prob_fn: ${reduction_log_prob_fn}
  reduction_kl_fn: ${reduction_kl_fn}
  use_schulman_kl_estimation: ${use_schulman_kl_estimation}
  not_matched_penalty: ${not_matched_penalty}
  unbias_teacher_log_probs: ${unbias_teacher_log_probs}
  unbias_student_log_probs_temp: ${unbias_student_log_probs_temp}
  include_teacher_think_entropy: ${include_teacher_think_entropy}
  correct_generation_coeff: ${correct_generation_coeff}
  correct_generation_rollouts: ${correct_generation_rollouts}
  generation_kwargs: ${student_generation_kwargs}
  generation_check_stategy: ${student_generation_check_stategy}
  formatting_sub_rewards: ${formatting_sub_rewards}
  evaluate_refined_solution: ${evaluate_refined_solution}
reward_fns:
  _target_: hydra_utils.wrap_as_list
  teacher_reward: ${teacher_reward}
logging_prob: 0.1
student_model: Qwen/Qwen3-14B
use_reference_teacher_model: false
student_model_init_kwargs: null
disable_student_offloading: false
do_eval: true
eval_strategy: steps
eval_steps: 2
wandb_entity: llm-compe-2025-kato
log_ctx_name: gr${num_generations}_${max_prompt_length}ctx_${max_completion_length}gen

[2025-08-18 21:11:49,551][__main__][INFO] - Accumulation steps 64 ----
[2025-08-18 21:11:49,956][__main__][INFO] - Configuration:
save_final_model: true
save_strategy: steps
save_steps: 2
push_to_hub: false
tags: null
call_post_training: null
logging_strategy: steps
logging_steps: 1
report_to: wandb
wandb_project: honban_step2_rlt
wandb_group_name: ${data_log_name}/${model_log_name}
wandb_run_name: ${trainer_log_name}
results_dir: /home/Competition2025/P07/shareP07/share_model/step2_rlt
exp_name: ${now:%Y.%m.%d}${now:%H%M%S}
output_dir: ${results_dir}/Qwen3-14B-step2-deepmath103k-bs${train_batch_size}
resume_from: ${output_dir}
seed: 42
model_log_name: qwen3-14b
model_name_or_path: llm-compe-2025-kato/Qwen3-14B-Step1-Bespoke17k-ep1
tokenizer_name_or_path: ${model_name_or_path}
model_args:
  _target_: hydra_utils.trl.ModelConfig
  model_name_or_path: ${model_name_or_path}
  trust_remote_code: true
  use_peft: ${use_peft}
  load_in_4bit: ${load_in_4bit}
  model_revision: main
  torch_dtype: bfloat16
  attn_implementation: flash_attention_2
use_peft: false
load_in_4bit: false
tokenizer:
  _target_: hydra_utils.transformers.AutoTokenizer.from_pretrained
  pretrained_model_name_or_path: ${tokenizer_name_or_path}
  trust_remote_code: true
  padding_side: left
  model_revision: ${model_args.model_revision}
unsafe_tokenizer_loading: false
make_tokenizer_fn:
  _target_: hydra_utils.fix_pad_token
  tokenizer: ${tokenizer}
  model_name: ${model_name_or_path}
  unsafe: ${unsafe_tokenizer_loading}
peft_config:
  _target_: hydra_utils.trl.get_peft_config
  model_args: ${model_args}
data_log_name: stage2_data
dataset_id_or_path: Nishi0923/DeepMath-103K-Bespoke-Filtered-Pilot-5K
dataset_local_directory: ${dataset_id_or_path}
make_dataset_fn:
  dataset_id_or_path: ${dataset_id_or_path}
  dataset_local_directory: ${dataset_local_directory}
  model_name_or_path: ${model_name_or_path}
  _target_: custom_data.sft_data.load_formatted_sft_dataset
  process_line_fn:
    _target_: custom_data.teacher_data.get_process_line_fn
    dataset_id_or_path: ${dataset_id_or_path}
    system_prompt_style: ${system_prompt_style}
    return_student_prompt_info: ${return_student_prompt_info}
    add_text_completions: ${add_text_completions}
  completion_only_training: ${completion_only_training}
  custom_start_of_response: ${custom_start_of_response}
  keep_columns: ${keep_columns}
  add_dataset_indices: ${add_dataset_indices}
dataset_configs:
- all
completion_only_training: false
custom_start_of_response:
  _target_: custom_data.teacher_data.get_teacher_data_mask_delimiter
  system_prompt_style: ${system_prompt_style}
  mask_teacher_answer: ${mask_teacher_answer}
  dataset_id_or_path: ${dataset_id_or_path}
keep_columns: null
add_dataset_indices: false
system_prompt_style: stratos
mask_teacher_answer: true
return_student_prompt_info: true
add_text_completions: false
max_steps: -1
num_train_epochs: 1.0
train_batch_size: 512
per_device_train_batch_size: 1
gradient_accumulation_steps: ???
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  _target_: builtins.dict
  use_reentrant: false
learning_rate: 1.0e-06
weight_decay: 0
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1.0e-08
max_grad_norm: 1.0
lr_scheduler_type: constant
lr_scheduler_kwargs: null
warmup_ratio: 0.03
bf16: true
tf32: true
ddp_timeout: 18000
trainer_log_name: teacher_grpo_rw_${reward_log_name}
trainer_args:
  _target_: trainers.GRPOConfig
  output_dir: ${output_dir}
  max_steps: ${max_steps}
  num_train_epochs: ${num_train_epochs}
  per_device_train_batch_size: ${per_device_train_batch_size}
  gradient_accumulation_steps: ${gradient_accumulation_steps}
  gradient_checkpointing: ${gradient_checkpointing}
  gradient_checkpointing_kwargs: ${gradient_checkpointing_kwargs}
  learning_rate: ${learning_rate}
  weight_decay: ${weight_decay}
  adam_beta1: ${adam_beta1}
  adam_beta2: ${adam_beta2}
  adam_epsilon: ${adam_epsilon}
  max_grad_norm: ${max_grad_norm}
  lr_scheduler_type: ${lr_scheduler_type}
  lr_scheduler_kwargs: ${lr_scheduler_kwargs}
  warmup_ratio: ${warmup_ratio}
  logging_strategy: ${logging_strategy}
  logging_steps: ${logging_steps}
  save_strategy: ${save_strategy}
  save_steps: ${save_steps}
  report_to: ${report_to}
  run_name: ${wandb_run_name}
  bf16: ${bf16}
  tf32: ${tf32}
  seed: ${seed}
  ddp_timeout: ${ddp_timeout}
  model_init_kwargs: ${model_init_kwargs}
  remove_unused_columns: ${remove_unused_columns}
  max_prompt_length: ${max_prompt_length}
  num_generations: ${num_generations}
  max_completion_length: ${max_completion_length}
  shuffle_generation_inputs: ${shuffle_generation_inputs}
  ds3_gather_for_generation: ${ds3_gather_for_generation}
  temperature: ${temperature}
  top_p: ${top_p}
  top_k: ${top_k}
  min_p: ${min_p}
  repetition_penalty: ${repetition_penalty}
  generation_aggregation_steps: ${generation_aggregation_steps}
  use_vllm: ${use_vllm}
  vllm_device: ${vllm_device}
  vllm_gpu_memory_utilization: ${vllm_gpu_memory_utilization}
  vllm_dtype: ${vllm_dtype}
  vllm_max_model_len: ${vllm_max_model_len}
  use_ray: ${use_ray}
  ray_share_training_devices: ${ray_share_training_devices}
  ray_tensor_parallelism: ${ray_tensor_parallelism}
  ray_data_parallelism: ${ray_data_parallelism}
  ray_no_memory_duplication: ${ray_no_memory_duplication}
  enable_prefix_caching: ${enable_prefix_caching}
  enforce_eager: ${enforce_eager}
  vllm_sleep_level: ${vllm_sleep_level}
  use_vllm_server: ${use_vllm_server}
  vllm_host: ${vllm_host}
  vllm_port: ${vllm_port}
  vllm_group_port: ${vllm_group_port}
  num_vllm_clients: ${num_vllm_clients}
  beta: ${beta}
  reward_weights: ${reward_weights}
  sync_ref_model: ${sync_ref_model}
  ref_model_mixup_alpha: ${ref_model_mixup_alpha}
  ref_model_sync_steps: ${ref_model_sync_steps}
  log_completions: ${log_completions}
  save_completions_probability: ${save_completions_probability}
  artificial_epochs: ${artificial_epochs}
  backprop_accumulation_steps: ${backprop_accumulation_steps}
  backprop_accumulation_micro_batch_size: ${backprop_accumulation_micro_batch_size}
  offload_untrained_models: ${offload_untrained_models}
  unbias_log_probabilities: ${unbias_log_probabilities}
  activate_debugging_logs: ${activate_debugging_logs}
  push_to_hub: ${push_to_hub}
trainer:
  _target_: trainers.TeacherGRPOTrainer
  model: ${model_name_or_path}
  args: ${trainer_args}
  peft_config: ${peft_config}
  reward_funcs: ${reward_fns}
  student_model: ${student_model}
  use_reference_teacher_model: ${use_reference_teacher_model}
  student_model_init_kwargs: ${student_model_init_kwargs}
  logging_prob: ${logging_prob}
  disable_student_offloading: ${disable_student_offloading}
artificial_epochs: 1
num_generations: 128
beta: 0.04
model_init_kwargs: null
remove_unused_columns: false
max_prompt_length: 16384
max_completion_length: 16384
shuffle_generation_inputs: true
ds3_gather_for_generation: true
temperature: 0.7
top_p: 1.0
top_k: null
min_p: null
repetition_penalty: 1.0
generation_aggregation_steps: 64
use_vllm: false
vllm_device: auto
vllm_gpu_memory_utilization: 0.9
vllm_dtype: auto
vllm_max_model_len: null
use_ray: false
ray_share_training_devices: false
ray_tensor_parallelism: 1
ray_data_parallelism: null
ray_no_memory_duplication: false
vllm_sleep_level: 0
enable_prefix_caching: false
enforce_eager: true
use_vllm_server: true
vllm_host: osk-gpu70
vllm_port: 8765
vllm_group_port: 51216
num_vllm_clients: 8
reward_weights: null
sync_ref_model: true
ref_model_mixup_alpha: 0.9
ref_model_sync_steps: 64
backprop_accumulation_steps: null
backprop_accumulation_micro_batch_size: null
offload_untrained_models: false
unbias_log_probabilities: true
log_completions: false
save_completions_probability: 0.1
activate_debugging_logs: false
reward_log_name: student_solution_kl_reg
answer_log_prob_coeff:
- 1
- 0.01
kl_penalty_reward_coeff:
- 3
- 0.03
normalize_log_prob_fn: null
clip_log_prob: 100000
normalize_kl_fn: null
clip_kl: 100000
reduction_log_prob_fn:
- mean
- min
reduction_kl_fn:
- mean
- max
use_schulman_kl_estimation: false
not_matched_penalty: -1.0
unbias_teacher_log_probs: true
unbias_student_log_probs_temp: 0.7
include_teacher_think_entropy: true
correct_generation_coeff: 0.0
correct_generation_rollouts: 8
student_generation_kwargs: {}
student_generation_check_stategy: ground_truth
formatting_sub_rewards: []
evaluate_refined_solution: false
teacher_reward:
  _target_: trainers.TeacherKLBasedReward
  student_model: null
  teacher_model: null
  tokenizer: null
  answer_log_prob_coeff: ${answer_log_prob_coeff}
  kl_penalty_reward_coeff: ${kl_penalty_reward_coeff}
  normalize_log_prob_fn: ${normalize_log_prob_fn}
  clip_log_prob: ${clip_log_prob}
  normalize_kl_fn: ${normalize_kl_fn}
  clip_kl: ${clip_kl}
  reduction_log_prob_fn: ${reduction_log_prob_fn}
  reduction_kl_fn: ${reduction_kl_fn}
  use_schulman_kl_estimation: ${use_schulman_kl_estimation}
  not_matched_penalty: ${not_matched_penalty}
  unbias_teacher_log_probs: ${unbias_teacher_log_probs}
  unbias_student_log_probs_temp: ${unbias_student_log_probs_temp}
  include_teacher_think_entropy: ${include_teacher_think_entropy}
  correct_generation_coeff: ${correct_generation_coeff}
  correct_generation_rollouts: ${correct_generation_rollouts}
  generation_kwargs: ${student_generation_kwargs}
  generation_check_stategy: ${student_generation_check_stategy}
  formatting_sub_rewards: ${formatting_sub_rewards}
  evaluate_refined_solution: ${evaluate_refined_solution}
reward_fns:
  _target_: hydra_utils.wrap_as_list
  teacher_reward: ${teacher_reward}
logging_prob: 0.1
student_model: Qwen/Qwen3-14B
use_reference_teacher_model: false
student_model_init_kwargs: null
disable_student_offloading: false
do_eval: true
eval_strategy: steps
eval_steps: 2
wandb_entity: llm-compe-2025-kato
log_ctx_name: gr${num_generations}_${max_prompt_length}ctx_${max_completion_length}gen

[2025-08-18 21:11:49,971][__main__][INFO] - Accumulation steps 64 ----
[2025-08-18 21:11:50,446][datasets][INFO] - PyTorch version 2.6.0+cu124 available.
[2025-08-18 21:11:51,248][datasets][INFO] - PyTorch version 2.6.0+cu124 available.
[2025-08-18 21:11:51,812][datasets][INFO] - PyTorch version 2.6.0+cu124 available.
[2025-08-18 21:11:51,819][datasets][INFO] - PyTorch version 2.6.0+cu124 available.
[2025-08-18 21:11:51,935][datasets][INFO] - PyTorch version 2.6.0+cu124 available.
[2025-08-18 21:11:52,002][datasets][INFO] - PyTorch version 2.6.0+cu124 available.
[2025-08-18 21:11:52,028][datasets][INFO] - PyTorch version 2.6.0+cu124 available.
Creating data for format Nishi0923/DeepMath-103K-Bespoke-Filtered-Pilot-5K
Creating data for format Nishi0923/DeepMath-103K-Bespoke-Filtered-Pilot-5K
Creating data for format Nishi0923/DeepMath-103K-Bespoke-Filtered-Pilot-5K
Creating data for format Nishi0923/DeepMath-103K-Bespoke-Filtered-Pilot-5K
Creating data for format Nishi0923/DeepMath-103K-Bespoke-Filtered-Pilot-5K
Creating data for format Nishi0923/DeepMath-103K-Bespoke-Filtered-Pilot-5K
Creating data for format Nishi0923/DeepMath-103K-Bespoke-Filtered-Pilot-5K
wandb: Currently logged in as: junkato (llm-compe-2025-kato) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /home/Competition2025/P07/shareP07/jun_kato2/RLT/step2_rlt/wandb/run-20250818_211155-2mjw3842
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run teacher_grpo_rw_student_solution_kl_reg
wandb: ⭐️ View project at https://wandb.ai/llm-compe-2025-kato/honban_step2_rlt
wandb: 🚀 View run at https://wandb.ai/llm-compe-2025-kato/honban_step2_rlt/runs/2mjw3842
[2025-08-18 21:11:57,495][datasets][INFO] - PyTorch version 2.6.0+cu124 available.
Creating data for format Nishi0923/DeepMath-103K-Bespoke-Filtered-Pilot-5K
Generating train split:   0%|          | 0/5643 [00:00<?, ? examples/s]Generating train split:  18%|█▊        | 1000/5643 [00:00<00:00, 8373.10 examples/s]Generating train split:  68%|██████▊   | 3822/5643 [00:00<00:00, 15675.23 examples/s]Generating train split: 100%|██████████| 5643/5643 [00:00<00:00, 19036.51 examples/s]
not loading from cache
not loading from cache
not loading from cache
not loading from cache
not loading from cache
not loading from cache
not loading from cache
Map:   0%|          | 0/5643 [00:00<?, ? examples/s]Map:   0%|          | 0/5643 [00:00<?, ? examples/s]Map:   1%|          | 31/5643 [00:00<00:24, 227.12 examples/s]Map:   0%|          | 0/5643 [00:00<?, ? examples/s]Map:   0%|          | 1/5643 [00:00<13:08,  7.15 examples/s]Map:   1%|▏         | 84/5643 [00:00<00:16, 346.61 examples/s]Map:   0%|          | 0/5643 [00:00<?, ? examples/s]Map:   0%|          | 0/5643 [00:00<?, ? examples/s]Map:   0%|          | 0/5643 [00:00<?, ? examples/s]Map:   0%|          | 1/5643 [00:00<12:10,  7.73 examples/s]Map:   0%|          | 0/5643 [00:00<?, ? examples/s]Map:   1%|          | 48/5643 [00:00<00:23, 236.53 examples/s]Map:   2%|▏         | 124/5643 [00:00<00:15, 360.23 examples/s]Map:   0%|          | 1/5643 [00:00<10:21,  9.08 examples/s]Map:   0%|          | 1/5643 [00:00<10:21,  9.08 examples/s]Map:   0%|          | 1/5643 [00:00<11:24,  8.25 examples/s]Map:   1%|          | 58/5643 [00:00<00:20, 274.89 examples/s]Map:   2%|▏         | 90/5643 [00:00<00:18, 306.17 examples/s]Map:   0%|          | 1/5643 [00:00<11:22,  8.27 examples/s]Map:   3%|▎         | 164/5643 [00:00<00:15, 364.29 examples/s]Map:   1%|          | 59/5643 [00:00<00:17, 323.20 examples/s]Map:   1%|          | 42/5643 [00:00<00:24, 229.30 examples/s]Map:   1%|          | 45/5643 [00:00<00:24, 231.69 examples/s]Map:   2%|▏         | 102/5643 [00:00<00:16, 329.61 examples/s]Map:   2%|▏         | 141/5643 [00:00<00:14, 375.48 examples/s]Map:   1%|          | 56/5643 [00:00<00:19, 287.92 examples/s]Map:   4%|▎         | 211/5643 [00:00<00:13, 392.53 examples/s]Map:   2%|▏         | 109/5643 [00:00<00:13, 395.67 examples/s]Map:   3%|▎         | 181/5643 [00:00<00:14, 383.10 examples/s]Map:   2%|▏         | 95/5643 [00:00<00:16, 332.13 examples/s]Map:   2%|▏         | 100/5643 [00:00<00:16, 340.59 examples/s]Map:   3%|▎         | 144/5643 [00:00<00:15, 349.90 examples/s]Map:   2%|▏         | 102/5643 [00:00<00:15, 355.84 examples/s]Map:   4%|▍         | 252/5643 [00:00<00:13, 391.32 examples/s]Map:   3%|▎         | 157/5643 [00:00<00:13, 413.45 examples/s]Map:   2%|▏         | 139/5643 [00:00<00:15, 362.78 examples/s]Map:   3%|▎         | 190/5643 [00:00<00:14, 381.08 examples/s]Map:   3%|▎         | 143/5643 [00:00<00:15, 360.50 examples/s]Map:   3%|▎         | 143/5643 [00:00<00:15, 348.90 examples/s]Map:   4%|▍         | 243/5643 [00:00<00:13, 401.89 examples/s]Map:   5%|▌         | 292/5643 [00:00<00:14, 381.10 examples/s]Map:   3%|▎         | 181/5643 [00:00<00:15, 358.52 examples/s]Map:   3%|▎         | 182/5643 [00:00<00:15, 355.15 examples/s]Map:   4%|▎         | 209/5643 [00:00<00:13, 395.41 examples/s]Map:   4%|▍         | 242/5643 [00:00<00:13, 391.46 examples/s]Map:   3%|▎         | 190/5643 [00:00<00:14, 374.86 examples/s]not loading from cache
Map:   6%|▌         | 337/5643 [00:00<00:13, 384.56 examples/s]Map:   5%|▌         | 295/5643 [00:00<00:14, 361.47 examples/s]Map:   4%|▍         | 251/5643 [00:00<00:13, 390.23 examples/s]Map:   4%|▍         | 226/5643 [00:00<00:14, 361.57 examples/s]Map:   5%|▌         | 283/5643 [00:00<00:13, 384.06 examples/s]Map:   4%|▍         | 233/5643 [00:00<00:14, 370.91 examples/s]Map:   4%|▍         | 238/5643 [00:00<00:13, 400.66 examples/s]Map:   7%|▋         | 377/5643 [00:01<00:13, 376.16 examples/s]Map:   6%|▌         | 342/5643 [00:00<00:14, 376.20 examples/s]Map:   5%|▌         | 292/5643 [00:00<00:14, 380.76 examples/s]Map:   5%|▍         | 264/5643 [00:00<00:15, 352.23 examples/s]Map:   6%|▌         | 330/5643 [00:00<00:13, 386.66 examples/s]Map:   5%|▍         | 271/5643 [00:00<00:14, 358.65 examples/s]Map:   7%|▋         | 415/5643 [00:01<00:14, 367.75 examples/s]Map:   5%|▌         | 296/5643 [00:00<00:14, 376.20 examples/s]Map:   6%|▌         | 338/5643 [00:00<00:13, 388.45 examples/s]Map:   7%|▋         | 369/5643 [00:01<00:13, 379.59 examples/s]Map:   5%|▌         | 310/5643 [00:00<00:14, 368.55 examples/s]Map:   6%|▌         | 313/5643 [00:00<00:14, 363.39 examples/s]Map:   7%|▋         | 398/5643 [00:01<00:14, 362.53 examples/s]Map:   6%|▌         | 346/5643 [00:00<00:13, 402.70 examples/s]Map:   0%|          | 0/5643 [00:00<?, ? examples/s]Map:   6%|▌         | 352/5643 [00:01<00:13, 382.24 examples/s]Map:   8%|▊         | 471/5643 [00:01<00:14, 353.95 examples/s]Map:   6%|▋         | 354/5643 [00:01<00:14, 364.68 examples/s]Map:   7%|▋         | 411/5643 [00:01<00:14, 363.88 examples/s]Map:   8%|▊         | 440/5643 [00:01<00:14, 363.50 examples/s]Map:   7%|▋         | 395/5643 [00:01<00:14, 370.54 examples/s]Map:   0%|          | 1/5643 [00:00<10:47,  8.71 examples/s]Map:   7%|▋         | 393/5643 [00:01<00:14, 372.83 examples/s]Map:   7%|▋         | 395/5643 [00:01<00:14, 363.31 examples/s]Map:   8%|▊         | 454/5643 [00:01<00:14, 367.78 examples/s]Map:   9%|▊         | 481/5643 [00:01<00:14, 360.44 examples/s]Map:   9%|▉         | 523/5643 [00:01<00:14, 349.97 examples/s]Map:   8%|▊         | 439/5643 [00:01<00:14, 371.52 examples/s]Map:   7%|▋         | 401/5643 [00:01<00:15, 334.30 examples/s]Map:   1%|          | 45/5643 [00:00<00:24, 226.67 examples/s]Map:   8%|▊         | 439/5643 [00:01<00:13, 372.38 examples/s]Map:   8%|▊         | 437/5643 [00:01<00:14, 365.39 examples/s]Map:   9%|▊         | 493/5643 [00:01<00:13, 369.61 examples/s]Map:  10%|█         | 566/5643 [00:01<00:14, 356.37 examples/s]Map:   8%|▊         | 443/5643 [00:01<00:15, 335.97 examples/s]Map:   9%|▉         | 530/5643 [00:01<00:15, 333.99 examples/s]Map:   9%|▉         | 495/5643 [00:01<00:14, 362.77 examples/s]Map:   2%|▏         | 87/5643 [00:00<00:20, 277.50 examples/s]Map:   8%|▊         | 474/5643 [00:01<00:15, 342.33 examples/s]Map:  11%|█         | 614/5643 [00:01<00:13, 374.72 examples/s]Map:   9%|▉         | 495/5643 [00:01<00:14, 356.57 examples/s]Map:   9%|▊         | 484/5643 [00:01<00:15, 343.78 examples/s]Map:  10%|▉         | 547/5643 [00:01<00:14, 343.52 examples/s]Map:  10%|█         | 571/5643 [00:01<00:14, 339.31 examples/s]Map:   2%|▏         | 133/5643 [00:00<00:17, 323.89 examples/s]Map:   9%|▉         | 536/5643 [00:01<00:14, 348.32 examples/s]Map:   9%|▉         | 513/5643 [00:01<00:14, 348.84 examples/s]Map:  12%|█▏        | 653/5643 [00:01<00:13, 365.92 examples/s]Map:   9%|▉         | 533/5643 [00:01<00:14, 350.25 examples/s]Map:  10%|█         | 588/5643 [00:01<00:14, 351.21 examples/s]Map:   9%|▉         | 523/5643 [00:01<00:15, 336.11 examples/s]Map:  11%|█         | 620/5643 [00:01<00:14, 352.04 examples/s]Map:  10%|█         | 575/5643 [00:01<00:14, 351.49 examples/s]Map:   3%|▎         | 174/5643 [00:00<00:16, 334.57 examples/s]Map:  10%|▉         | 552/5643 [00:01<00:15, 338.04 examples/s]Map:  12%|█▏        | 692/5643 [00:01<00:13, 364.59 examples/s]Map:  10%|█         | 572/5643 [00:01<00:14, 353.83 examples/s]Map:  11%|█         | 628/5643 [00:01<00:14, 353.58 examples/s]Map:  10%|▉         | 563/5643 [00:01<00:14, 346.23 examples/s]Map:  11%|█         | 616/5643 [00:01<00:13, 359.21 examples/s]Map:   4%|▍         | 219/5643 [00:00<00:15, 353.88 examples/s]Map:  11%|█         | 593/5643 [00:01<00:14, 350.09 examples/s]Map:  12%|█▏        | 673/5643 [00:01<00:14, 345.92 examples/s]Map:  11%|█         | 617/5643 [00:01<00:13, 372.79 examples/s]Map:  13%|█▎        | 734/5643 [00:02<00:13, 360.02 examples/s]Map:  12%|█▏        | 665/5643 [00:01<00:14, 351.01 examples/s]Map:  11%|█         | 602/5643 [00:01<00:14, 344.11 examples/s]Map:  12%|█▏        | 653/5643 [00:01<00:13, 357.36 examples/s]Map:   5%|▍         | 259/5643 [00:00<00:15, 351.55 examples/s]Map:  11%|█         | 634/5643 [00:01<00:14, 352.47 examples/s]Map:  13%|█▎        | 710/5643 [00:02<00:14, 338.41 examples/s]Map:  14%|█▎        | 773/5643 [00:02<00:13, 359.19 examples/s]Map:  12%|█▏        | 661/5643 [00:01<00:13, 366.47 examples/s]Map:  12%|█▏        | 701/5643 [00:02<00:14, 341.37 examples/s]Map:  11%|█▏        | 645/5643 [00:01<00:14, 345.60 examples/s]Map:  12%|█▏        | 691/5643 [00:01<00:13, 357.15 examples/s]Map:   5%|▌         | 302/5643 [00:00<00:14, 364.01 examples/s]Map:  12%|█▏        | 674/5643 [00:01<00:14, 342.34 examples/s]Map:  13%|█▎        | 754/5643 [00:02<00:14, 342.97 examples/s]Map:  14%|█▍        | 816/5643 [00:02<00:13, 353.31 examples/s]Map:  13%|█▎        | 744/5643 [00:02<00:14, 339.27 examples/s]Map:  12%|█▏        | 689/5643 [00:02<00:14, 344.02 examples/s]Map:  13%|█▎        | 713/5643 [00:02<00:14, 341.94 examples/s]Map:   6%|▌         | 347/5643 [00:01<00:14, 366.72 examples/s]Map:  13%|█▎        | 711/5643 [00:02<00:14, 344.08 examples/s]Map:  13%|█▎        | 744/5643 [00:02<00:14, 344.42 examples/s]Map:  14%|█▍        | 796/5643 [00:02<00:14, 338.81 examples/s]Map:  14%|█▍        | 787/5643 [00:02<00:14, 344.49 examples/s]Map:  13%|█▎        | 724/5643 [00:02<00:14, 339.40 examples/s]Map:  15%|█▌        | 867/5643 [00:02<00:14, 340.11 examples/s]Map:  13%|█▎        | 751/5643 [00:02<00:14, 334.49 examples/s]Map:   7%|▋         | 391/5643 [00:01<00:13, 375.68 examples/s]Map:  14%|█▍        | 783/5643 [00:02<00:13, 355.24 examples/s]Map:  13%|█▎        | 750/5643 [00:02<00:14, 346.62 examples/s]Map:  15%|█▍        | 831/5643 [00:02<00:14, 338.91 examples/s]Map:  15%|█▍        | 824/5643 [00:02<00:14, 338.23 examples/s]Map:  16%|█▌        | 902/5643 [00:02<00:14, 337.00 examples/s]Map:  14%|█▎        | 765/5643 [00:02<00:14, 337.98 examples/s]Map:  14%|█▍        | 795/5643 [00:02<00:13, 356.47 examples/s]Map:  14%|█▍        | 792/5643 [00:02<00:13, 350.20 examples/s]Map:  15%|█▍        | 822/5643 [00:02<00:13, 345.67 examples/s]Map:   8%|▊         | 440/5643 [00:01<00:14, 348.47 examples/s]Map:  17%|█▋        | 942/5643 [00:02<00:13, 347.04 examples/s]Map:  15%|█▌        | 865/5643 [00:02<00:14, 332.82 examples/s]Map:  16%|█▌        | 882/5643 [00:02<00:14, 327.14 examples/s]Map:  14%|█▍        | 811/5643 [00:02<00:13, 345.48 examples/s]Map:  15%|█▌        | 863/5643 [00:02<00:14, 337.80 examples/s]Map:  15%|█▍        | 844/5643 [00:02<00:14, 335.82 examples/s]Map:   9%|▊         | 491/5643 [00:01<00:13, 375.46 examples/s]Map:  15%|█▌        | 849/5643 [00:02<00:13, 350.30 examples/s]Map:  17%|█▋        | 982/5643 [00:02<00:13, 354.19 examples/s]Map:  16%|█▌        | 905/5643 [00:02<00:14, 333.42 examples/s]Map:  16%|█▋        | 922/5643 [00:02<00:14, 331.30 examples/s]Map:  15%|█▌        | 850/5643 [00:02<00:14, 341.51 examples/s]Map:  16%|█▌        | 916/5643 [00:02<00:14, 335.74 examples/s]Map:  17%|█▋        | 966/5643 [00:02<00:13, 353.03 examples/s]Map:  17%|█▋        | 947/5643 [00:02<00:13, 348.26 examples/s]Map:  16%|█▌        | 897/5643 [00:02<00:14, 324.73 examples/s]Map:  10%|▉         | 541/5643 [00:01<00:14, 348.32 examples/s]Map:  16%|█▌        | 895/5643 [00:02<00:14, 317.35 examples/s]Map:  16%|█▌        | 904/5643 [00:02<00:14, 321.40 examples/s]Map:  17%|█▋        | 957/5643 [00:02<00:13, 347.50 examples/s]Map:  17%|█▋        | 984/5643 [00:02<00:13, 342.68 examples/s]Map:  17%|█▋        | 945/5643 [00:02<00:13, 343.98 examples/s]Map:  10%|█         | 585/5643 [00:01<00:14, 357.77 examples/s]Map:  17%|█▋        | 943/5643 [00:02<00:13, 339.77 examples/s]Map:  17%|█▋        | 945/5643 [00:02<00:13, 335.87 examples/s]Map:  11%|█         | 626/5643 [00:01<00:14, 357.70 examples/s]Map:  17%|█▋        | 986/5643 [00:02<00:13, 342.50 examples/s]Map:  17%|█▋        | 985/5643 [00:02<00:13, 338.73 examples/s]Map:  18%|█▊        | 992/5643 [00:02<00:14, 325.34 examples/s]Map:  12%|█▏        | 668/5643 [00:01<00:14, 351.70 examples/s]Map:  13%|█▎        | 717/5643 [00:02<00:15, 328.33 examples/s]Map:  13%|█▎        | 755/5643 [00:02<00:15, 324.01 examples/s]Map:  18%|█▊        | 1019/5643 [00:03<00:38, 119.99 examples/s]Map:  19%|█▉        | 1060/5643 [00:03<00:30, 150.14 examples/s]Map:  14%|█▍        | 803/5643 [00:02<00:15, 312.48 examples/s]Map:  20%|█▉        | 1103/5643 [00:03<00:24, 188.72 examples/s]Map:  15%|█▍        | 839/5643 [00:02<00:15, 312.43 examples/s]Map:  18%|█▊        | 1018/5643 [00:03<00:38, 120.80 examples/s]Map:  18%|█▊        | 1000/5643 [00:03<00:38, 120.21 examples/s]Map:  20%|██        | 1138/5643 [00:03<00:21, 210.95 examples/s]Map:  15%|█▌        | 873/5643 [00:02<00:15, 306.43 examples/s]Map:  18%|█▊        | 1035/5643 [00:03<00:39, 116.67 examples/s]Map:  19%|█▉        | 1060/5643 [00:03<00:30, 148.80 examples/s]Map:  18%|█▊        | 1035/5643 [00:03<00:32, 143.53 examples/s]Map:  21%|██        | 1183/5643 [00:04<00:17, 249.78 examples/s]Map:  16%|█▌        | 911/5643 [00:02<00:15, 313.97 examples/s]Map:  19%|█▉        | 1072/5643 [00:03<00:32, 141.68 examples/s]Map:  20%|█▉        | 1107/5643 [00:04<00:24, 185.32 examples/s]Map:  18%|█▊        | 1040/5643 [00:03<00:37, 124.30 examples/s]Map:  19%|█▉        | 1083/5643 [00:03<00:25, 181.86 examples/s]Map:  18%|█▊        | 1041/5643 [00:03<00:36, 126.02 examples/s]Map:  22%|██▏       | 1224/5643 [00:04<00:15, 278.20 examples/s]Map:  17%|█▋        | 954/5643 [00:02<00:14, 330.97 examples/s]Map:  20%|█▉        | 1118/5643 [00:04<00:25, 179.90 examples/s]Map:  18%|█▊        | 1038/5643 [00:03<00:38, 118.46 examples/s]Map:  20%|██        | 1149/5643 [00:04<00:20, 214.40 examples/s]Map:  19%|█▉        | 1085/5643 [00:03<00:29, 154.56 examples/s]Map:  19%|█▉        | 1085/5643 [00:03<00:29, 157.14 examples/s]Map:  22%|██▏       | 1262/5643 [00:04<00:14, 296.72 examples/s]Map:  20%|██        | 1132/5643 [00:03<00:20, 220.05 examples/s]Map:  18%|█▊        | 989/5643 [00:02<00:14, 329.63 examples/s]Map:  21%|██        | 1158/5643 [00:04<00:21, 210.38 examples/s]Map:  19%|█▉        | 1083/5643 [00:04<00:30, 149.41 examples/s]Map:  21%|██        | 1191/5643 [00:04<00:18, 242.42 examples/s]Map:  20%|██        | 1130/5643 [00:04<00:24, 187.71 examples/s]Map:  21%|██        | 1176/5643 [00:04<00:17, 255.00 examples/s]Map:  20%|█▉        | 1128/5643 [00:04<00:24, 186.36 examples/s]Map:  23%|██▎       | 1300/5643 [00:04<00:14, 302.24 examples/s]Map:  21%|██        | 1198/5643 [00:04<00:18, 239.58 examples/s]Map:  20%|█▉        | 1126/5643 [00:04<00:24, 181.71 examples/s]Map:  22%|██▏       | 1228/5643 [00:04<00:16, 265.16 examples/s]Map:  21%|██        | 1169/5643 [00:04<00:20, 215.14 examples/s]Map:  22%|██▏       | 1215/5643 [00:04<00:15, 277.71 examples/s]Map:  21%|██        | 1174/5643 [00:04<00:20, 222.33 examples/s]Map:  24%|██▍       | 1347/5643 [00:04<00:13, 328.93 examples/s]Map:  21%|██        | 1171/5643 [00:04<00:20, 217.85 examples/s]Map:  22%|██▏       | 1250/5643 [00:04<00:15, 274.94 examples/s]Map:  23%|██▎       | 1272/5643 [00:04<00:15, 288.43 examples/s]Map:  21%|██▏       | 1207/5643 [00:04<00:18, 240.47 examples/s]Map:  22%|██▏       | 1257/5643 [00:04<00:14, 300.70 examples/s]Map:  21%|██▏       | 1212/5643 [00:04<00:18, 242.69 examples/s]Map:  25%|██▍       | 1384/5643 [00:04<00:13, 326.19 examples/s]Map:  22%|██▏       | 1216/5643 [00:04<00:17, 248.52 examples/s]Map:  23%|██▎       | 1313/5643 [00:04<00:14, 306.17 examples/s]Map:  22%|██▏       | 1251/5643 [00:04<00:16, 272.15 examples/s]Map:  23%|██▎       | 1294/5643 [00:04<00:13, 311.05 examples/s]Map:  23%|██▎       | 1304/5643 [00:04<00:14, 298.74 examples/s]Map:  22%|██▏       | 1255/5643 [00:04<00:15, 276.51 examples/s]Map:  25%|██▌       | 1426/5643 [00:04<00:12, 343.60 examples/s]Map:  22%|██▏       | 1257/5643 [00:04<00:16, 273.04 examples/s]Map:  24%|██▍       | 1356/5643 [00:04<00:13, 324.05 examples/s]Map:  24%|██▎       | 1331/5643 [00:04<00:13, 314.04 examples/s]Map:  23%|██▎       | 1298/5643 [00:04<00:14, 293.16 examples/s]Map:  23%|██▎       | 1294/5643 [00:04<00:14, 291.95 examples/s]Map:  26%|██▌       | 1476/5643 [00:04<00:11, 374.57 examples/s]Map:  24%|██▍       | 1366/5643 [00:04<00:12, 329.38 examples/s]Map:  23%|██▎       | 1297/5643 [00:04<00:14, 291.21 examples/s]Map:  25%|██▍       | 1396/5643 [00:04<00:12, 336.78 examples/s]Map:  24%|██▍       | 1371/5643 [00:04<00:12, 335.47 examples/s]Map:  24%|██▎       | 1334/5643 [00:04<00:14, 303.70 examples/s]Map:  24%|██▎       | 1339/5643 [00:04<00:13, 312.78 examples/s]Map:  27%|██▋       | 1515/5643 [00:04<00:11, 361.82 examples/s]Map:  24%|██▎       | 1339/5643 [00:04<00:13, 310.65 examples/s]Map:  26%|██▌       | 1439/5643 [00:04<00:11, 353.11 examples/s]Map:  25%|██▌       | 1419/5643 [00:04<00:13, 323.29 examples/s]Map:  24%|██▍       | 1382/5643 [00:04<00:12, 329.47 examples/s]Map:  25%|██▍       | 1383/5643 [00:04<00:12, 335.46 examples/s]Map:  28%|██▊       | 1558/5643 [00:05<00:11, 369.75 examples/s]Map:  25%|██▌       | 1426/5643 [00:04<00:12, 343.78 examples/s]Map:  25%|██▍       | 1383/5643 [00:04<00:12, 330.32 examples/s]Map:  26%|██▋       | 1483/5643 [00:05<00:11, 364.31 examples/s]Map:  26%|██▌       | 1466/5643 [00:04<00:12, 344.36 examples/s]Map:  25%|██▌       | 1420/5643 [00:04<00:12, 333.12 examples/s]Map:  25%|██▌       | 1421/5643 [00:04<00:12, 335.72 examples/s]Map:  19%|█▊        | 1044/5643 [00:03<00:36, 125.79 examples/s]Map:  26%|██▌       | 1470/5643 [00:04<00:11, 355.19 examples/s]Map:  28%|██▊       | 1605/5643 [00:05<00:11, 366.57 examples/s]Map:  27%|██▋       | 1525/5643 [00:05<00:11, 369.57 examples/s]Map:  25%|██▌       | 1426/5643 [00:04<00:12, 336.12 examples/s]Map:  27%|██▋       | 1506/5643 [00:05<00:12, 343.88 examples/s]Map:  19%|█▉        | 1088/5643 [00:03<00:28, 158.96 examples/s]Map:  26%|██▌       | 1468/5643 [00:04<00:11, 354.85 examples/s]Map:  27%|██▋       | 1517/5643 [00:04<00:10, 379.20 examples/s]Map:  26%|██▌       | 1474/5643 [00:04<00:11, 358.32 examples/s]Map:  29%|██▉       | 1646/5643 [00:05<00:10, 364.91 examples/s]Map:  26%|██▌       | 1468/5643 [00:05<00:11, 351.53 examples/s]Map:  28%|██▊       | 1568/5643 [00:05<00:11, 364.93 examples/s]Map:  28%|██▊       | 1555/5643 [00:05<00:11, 360.80 examples/s]Map:  27%|██▋       | 1516/5643 [00:05<00:10, 382.92 examples/s]Map:  27%|██▋       | 1514/5643 [00:05<00:11, 361.31 examples/s]Map:  20%|██        | 1133/5643 [00:04<00:23, 192.84 examples/s]Map:  30%|██▉       | 1687/5643 [00:05<00:10, 363.83 examples/s]Map:  28%|██▊       | 1578/5643 [00:05<00:10, 370.43 examples/s]Map:  28%|██▊       | 1607/5643 [00:05<00:11, 363.68 examples/s]Map:  27%|██▋       | 1512/5643 [00:05<00:11, 352.80 examples/s]Map:  28%|██▊       | 1598/5643 [00:05<00:11, 361.24 examples/s]Map:  28%|██▊       | 1555/5643 [00:05<00:11, 367.87 examples/s]Map:  21%|██        | 1178/5643 [00:04<00:19, 228.00 examples/s]Map:  31%|███       | 1736/5643 [00:05<00:10, 381.10 examples/s]Map:  28%|██▊       | 1576/5643 [00:05<00:11, 361.99 examples/s]Map:  29%|██▉       | 1650/5643 [00:05<00:10, 367.89 examples/s]Map:  29%|██▉       | 1625/5643 [00:05<00:10, 369.78 examples/s]Map:  28%|██▊       | 1557/5643 [00:05<00:11, 365.10 examples/s]Map:  29%|██▉       | 1638/5643 [00:05<00:10, 370.28 examples/s]Map:  28%|██▊       | 1599/5643 [00:05<00:10, 385.85 examples/s]Map:  22%|██▏       | 1223/5643 [00:04<00:17, 259.57 examples/s]Map:  32%|███▏      | 1779/5643 [00:05<00:10, 382.94 examples/s]Map:  29%|██▉       | 1663/5643 [00:05<00:10, 370.70 examples/s]Map:  29%|██▊       | 1621/5643 [00:05<00:11, 365.38 examples/s]Map:  28%|██▊       | 1597/5643 [00:05<00:11, 367.15 examples/s]Map:  30%|██▉       | 1691/5643 [00:05<00:11, 358.82 examples/s]Map:  30%|██▉       | 1677/5643 [00:05<00:10, 366.77 examples/s]Map:  29%|██▉       | 1651/5643 [00:05<00:11, 362.15 examples/s]Map:  23%|██▎       | 1278/5643 [00:04<00:15, 283.34 examples/s]Map:  30%|███       | 1708/5643 [00:05<00:10, 380.78 examples/s]Map:  33%|███▎      | 1843/5643 [00:05<00:09, 387.90 examples/s]Map:  29%|██▉       | 1663/5643 [00:05<00:10, 364.19 examples/s]Map:  29%|██▉       | 1640/5643 [00:05<00:10, 367.40 examples/s]Map:  31%|███       | 1738/5643 [00:05<00:10, 371.61 examples/s]Map:  30%|███       | 1716/5643 [00:05<00:10, 359.13 examples/s]Map:  30%|███       | 1696/5643 [00:05<00:10, 362.21 examples/s]Map:  23%|██▎       | 1316/5643 [00:04<00:14, 294.51 examples/s]Map:  30%|███       | 1706/5643 [00:05<00:10, 369.13 examples/s]Map:  30%|██▉       | 1681/5643 [00:05<00:10, 364.13 examples/s]Map:  31%|███       | 1760/5643 [00:05<00:10, 373.30 examples/s]Map:  32%|███▏      | 1779/5643 [00:05<00:10, 367.27 examples/s]Map:  31%|███       | 1761/5643 [00:05<00:10, 382.35 examples/s]Map:  34%|███▎      | 1896/5643 [00:05<00:10, 372.25 examples/s]Map:  31%|███       | 1742/5643 [00:05<00:10, 376.17 examples/s]Map:  31%|███       | 1747/5643 [00:05<00:10, 378.31 examples/s]Map:  24%|██▍       | 1360/5643 [00:04<00:13, 316.05 examples/s]Map:  30%|███       | 1721/5643 [00:05<00:10, 368.48 examples/s]Map:  32%|███▏      | 1820/5643 [00:05<00:10, 377.77 examples/s]Map:  32%|███▏      | 1802/5643 [00:05<00:10, 379.92 examples/s]Map:  32%|███▏      | 1803/5643 [00:05<00:10, 367.46 examples/s]Map:  32%|███▏      | 1784/5643 [00:05<00:10, 372.55 examples/s]Map:  35%|███▍      | 1953/5643 [00:06<00:10, 364.07 examples/s]Map:  25%|██▍       | 1399/5643 [00:04<00:13, 322.37 examples/s]Map:  32%|███▏      | 1796/5643 [00:05<00:10, 378.86 examples/s]Map:  33%|███▎      | 1863/5643 [00:06<00:10, 377.06 examples/s]Map:  31%|███▏      | 1769/5643 [00:05<00:10, 377.12 examples/s]Map:  33%|███▎      | 1842/5643 [00:05<00:10, 367.75 examples/s]Map:  33%|███▎      | 1844/5643 [00:05<00:10, 376.61 examples/s]Map:  32%|███▏      | 1826/5643 [00:05<00:10, 380.45 examples/s]Map:  26%|██▌       | 1443/5643 [00:04<00:12, 338.46 examples/s]Map:  33%|███▎      | 1883/5643 [00:06<00:10, 375.72 examples/s]Map:  33%|███▎      | 1837/5643 [00:05<00:10, 372.54 examples/s]Map:  34%|███▎      | 1904/5643 [00:06<00:10, 370.41 examples/s]Map:  32%|███▏      | 1810/5643 [00:05<00:10, 368.74 examples/s]Map:  33%|███▎      | 1890/5643 [00:05<00:09, 383.58 examples/s]Map:  33%|███▎      | 1865/5643 [00:06<00:10, 366.26 examples/s]Map:  26%|██▋       | 1486/5643 [00:05<00:11, 357.12 examples/s]Map:  34%|███▍      | 1944/5643 [00:06<00:10, 369.67 examples/s]Map:  34%|███▍      | 1921/5643 [00:06<00:10, 357.92 examples/s]Map:  33%|███▎      | 1851/5643 [00:06<00:10, 372.31 examples/s]Map:  33%|███▎      | 1883/5643 [00:06<00:10, 374.05 examples/s]Map:  34%|███▍      | 1933/5643 [00:06<00:10, 369.17 examples/s]Map:  34%|███▍      | 1906/5643 [00:06<00:10, 364.02 examples/s]Map:  27%|██▋       | 1526/5643 [00:05<00:11, 366.61 examples/s]Map:  35%|███▍      | 1962/5643 [00:06<00:10, 365.49 examples/s]Map:  35%|███▌      | 1982/5643 [00:06<00:10, 347.88 examples/s]Map:  34%|███▎      | 1898/5643 [00:06<00:10, 371.22 examples/s]Map:  34%|███▍      | 1929/5643 [00:06<00:10, 362.21 examples/s]Map:  35%|███▍      | 1972/5643 [00:06<00:10, 351.94 examples/s]Map:  34%|███▍      | 1946/5643 [00:06<00:10, 367.36 examples/s]Map:  28%|██▊       | 1579/5643 [00:05<00:11, 353.20 examples/s]Map:  34%|███▍      | 1940/5643 [00:06<00:10, 361.82 examples/s]Map:  35%|███▍      | 1969/5643 [00:06<00:10, 361.31 examples/s]Map:  29%|██▊       | 1618/5643 [00:05<00:11, 351.65 examples/s]Map:  35%|███▌      | 1986/5643 [00:06<00:09, 369.12 examples/s]Map:  29%|██▉       | 1655/5643 [00:05<00:11, 342.81 examples/s]Map:  35%|███▌      | 2000/5643 [00:06<00:24, 150.55 examples/s]Map:  30%|███       | 1693/5643 [00:05<00:11, 338.23 examples/s]Map:  36%|███▌      | 2034/5643 [00:06<00:21, 171.40 examples/s]Map:  31%|███       | 1736/5643 [00:05<00:11, 349.16 examples/s]Map:  37%|███▋      | 2068/5643 [00:07<00:18, 193.77 examples/s]Map:  31%|███▏      | 1776/5643 [00:05<00:11, 348.95 examples/s]Map:  37%|███▋      | 2103/5643 [00:07<00:16, 217.83 examples/s]Map:  35%|███▌      | 2000/5643 [00:07<00:29, 125.16 examples/s]Map:  32%|███▏      | 1818/5643 [00:06<00:11, 346.62 examples/s]Map:  38%|███▊      | 2140/5643 [00:07<00:14, 246.43 examples/s]Map:  36%|███▌      | 2018/5643 [00:07<00:30, 119.45 examples/s]Map:  36%|███▌      | 2013/5643 [00:07<00:29, 125.05 examples/s]Map:  36%|███▌      | 2031/5643 [00:07<00:24, 146.47 examples/s]Map:  35%|███▌      | 2000/5643 [00:07<00:27, 134.38 examples/s]Map:  39%|███▊      | 2173/5643 [00:07<00:13, 258.13 examples/s]Map:  33%|███▎      | 1861/5643 [00:06<00:10, 349.05 examples/s]Map:  37%|███▋      | 2067/5643 [00:07<00:22, 157.17 examples/s]Map:  36%|███▌      | 2013/5643 [00:07<00:27, 131.51 examples/s]Map:  36%|███▋      | 2055/5643 [00:07<00:22, 157.04 examples/s]Map:  37%|███▋      | 2076/5643 [00:07<00:19, 185.14 examples/s]Map:  36%|███▌      | 2038/5643 [00:07<00:22, 160.96 examples/s]Map:  34%|███▎      | 1900/5643 [00:06<00:10, 357.60 examples/s]Map:  39%|███▉      | 2216/5643 [00:07<00:11, 293.05 examples/s]Map:  37%|███▋      | 2107/5643 [00:07<00:19, 185.51 examples/s]Map:  36%|███▋      | 2059/5643 [00:07<00:21, 164.65 examples/s]Map:  37%|███▋      | 2097/5643 [00:07<00:18, 190.37 examples/s]Map:  37%|███▋      | 2111/5643 [00:07<00:16, 209.93 examples/s]Map:  37%|███▋      | 2082/5643 [00:07<00:18, 195.52 examples/s]Map:  36%|███▌      | 2040/5643 [00:07<00:26, 133.70 examples/s]Map:  40%|████      | 2263/5643 [00:07<00:10, 325.00 examples/s]Map:  38%|███▊      | 2145/5643 [00:07<00:16, 214.48 examples/s]Map:  35%|███▍      | 1947/5643 [00:06<00:10, 349.54 examples/s]Map:  37%|███▋      | 2099/5643 [00:07<00:18, 194.55 examples/s]Map:  38%|███▊      | 2137/5643 [00:07<00:16, 218.34 examples/s]Map:  38%|███▊      | 2154/5643 [00:07<00:13, 250.97 examples/s]Map:  38%|███▊      | 2118/5643 [00:07<00:15, 220.99 examples/s]Map:  37%|███▋      | 2082/5643 [00:07<00:21, 162.53 examples/s]Map:  41%|████      | 2303/5643 [00:07<00:09, 341.36 examples/s]Map:  39%|███▉      | 2189/5643 [00:07<00:13, 249.18 examples/s]Map:  35%|███▌      | 1985/5643 [00:06<00:10, 344.02 examples/s]Map:  38%|███▊      | 2141/5643 [00:07<00:15, 225.25 examples/s]Map:  39%|███▉      | 2191/5643 [00:07<00:12, 272.42 examples/s]Map:  39%|███▊      | 2185/5643 [00:07<00:13, 250.61 examples/s]Map:  38%|███▊      | 2155/5643 [00:07<00:14, 247.18 examples/s]Map:  38%|███▊      | 2121/5643 [00:07<00:18, 191.03 examples/s]Map:  42%|████▏     | 2349/5643 [00:07<00:09, 338.19 examples/s]Map:  40%|███▉      | 2234/5643 [00:07<00:12, 277.91 examples/s]Map:  39%|███▊      | 2183/5643 [00:07<00:13, 255.50 examples/s]Map:  40%|███▉      | 2234/5643 [00:07<00:11, 308.37 examples/s]Map:  40%|███▉      | 2232/5643 [00:07<00:11, 290.33 examples/s]Map:  39%|███▉      | 2196/5643 [00:07<00:12, 271.43 examples/s]Map:  38%|███▊      | 2163/5643 [00:07<00:15, 218.34 examples/s]Map:  42%|████▏     | 2387/5643 [00:07<00:09, 343.36 examples/s]Map:  40%|████      | 2282/5643 [00:07<00:10, 313.30 examples/s]Map:  39%|███▉      | 2228/5643 [00:07<00:12, 283.44 examples/s]Map:  40%|████      | 2285/5643 [00:07<00:09, 339.59 examples/s]Map:  40%|████      | 2272/5643 [00:07<00:10, 309.61 examples/s]Map:  40%|███▉      | 2243/5643 [00:07<00:10, 311.47 examples/s]Map:  39%|███▉      | 2213/5643 [00:07<00:13, 257.80 examples/s]Map:  43%|████▎     | 2428/5643 [00:08<00:09, 352.59 examples/s]Map:  40%|████      | 2274/5643 [00:07<00:10, 316.55 examples/s]Map:  41%|████      | 2310/5643 [00:07<00:10, 317.70 examples/s]Map:  41%|████▏     | 2335/5643 [00:08<00:10, 319.82 examples/s]Map:  41%|████      | 2289/5643 [00:07<00:10, 332.65 examples/s]Map:  44%|████▎     | 2467/5643 [00:08<00:08, 357.03 examples/s]Map:  40%|███▉      | 2256/5643 [00:07<00:11, 286.37 examples/s]Map:  41%|████▏     | 2341/5643 [00:08<00:10, 327.57 examples/s]Map:  41%|████      | 2313/5643 [00:07<00:10, 316.62 examples/s]Map:  42%|████▏     | 2376/5643 [00:08<00:09, 334.75 examples/s]Map:  44%|████▍     | 2505/5643 [00:08<00:08, 350.84 examples/s]Map:  41%|████      | 2298/5643 [00:08<00:10, 307.34 examples/s]Map:  42%|████▏     | 2368/5643 [00:08<00:10, 321.62 examples/s]Map:  42%|████▏     | 2383/5643 [00:08<00:09, 336.81 examples/s]Map:  42%|████▏     | 2345/5643 [00:08<00:09, 333.19 examples/s]Map:  42%|████▏     | 2353/5643 [00:08<00:10, 324.62 examples/s]Map:  43%|████▎     | 2416/5643 [00:08<00:09, 343.28 examples/s]Map:  41%|████▏     | 2337/5643 [00:08<00:10, 314.20 examples/s]Map:  45%|████▌     | 2551/5643 [00:08<00:08, 359.61 examples/s]Map:  43%|████▎     | 2414/5643 [00:08<00:09, 337.41 examples/s]Map:  43%|████▎     | 2426/5643 [00:08<00:09, 345.36 examples/s]Map:  42%|████▏     | 2392/5643 [00:08<00:09, 344.13 examples/s]Map:  42%|████▏     | 2396/5643 [00:08<00:09, 343.84 examples/s]Map:  44%|████▎     | 2456/5643 [00:08<00:09, 344.52 examples/s]Map:  44%|████▎     | 2465/5643 [00:08<00:08, 355.33 examples/s]Map:  42%|████▏     | 2380/5643 [00:08<00:09, 330.82 examples/s]Map:  44%|████▎     | 2457/5643 [00:08<00:09, 345.74 examples/s]Map:  46%|████▌     | 2595/5643 [00:08<00:08, 355.87 examples/s]Map:  36%|███▌      | 2038/5643 [00:07<00:25, 139.58 examples/s]Map:  43%|████▎     | 2435/5643 [00:08<00:09, 348.38 examples/s]Map:  43%|████▎     | 2435/5643 [00:08<00:09, 339.80 examples/s]Map:  44%|████▍     | 2499/5643 [00:08<00:09, 348.75 examples/s]Map:  44%|████▍     | 2495/5643 [00:08<00:08, 353.90 examples/s]Map:  47%|████▋     | 2631/5643 [00:08<00:08, 355.43 examples/s]Map:  43%|████▎     | 2425/5643 [00:08<00:09, 341.30 examples/s]Map:  37%|███▋      | 2082/5643 [00:07<00:20, 170.77 examples/s]Map:  44%|████▍     | 2480/5643 [00:08<00:08, 360.25 examples/s]Map:  44%|████▍     | 2480/5643 [00:08<00:08, 355.90 examples/s]Map:  45%|████▍     | 2520/5643 [00:08<00:08, 348.56 examples/s]Map:  45%|████▌     | 2546/5643 [00:08<00:08, 355.43 examples/s]Map:  45%|████▌     | 2542/5643 [00:08<00:08, 363.64 examples/s]Map:  47%|████▋     | 2673/5643 [00:08<00:08, 353.63 examples/s]Map:  44%|████▎     | 2468/5643 [00:08<00:09, 349.87 examples/s]Map:  38%|███▊      | 2123/5643 [00:07<00:17, 200.22 examples/s]Map:  45%|████▌     | 2560/5643 [00:08<00:08, 353.80 examples/s]Map:  45%|████▍     | 2520/5643 [00:08<00:09, 346.97 examples/s]Map:  46%|████▌     | 2584/5643 [00:08<00:08, 356.21 examples/s]Map:  45%|████▍     | 2538/5643 [00:08<00:08, 359.33 examples/s]Map:  48%|████▊     | 2710/5643 [00:08<00:08, 352.15 examples/s]Map:  44%|████▍     | 2507/5643 [00:08<00:09, 346.99 examples/s]Map:  46%|████▌     | 2583/5643 [00:08<00:08, 353.55 examples/s]Map:  38%|███▊      | 2165/5643 [00:07<00:15, 230.88 examples/s]Map:  46%|████▌     | 2602/5643 [00:08<00:08, 364.32 examples/s]Map:  45%|████▌     | 2560/5643 [00:08<00:08, 348.06 examples/s]Map:  47%|████▋     | 2625/5643 [00:08<00:08, 355.06 examples/s]Map:  49%|████▊     | 2750/5643 [00:08<00:08, 357.03 examples/s]Map:  47%|████▋     | 2624/5643 [00:08<00:08, 360.31 examples/s]Map:  46%|████▌     | 2595/5643 [00:08<00:08, 357.55 examples/s]Map:  45%|████▌     | 2549/5643 [00:08<00:09, 341.27 examples/s]Map:  47%|████▋     | 2640/5643 [00:08<00:08, 361.30 examples/s]Map:  39%|███▉      | 2211/5643 [00:07<00:12, 266.73 examples/s]Map:  46%|████▋     | 2612/5643 [00:08<00:08, 375.05 examples/s]Map:  47%|████▋     | 2663/5643 [00:09<00:08, 349.80 examples/s]Map:  49%|████▉     | 2787/5643 [00:09<00:08, 353.01 examples/s]Map:  47%|████▋     | 2666/5643 [00:08<00:08, 366.66 examples/s]Map:  46%|████▌     | 2588/5643 [00:08<00:08, 350.49 examples/s]Map:  47%|████▋     | 2640/5643 [00:08<00:08, 362.24 examples/s]Map:  47%|████▋     | 2679/5643 [00:08<00:08, 356.26 examples/s]Map:  40%|███▉      | 2256/5643 [00:07<00:11, 294.27 examples/s]Map:  48%|████▊     | 2706/5643 [00:09<00:08, 349.45 examples/s]Map:  50%|█████     | 2831/5643 [00:09<00:07, 370.13 examples/s]Map:  47%|████▋     | 2662/5643 [00:08<00:08, 349.02 examples/s]Map:  47%|████▋     | 2626/5643 [00:08<00:08, 355.47 examples/s]Map:  47%|████▋     | 2678/5643 [00:08<00:08, 361.28 examples/s]Map:  41%|████      | 2295/5643 [00:07<00:10, 315.07 examples/s]Map:  48%|████▊     | 2716/5643 [00:09<00:08, 352.54 examples/s]Map:  48%|████▊     | 2726/5643 [00:09<00:08, 354.70 examples/s]Map:  51%|█████     | 2874/5643 [00:09<00:07, 378.05 examples/s]Map:  49%|████▉     | 2752/5643 [00:09<00:08, 355.93 examples/s]Map:  48%|████▊     | 2703/5643 [00:09<00:08, 352.75 examples/s]Map:  47%|████▋     | 2669/5643 [00:09<00:08, 350.98 examples/s]Map:  49%|████▉     | 2756/5643 [00:09<00:08, 351.67 examples/s]Map:  41%|████▏     | 2332/5643 [00:08<00:10, 311.26 examples/s]Map:  48%|████▊     | 2725/5643 [00:09<00:08, 356.22 examples/s]Map:  49%|████▉     | 2765/5643 [00:09<00:08, 350.88 examples/s]Map:  52%|█████▏    | 2919/5643 [00:09<00:06, 393.60 examples/s]Map:  50%|████▉     | 2795/5643 [00:09<00:08, 355.21 examples/s]Map:  49%|████▊     | 2744/5643 [00:09<00:08, 356.54 examples/s]Map:  48%|████▊     | 2710/5643 [00:09<00:08, 352.85 examples/s]Map:  50%|████▉     | 2800/5643 [00:09<00:07, 361.44 examples/s]Map:  42%|████▏     | 2373/5643 [00:08<00:10, 324.24 examples/s]Map:  49%|████▉     | 2765/5643 [00:09<00:08, 355.02 examples/s]Map:  50%|████▉     | 2812/5643 [00:09<00:07, 362.90 examples/s]Map:  52%|█████▏    | 2959/5643 [00:09<00:07, 377.74 examples/s]Map:  50%|█████     | 2838/5643 [00:09<00:07, 370.70 examples/s]Map:  49%|████▉     | 2785/5643 [00:09<00:08, 352.88 examples/s]Map:  50%|█████     | 2842/5643 [00:09<00:07, 376.76 examples/s]Map:  50%|████▉     | 2807/5643 [00:09<00:07, 368.75 examples/s]Map:  49%|████▉     | 2753/5643 [00:09<00:08, 345.51 examples/s]Map:  43%|████▎     | 2423/5643 [00:08<00:09, 341.94 examples/s]Map:  51%|█████     | 2855/5643 [00:09<00:07, 372.30 examples/s]Map:  51%|█████     | 2884/5643 [00:09<00:07, 372.01 examples/s]Map:  50%|█████     | 2834/5643 [00:09<00:07, 377.57 examples/s]Map:  51%|█████     | 2882/5643 [00:09<00:07, 369.02 examples/s]Map:  51%|█████     | 2850/5643 [00:09<00:07, 366.64 examples/s]Map:  50%|████▉     | 2796/5643 [00:09<00:07, 356.14 examples/s]Map:  51%|█████▏    | 2902/5643 [00:09<00:07, 370.96 examples/s]Map:  44%|████▍     | 2481/5643 [00:08<00:09, 347.10 examples/s]Map:  52%|█████▏    | 2926/5643 [00:09<00:07, 369.15 examples/s]Map:  51%|█████     | 2877/5643 [00:09<00:07, 373.84 examples/s]Map:  52%|█████▏    | 2927/5643 [00:09<00:07, 376.37 examples/s]Map:  51%|█████▏    | 2894/5643 [00:09<00:07, 371.60 examples/s]Map:  50%|█████     | 2840/5643 [00:09<00:07, 361.03 examples/s]Map:  52%|█████▏    | 2944/5643 [00:09<00:07, 375.78 examples/s]Map:  45%|████▍     | 2521/5643 [00:08<00:08, 347.24 examples/s]Map:  53%|█████▎    | 2970/5643 [00:09<00:07, 379.33 examples/s]Map:  52%|█████▏    | 2919/5643 [00:09<00:07, 371.49 examples/s]Map:  53%|█████▎    | 2975/5643 [00:09<00:06, 393.24 examples/s]Map:  52%|█████▏    | 2937/5643 [00:09<00:07, 379.49 examples/s]Map:  51%|█████     | 2885/5643 [00:09<00:07, 370.24 examples/s]Map:  53%|█████▎    | 2985/5643 [00:09<00:07, 377.60 examples/s]Map:  45%|████▌     | 2564/5643 [00:08<00:08, 345.61 examples/s]Map:  53%|█████▎    | 2967/5643 [00:09<00:06, 387.46 examples/s]Map:  53%|█████▎    | 2978/5643 [00:09<00:07, 380.67 examples/s]Map:  52%|█████▏    | 2933/5643 [00:09<00:07, 371.76 examples/s]Map:  46%|████▌     | 2600/5643 [00:08<00:08, 345.27 examples/s]Map:  53%|█████▎    | 2974/5643 [00:09<00:07, 374.79 examples/s]Map:  47%|████▋     | 2641/5643 [00:08<00:08, 345.32 examples/s]Map:  53%|█████▎    | 3000/5643 [00:10<00:20, 128.97 examples/s]Map:  48%|████▊     | 2681/5643 [00:09<00:08, 342.54 examples/s]Map:  48%|████▊     | 2717/5643 [00:09<00:08, 334.06 examples/s]Map:  54%|█████▍    | 3041/5643 [00:10<00:16, 156.91 examples/s]Map:  55%|█████▍    | 3078/5643 [00:10<00:13, 185.92 examples/s]Map:  49%|████▉     | 2757/5643 [00:09<00:08, 337.88 examples/s]Map:  55%|█████▌    | 3123/5643 [00:10<00:11, 223.27 examples/s]Map:  50%|████▉     | 2799/5643 [00:09<00:08, 341.72 examples/s]Map:  53%|█████▎    | 3016/5643 [00:10<00:19, 133.69 examples/s]Map:  54%|█████▎    | 3023/5643 [00:10<00:19, 133.60 examples/s]Map:  56%|█████▌    | 3157/5643 [00:10<00:10, 240.52 examples/s]Map:  50%|█████     | 2840/5643 [00:09<00:07, 350.73 examples/s]Map:  54%|█████▍    | 3056/5643 [00:10<00:16, 161.41 examples/s]Map:  54%|█████▍    | 3037/5643 [00:10<00:19, 134.10 examples/s]Map:  54%|█████▍    | 3055/5643 [00:10<00:16, 153.29 examples/s]Map:  53%|█████▎    | 3016/5643 [00:10<00:19, 132.21 examples/s]Map:  51%|█████     | 2878/5643 [00:09<00:07, 351.15 examples/s]Map:  57%|█████▋    | 3202/5643 [00:10<00:08, 272.72 examples/s]Map:  54%|█████▍    | 3035/5643 [00:10<00:19, 135.32 examples/s]Map:  55%|█████▍    | 3098/5643 [00:10<00:13, 195.17 examples/s]Map:  55%|█████▍    | 3086/5643 [00:10<00:15, 170.07 examples/s]Map:  55%|█████▍    | 3096/5643 [00:10<00:13, 187.86 examples/s]Map:  53%|█████▎    | 3017/5643 [00:10<00:20, 130.49 examples/s]Map:  54%|█████▍    | 3059/5643 [00:10<00:16, 160.89 examples/s]Map:  58%|█████▊    | 3245/5643 [00:11<00:08, 295.09 examples/s]Map:  52%|█████▏    | 2924/5643 [00:09<00:07, 358.25 examples/s]Map:  56%|█████▌    | 3137/5643 [00:10<00:11, 225.07 examples/s]Map:  55%|█████▍    | 3081/5643 [00:10<00:15, 166.07 examples/s]Map:  55%|█████▌    | 3129/5643 [00:10<00:12, 198.93 examples/s]Map:  56%|█████▌    | 3141/5643 [00:10<00:11, 223.98 examples/s]Map:  54%|█████▍    | 3058/5643 [00:10<00:16, 159.85 examples/s]Map:  55%|█████▍    | 3103/5643 [00:10<00:13, 193.71 examples/s]Map:  53%|█████▎    | 2966/5643 [00:09<00:07, 359.43 examples/s]Map:  55%|█████▌    | 3124/5643 [00:10<00:12, 199.14 examples/s]Map:  56%|█████▋    | 3181/5643 [00:11<00:09, 256.76 examples/s]Map:  56%|█████▌    | 3169/5643 [00:10<00:10, 227.87 examples/s]Map:  56%|█████▋    | 3176/5643 [00:11<00:09, 246.85 examples/s]Map:  58%|█████▊    | 3300/5643 [00:11<00:07, 307.17 examples/s]Map:  55%|█████▍    | 3100/5643 [00:10<00:13, 193.11 examples/s]Map:  56%|█████▌    | 3149/5643 [00:10<00:11, 225.18 examples/s]Map:  57%|█████▋    | 3225/5643 [00:11<00:08, 287.17 examples/s]Map:  56%|█████▌    | 3168/5643 [00:10<00:10, 229.39 examples/s]Map:  57%|█████▋    | 3211/5643 [00:11<00:09, 262.54 examples/s]Map:  57%|█████▋    | 3221/5643 [00:11<00:08, 281.69 examples/s]Map:  59%|█████▉    | 3351/5643 [00:11<00:06, 337.20 examples/s]Map:  56%|█████▌    | 3143/5643 [00:11<00:11, 225.34 examples/s]Map:  57%|█████▋    | 3193/5643 [00:11<00:09, 256.73 examples/s]Map:  57%|█████▋    | 3210/5643 [00:11<00:09, 260.89 examples/s]Map:  58%|█████▊    | 3258/5643 [00:11<00:08, 289.68 examples/s]Map:  58%|█████▊    | 3278/5643 [00:11<00:08, 295.40 examples/s]Map:  58%|█████▊    | 3260/5643 [00:11<00:08, 278.39 examples/s]Map:  56%|█████▋    | 3184/5643 [00:11<00:09, 252.24 examples/s]Map:  60%|██████    | 3401/5643 [00:11<00:06, 330.73 examples/s]Map:  58%|█████▊    | 3247/5643 [00:11<00:08, 278.37 examples/s]Map:  57%|█████▋    | 3237/5643 [00:11<00:08, 284.46 examples/s]Map:  58%|█████▊    | 3293/5643 [00:11<00:07, 299.19 examples/s]Map:  59%|█████▉    | 3320/5643 [00:11<00:07, 300.34 examples/s]Map:  57%|█████▋    | 3225/5643 [00:11<00:08, 270.59 examples/s]Map:  61%|██████    | 3443/5643 [00:11<00:06, 340.13 examples/s]Map:  59%|█████▊    | 3315/5643 [00:11<00:07, 297.22 examples/s]Map:  58%|█████▊    | 3275/5643 [00:11<00:08, 283.49 examples/s]Map:  59%|█████▉    | 3332/5643 [00:11<00:07, 316.41 examples/s]Map:  59%|█████▊    | 3304/5643 [00:11<00:07, 293.19 examples/s]Map:  60%|█████▉    | 3360/5643 [00:11<00:07, 322.37 examples/s]Map:  58%|█████▊    | 3261/5643 [00:11<00:08, 281.33 examples/s]Map:  62%|██████▏   | 3481/5643 [00:11<00:06, 342.52 examples/s]Map:  60%|█████▉    | 3361/5643 [00:11<00:06, 328.12 examples/s]Map:  59%|█████▉    | 3316/5643 [00:11<00:07, 304.41 examples/s]Map:  60%|█████▉    | 3381/5643 [00:11<00:06, 333.48 examples/s]Map:  60%|██████    | 3400/5643 [00:11<00:06, 335.25 examples/s]Map:  59%|█████▉    | 3350/5643 [00:11<00:07, 315.18 examples/s]Map:  58%|█████▊    | 3298/5643 [00:11<00:07, 296.34 examples/s]Map:  62%|██████▏   | 3517/5643 [00:11<00:06, 341.33 examples/s]Map:  59%|█████▉    | 3356/5643 [00:11<00:07, 323.30 examples/s]Map:  61%|██████    | 3418/5643 [00:11<00:06, 342.11 examples/s]Map:  61%|██████    | 3418/5643 [00:11<00:06, 330.14 examples/s]Map:  60%|██████    | 3387/5643 [00:11<00:06, 322.57 examples/s]Map:  61%|██████    | 3439/5643 [00:11<00:06, 336.85 examples/s]Map:  59%|█████▉    | 3338/5643 [00:11<00:07, 317.18 examples/s]Map:  63%|██████▎   | 3557/5643 [00:11<00:05, 349.74 examples/s]Map:  60%|██████    | 3397/5643 [00:11<00:06, 333.41 examples/s]Map:  54%|█████▎    | 3021/5643 [00:10<00:18, 138.59 examples/s]Map:  61%|██████    | 3455/5643 [00:11<00:06, 343.26 examples/s]Map:  61%|██████▏   | 3459/5643 [00:11<00:06, 336.78 examples/s]Map:  61%|██████    | 3429/5643 [00:11<00:06, 334.41 examples/s]Map:  64%|██████▎   | 3593/5643 [00:12<00:05, 352.21 examples/s]Map:  60%|█████▉    | 3376/5643 [00:11<00:06, 330.41 examples/s]Map:  62%|██████▏   | 3481/5643 [00:11<00:06, 338.08 examples/s]Map:  61%|██████    | 3441/5643 [00:11<00:06, 342.25 examples/s]Map:  62%|██████▏   | 3493/5643 [00:11<00:06, 352.53 examples/s]Map:  62%|██████▏   | 3498/5643 [00:11<00:06, 343.09 examples/s]Map:  54%|█████▍    | 3065/5643 [00:10<00:15, 168.76 examples/s]Map:  61%|██████▏   | 3468/5643 [00:11<00:06, 342.41 examples/s]Map:  64%|██████▍   | 3634/5643 [00:12<00:05, 359.60 examples/s]Map:  62%|██████▏   | 3519/5643 [00:12<00:06, 335.11 examples/s]Map:  61%|██████    | 3426/5643 [00:11<00:06, 344.91 examples/s]Map:  63%|██████▎   | 3531/5643 [00:12<00:05, 352.96 examples/s]Map:  62%|██████▏   | 3480/5643 [00:11<00:06, 340.76 examples/s]Map:  55%|█████▌    | 3106/5643 [00:10<00:12, 201.26 examples/s]Map:  63%|██████▎   | 3540/5643 [00:11<00:06, 344.61 examples/s]Map:  62%|██████▏   | 3507/5643 [00:11<00:06, 342.98 examples/s]Map:  63%|██████▎   | 3561/5643 [00:12<00:05, 355.40 examples/s]Map:  65%|██████▌   | 3684/5643 [00:12<00:05, 371.49 examples/s]Map:  61%|██████▏   | 3470/5643 [00:12<00:06, 344.32 examples/s]Map:  56%|█████▌    | 3144/5643 [00:11<00:11, 226.49 examples/s]Map:  63%|██████▎   | 3578/5643 [00:12<00:05, 352.91 examples/s]Map:  62%|██████▏   | 3522/5643 [00:12<00:06, 335.93 examples/s]Map:  63%|██████▎   | 3547/5643 [00:12<00:05, 349.98 examples/s]Map:  64%|██████▎   | 3586/5643 [00:12<00:05, 348.33 examples/s]Map:  64%|██████▍   | 3600/5643 [00:12<00:05, 348.29 examples/s]Map:  66%|██████▌   | 3726/5643 [00:12<00:05, 376.15 examples/s]Map:  62%|██████▏   | 3509/5643 [00:12<00:06, 336.89 examples/s]Map:  56%|█████▋    | 3188/5643 [00:11<00:09, 258.19 examples/s]Map:  63%|██████▎   | 3567/5643 [00:12<00:05, 348.67 examples/s]Map:  64%|██████▎   | 3588/5643 [00:12<00:05, 351.73 examples/s]Map:  64%|██████▍   | 3629/5643 [00:12<00:05, 363.17 examples/s]Map:  64%|██████▍   | 3633/5643 [00:12<00:05, 365.46 examples/s]Map:  65%|██████▍   | 3642/5643 [00:12<00:05, 360.16 examples/s]Map:  67%|██████▋   | 3769/5643 [00:12<00:04, 377.19 examples/s]Map:  63%|██████▎   | 3551/5643 [00:12<00:05, 351.13 examples/s]Map:  57%|█████▋    | 3225/5643 [00:11<00:08, 276.24 examples/s]Map:  64%|██████▍   | 3609/5643 [00:12<00:05, 359.83 examples/s]Map:  64%|██████▍   | 3632/5643 [00:12<00:05, 369.51 examples/s]Map:  65%|██████▌   | 3671/5643 [00:12<00:05, 363.95 examples/s]Map:  65%|██████▌   | 3677/5643 [00:12<00:05, 371.36 examples/s]Map:  68%|██████▊   | 3815/5643 [00:12<00:04, 384.93 examples/s]Map:  65%|██████▌   | 3691/5643 [00:12<00:05, 371.99 examples/s]Map:  64%|██████▎   | 3591/5643 [00:12<00:05, 349.33 examples/s]Map:  58%|█████▊    | 3262/5643 [00:11<00:08, 290.91 examples/s]Map:  65%|██████▍   | 3653/5643 [00:12<00:05, 363.22 examples/s]Map:  65%|██████▌   | 3675/5643 [00:12<00:05, 365.07 examples/s]Map:  66%|██████▌   | 3715/5643 [00:12<00:05, 369.87 examples/s]Map:  66%|██████▌   | 3721/5643 [00:12<00:05, 375.24 examples/s]Map:  68%|██████▊   | 3860/5643 [00:12<00:04, 387.38 examples/s]Map:  66%|██████▌   | 3730/5643 [00:12<00:05, 360.76 examples/s]Map:  64%|██████▍   | 3634/5643 [00:12<00:05, 354.73 examples/s]Map:  59%|█████▊    | 3305/5643 [00:11<00:07, 311.45 examples/s]Map:  65%|██████▌   | 3696/5643 [00:12<00:05, 372.24 examples/s]Map:  66%|██████▌   | 3719/5643 [00:12<00:05, 377.39 examples/s]Map:  67%|██████▋   | 3758/5643 [00:12<00:05, 372.23 examples/s]Map:  67%|██████▋   | 3765/5643 [00:12<00:04, 377.90 examples/s]Map:  67%|██████▋   | 3778/5643 [00:12<00:04, 387.57 examples/s]Map:  69%|██████▉   | 3906/5643 [00:12<00:04, 385.79 examples/s]Map:  65%|██████▌   | 3681/5643 [00:12<00:05, 365.93 examples/s]Map:  59%|█████▉    | 3345/5643 [00:11<00:07, 323.95 examples/s]Map:  67%|██████▋   | 3762/5643 [00:12<00:04, 383.84 examples/s]Map:  66%|██████▌   | 3738/5643 [00:12<00:05, 358.90 examples/s]Map:  67%|██████▋   | 3800/5643 [00:12<00:04, 370.55 examples/s]Map:  68%|██████▊   | 3819/5643 [00:12<00:04, 383.62 examples/s]Map:  68%|██████▊   | 3812/5643 [00:12<00:04, 380.70 examples/s]Map:  70%|██████▉   | 3950/5643 [00:12<00:04, 389.60 examples/s]Map:  66%|██████▌   | 3727/5643 [00:12<00:05, 363.10 examples/s]Map:  60%|██████    | 3386/5643 [00:11<00:06, 332.93 examples/s]Map:  67%|██████▋   | 3781/5643 [00:12<00:05, 369.95 examples/s]Map:  68%|██████▊   | 3842/5643 [00:12<00:04, 376.53 examples/s]Map:  71%|███████   | 3989/5643 [00:13<00:04, 384.60 examples/s]Map:  68%|██████▊   | 3864/5643 [00:12<00:04, 385.65 examples/s]Map:  68%|██████▊   | 3858/5643 [00:12<00:04, 387.73 examples/s]Map:  68%|██████▊   | 3822/5643 [00:12<00:04, 379.94 examples/s]Map:  67%|██████▋   | 3777/5643 [00:12<00:04, 378.06 examples/s]Map:  61%|██████    | 3429/5643 [00:11<00:06, 339.93 examples/s]Map:  68%|██████▊   | 3826/5643 [00:12<00:04, 378.64 examples/s]Map:  69%|██████▉   | 3884/5643 [00:12<00:04, 380.65 examples/s]Map:  69%|██████▉   | 3899/5643 [00:12<00:04, 386.34 examples/s]Map:  69%|██████▉   | 3907/5643 [00:13<00:04, 378.59 examples/s]Map:  69%|██████▊   | 3866/5643 [00:12<00:04, 387.33 examples/s]Map:  61%|██████▏   | 3465/5643 [00:11<00:06, 340.37 examples/s]Map:  68%|██████▊   | 3821/5643 [00:12<00:04, 372.69 examples/s]Map:  70%|██████▉   | 3927/5643 [00:13<00:04, 387.39 examples/s]Map:  69%|██████▊   | 3872/5643 [00:12<00:04, 386.14 examples/s]Map:  70%|██████▉   | 3943/5643 [00:12<00:04, 392.19 examples/s]Map:  70%|███████   | 3954/5643 [00:13<00:04, 389.32 examples/s]Map:  69%|██████▉   | 3907/5643 [00:12<00:04, 385.65 examples/s]Map:  69%|██████▊   | 3868/5643 [00:13<00:04, 390.92 examples/s]Map:  70%|███████   | 3970/5643 [00:13<00:04, 389.89 examples/s]Map:  69%|██████▉   | 3914/5643 [00:13<00:04, 381.20 examples/s]Map:  71%|███████   | 3987/5643 [00:13<00:04, 390.29 examples/s]Map:  62%|██████▏   | 3516/5643 [00:12<00:06, 337.44 examples/s]Map:  71%|███████   | 3994/5643 [00:13<00:04, 374.97 examples/s]Map:  70%|███████   | 3954/5643 [00:13<00:04, 380.77 examples/s]Map:  69%|██████▉   | 3912/5643 [00:13<00:04, 387.62 examples/s]Map:  70%|███████   | 3960/5643 [00:13<00:04, 385.13 examples/s]Map:  63%|██████▎   | 3559/5643 [00:12<00:05, 348.03 examples/s]Map:  70%|███████   | 3951/5643 [00:13<00:04, 376.04 examples/s]Map:  64%|██████▎   | 3595/5643 [00:12<00:06, 335.16 examples/s]Map:  71%|███████   | 3994/5643 [00:13<00:04, 379.88 examples/s]Map:  65%|██████▍   | 3642/5643 [00:12<00:05, 349.64 examples/s]Map:  65%|██████▌   | 3680/5643 [00:12<00:05, 354.77 examples/s]Map:  72%|███████▏  | 4043/5643 [00:13<00:11, 139.13 examples/s]Map:  66%|██████▌   | 3719/5643 [00:12<00:05, 350.37 examples/s]Map:  72%|███████▏  | 4082/5643 [00:13<00:09, 166.51 examples/s]Map:  67%|██████▋   | 3762/5643 [00:12<00:05, 355.60 examples/s]Map:  73%|███████▎  | 4124/5643 [00:14<00:07, 195.79 examples/s]Map:  67%|██████▋   | 3802/5643 [00:12<00:05, 356.80 examples/s]Map:  71%|███████   | 4012/5643 [00:14<00:12, 125.93 examples/s]Map:  71%|███████▏  | 4028/5643 [00:13<00:12, 128.00 examples/s]Map:  74%|███████▍  | 4171/5643 [00:14<00:06, 230.11 examples/s]Map:  71%|███████   | 4000/5643 [00:13<00:12, 133.83 examples/s]Map:  72%|███████▏  | 4047/5643 [00:14<00:12, 130.04 examples/s]Map:  68%|██████▊   | 3852/5643 [00:13<00:04, 368.75 examples/s]Map:  71%|███████   | 4000/5643 [00:14<00:12, 128.53 examples/s]Map:  72%|███████▏  | 4055/5643 [00:14<00:10, 157.95 examples/s]Map:  72%|███████▏  | 4067/5643 [00:14<00:10, 156.48 examples/s]Map:  75%|███████▍  | 4214/5643 [00:14<00:05, 256.01 examples/s]Map:  72%|███████▏  | 4042/5643 [00:14<00:09, 162.75 examples/s]Map:  72%|███████▏  | 4090/5643 [00:14<00:09, 160.14 examples/s]Map:  69%|██████▉   | 3895/5643 [00:13<00:04, 372.26 examples/s]Map:  72%|███████▏  | 4038/5643 [00:14<00:10, 155.46 examples/s]Map:  73%|███████▎  | 4096/5643 [00:14<00:08, 190.86 examples/s]Map:  73%|███████▎  | 4115/5643 [00:14<00:07, 199.62 examples/s]Map:  75%|███████▌  | 4257/5643 [00:14<00:04, 279.41 examples/s]Map:  72%|███████▏  | 4089/5643 [00:14<00:07, 196.95 examples/s]Map:  73%|███████▎  | 4132/5643 [00:14<00:07, 190.68 examples/s]Map:  70%|██████▉   | 3940/5643 [00:13<00:04, 369.22 examples/s]Map:  74%|███████▎  | 4151/5643 [00:14<00:06, 225.62 examples/s]Map:  73%|███████▎  | 4135/5643 [00:14<00:06, 218.32 examples/s]Map:  72%|███████▏  | 4082/5643 [00:14<00:08, 188.82 examples/s]Map:  72%|███████▏  | 4040/5643 [00:14<00:12, 127.73 examples/s]Map:  76%|███████▌  | 4301/5643 [00:14<00:04, 309.25 examples/s]Map:  73%|███████▎  | 4132/5643 [00:14<00:06, 232.27 examples/s]Map:  74%|███████▍  | 4173/5643 [00:14<00:06, 224.18 examples/s]Map:  74%|███████▍  | 4178/5643 [00:14<00:05, 252.24 examples/s]Map:  71%|███████   | 3984/5643 [00:13<00:04, 371.44 examples/s]Map:  73%|███████▎  | 4130/5643 [00:14<00:06, 229.08 examples/s]Map:  72%|███████▏  | 4082/5643 [00:14<00:09, 157.46 examples/s]Map:  77%|███████▋  | 4342/5643 [00:14<00:03, 327.57 examples/s]Map:  75%|███████▍  | 4207/5643 [00:14<00:05, 260.47 examples/s]Map:  75%|███████▍  | 4210/5643 [00:14<00:05, 245.30 examples/s]Map:  74%|███████▍  | 4188/5643 [00:14<00:05, 261.74 examples/s]Map:  74%|███████▍  | 4172/5643 [00:14<00:05, 256.19 examples/s]Map:  73%|███████▎  | 4129/5643 [00:14<00:07, 195.83 examples/s]Map:  78%|███████▊  | 4382/5643 [00:14<00:03, 339.07 examples/s]Map:  75%|███████▌  | 4244/5643 [00:14<00:05, 278.46 examples/s]Map:  75%|███████▌  | 4233/5643 [00:14<00:05, 280.25 examples/s]Map:  75%|███████▌  | 4254/5643 [00:14<00:05, 276.14 examples/s]Map:  75%|███████▍  | 4227/5643 [00:14<00:05, 282.26 examples/s]Map:  75%|███████▍  | 4215/5643 [00:14<00:05, 283.18 examples/s]Map:  74%|███████▍  | 4170/5643 [00:14<00:06, 224.67 examples/s]Map:  76%|███████▌  | 4285/5643 [00:14<00:04, 302.18 examples/s]Map:  78%|███████▊  | 4425/5643 [00:14<00:03, 344.16 examples/s]Map:  76%|███████▌  | 4280/5643 [00:14<00:04, 308.30 examples/s]Map:  76%|███████▌  | 4298/5643 [00:14<00:04, 306.22 examples/s]Map:  76%|███████▌  | 4275/5643 [00:14<00:04, 310.22 examples/s]Map:  75%|███████▌  | 4256/5643 [00:14<00:04, 301.69 examples/s]Map:  75%|███████▍  | 4215/5643 [00:14<00:05, 255.67 examples/s]Map:  79%|███████▉  | 4465/5643 [00:15<00:03, 351.74 examples/s]Map:  77%|███████▋  | 4330/5643 [00:14<00:04, 323.02 examples/s]Map:  77%|███████▋  | 4320/5643 [00:14<00:04, 319.39 examples/s]Map:  77%|███████▋  | 4341/5643 [00:15<00:04, 324.39 examples/s]Map:  77%|███████▋  | 4318/5643 [00:14<00:04, 331.10 examples/s]Map:  76%|███████▌  | 4302/5643 [00:14<00:04, 328.22 examples/s]Map:  75%|███████▌  | 4256/5643 [00:14<00:04, 278.78 examples/s]Map:  77%|███████▋  | 4357/5643 [00:15<00:03, 330.85 examples/s]Map:  80%|███████▉  | 4512/5643 [00:15<00:03, 363.06 examples/s]Map:  78%|███████▊  | 4391/5643 [00:14<00:03, 345.87 examples/s]Map:  78%|███████▊  | 4386/5643 [00:15<00:03, 340.90 examples/s]Map:  77%|███████▋  | 4364/5643 [00:14<00:03, 344.74 examples/s]Map:  77%|███████▋  | 4343/5643 [00:14<00:03, 339.94 examples/s]Map:  78%|███████▊  | 4395/5643 [00:15<00:03, 342.94 examples/s]Map:  76%|███████▌  | 4302/5643 [00:14<00:04, 307.06 examples/s]Map:  81%|████████  | 4551/5643 [00:15<00:03, 363.22 examples/s]Map:  78%|███████▊  | 4424/5643 [00:15<00:03, 340.53 examples/s]Map:  78%|███████▊  | 4402/5643 [00:15<00:03, 346.89 examples/s]Map:  79%|███████▊  | 4441/5643 [00:15<00:03, 336.36 examples/s]Map:  78%|███████▊  | 4387/5643 [00:15<00:03, 354.32 examples/s]Map:  81%|████████▏ | 4590/5643 [00:15<00:02, 362.68 examples/s]Map:  77%|███████▋  | 4344/5643 [00:15<00:04, 322.64 examples/s]Map:  79%|███████▉  | 4452/5643 [00:15<00:03, 348.19 examples/s]Map:  79%|███████▉  | 4465/5643 [00:15<00:03, 352.19 examples/s]Map:  79%|███████▉  | 4448/5643 [00:15<00:03, 356.71 examples/s]Map:  78%|███████▊  | 4426/5643 [00:15<00:03, 351.21 examples/s]Map:  80%|███████▉  | 4490/5643 [00:15<00:03, 354.98 examples/s]Map:  82%|████████▏ | 4629/5643 [00:15<00:02, 363.04 examples/s]Map:  72%|███████▏  | 4042/5643 [00:14<00:10, 146.44 examples/s]Map:  78%|███████▊  | 4387/5643 [00:15<00:03, 341.57 examples/s]Map:  80%|███████▉  | 4494/5643 [00:15<00:03, 359.97 examples/s]Map:  80%|███████▉  | 4510/5643 [00:15<00:03, 361.18 examples/s]Map:  80%|███████▉  | 4490/5643 [00:15<00:03, 367.04 examples/s]Map:  80%|████████  | 4530/5643 [00:15<00:03, 360.51 examples/s]Map:  83%|████████▎ | 4674/5643 [00:15<00:02, 382.09 examples/s]Map:  79%|███████▉  | 4473/5643 [00:15<00:03, 360.40 examples/s]Map:  78%|███████▊  | 4427/5643 [00:15<00:03, 345.21 examples/s]Map:  72%|███████▏  | 4089/5643 [00:14<00:08, 179.36 examples/s]Map:  80%|████████  | 4536/5643 [00:15<00:03, 367.77 examples/s]Map:  81%|████████  | 4548/5643 [00:15<00:02, 365.34 examples/s]Map:  80%|████████  | 4531/5643 [00:15<00:03, 362.34 examples/s]Map:  84%|████████▎ | 4714/5643 [00:15<00:02, 385.85 examples/s]Map:  81%|████████  | 4579/5643 [00:15<00:02, 380.95 examples/s]Map:  80%|████████  | 4515/5643 [00:15<00:03, 360.87 examples/s]Map:  79%|███████▉  | 4467/5643 [00:15<00:03, 347.08 examples/s]Map:  73%|███████▎  | 4130/5643 [00:14<00:07, 205.24 examples/s]Map:  81%|████████  | 4580/5643 [00:15<00:02, 385.52 examples/s]Map:  81%|████████▏ | 4588/5643 [00:15<00:02, 369.82 examples/s]Map:  84%|████████▍ | 4765/5643 [00:15<00:02, 402.66 examples/s]Map:  81%|████████  | 4576/5643 [00:15<00:02, 361.88 examples/s]Map:  81%|████████  | 4554/5643 [00:15<00:03, 361.97 examples/s]Map:  82%|████████▏ | 4625/5643 [00:15<00:02, 378.27 examples/s]Map:  80%|███████▉  | 4508/5643 [00:15<00:03, 354.76 examples/s]Map:  74%|███████▍  | 4166/5643 [00:14<00:06, 229.66 examples/s]Map:  82%|████████▏ | 4621/5643 [00:15<00:02, 382.24 examples/s]Map:  82%|████████▏ | 4643/5643 [00:15<00:02, 362.64 examples/s]Map:  85%|████████▌ | 4818/5643 [00:15<00:01, 427.42 examples/s]Map:  81%|████████  | 4555/5643 [00:15<00:02, 378.02 examples/s]Map:  81%|████████▏ | 4593/5643 [00:15<00:02, 354.13 examples/s]Map:  83%|████████▎ | 4680/5643 [00:15<00:02, 400.64 examples/s]Map:  75%|███████▍  | 4216/5643 [00:14<00:05, 264.68 examples/s]Map:  82%|████████▏ | 4631/5643 [00:15<00:02, 355.48 examples/s]Map:  83%|████████▎ | 4678/5643 [00:15<00:02, 372.20 examples/s]Map:  83%|████████▎ | 4680/5643 [00:15<00:02, 354.29 examples/s]Map:  81%|████████▏ | 4595/5643 [00:15<00:02, 373.08 examples/s]Map:  84%|████████▎ | 4721/5643 [00:15<00:02, 397.16 examples/s]Map:  82%|████████▏ | 4642/5643 [00:15<00:02, 365.49 examples/s]Map:  86%|████████▋ | 4877/5643 [00:16<00:01, 385.08 examples/s]Map:  84%|████████▎ | 4720/5643 [00:15<00:02, 371.53 examples/s]Map:  84%|████████▎ | 4719/5643 [00:16<00:02, 354.26 examples/s]Map:  83%|████████▎ | 4688/5643 [00:15<00:02, 354.93 examples/s]Map:  76%|███████▌  | 4275/5643 [00:14<00:04, 286.42 examples/s]Map:  82%|████████▏ | 4639/5643 [00:15<00:02, 371.12 examples/s]Map:  85%|████████▍ | 4770/5643 [00:15<00:02, 396.52 examples/s]Map:  83%|████████▎ | 4684/5643 [00:15<00:02, 364.23 examples/s]Map:  87%|████████▋ | 4917/5643 [00:16<00:01, 369.70 examples/s]Map:  85%|████████▍ | 4771/5643 [00:16<00:02, 392.52 examples/s]Map:  84%|████████▍ | 4733/5643 [00:15<00:02, 376.22 examples/s]Map:  84%|████████▍ | 4767/5643 [00:16<00:02, 367.51 examples/s]Map:  77%|███████▋  | 4317/5643 [00:14<00:04, 304.80 examples/s]Map:  83%|████████▎ | 4681/5643 [00:16<00:02, 357.41 examples/s]Map:  85%|████████▌ | 4823/5643 [00:16<00:02, 402.48 examples/s]Map:  84%|████████▍ | 4731/5643 [00:16<00:02, 368.95 examples/s]Map:  88%|████████▊ | 4961/5643 [00:16<00:01, 373.32 examples/s]Map:  85%|████████▌ | 4810/5643 [00:16<00:02, 380.76 examples/s]Map:  85%|████████▍ | 4781/5643 [00:16<00:02, 373.81 examples/s]Map:  77%|███████▋  | 4364/5643 [00:15<00:03, 328.57 examples/s]Map:  86%|████████▌ | 4831/5643 [00:16<00:02, 388.50 examples/s]Map:  84%|████████▎ | 4722/5643 [00:16<00:02, 360.29 examples/s]Map:  85%|████████▍ | 4779/5643 [00:16<00:02, 382.29 examples/s]Map:  86%|████████▋ | 4878/5643 [00:16<00:02, 380.22 examples/s]Map:  86%|████████▌ | 4825/5643 [00:16<00:02, 387.65 examples/s]Map:  78%|███████▊  | 4403/5643 [00:15<00:03, 330.60 examples/s]Map:  86%|████████▌ | 4862/5643 [00:16<00:02, 359.05 examples/s]Map:  85%|████████▌ | 4824/5643 [00:16<00:02, 384.73 examples/s]Map:  87%|████████▋ | 4884/5643 [00:16<00:02, 370.03 examples/s]Map:  85%|████████▍ | 4779/5643 [00:16<00:02, 361.29 examples/s]Map:  79%|███████▊  | 4443/5643 [00:15<00:03, 336.81 examples/s]Map:  87%|████████▋ | 4901/5643 [00:16<00:02, 360.51 examples/s]Map:  88%|████████▊ | 4939/5643 [00:16<00:01, 369.38 examples/s]Map:  86%|████████▋ | 4881/5643 [00:16<00:02, 362.66 examples/s]Map:  87%|████████▋ | 4925/5643 [00:16<00:01, 362.19 examples/s]Map:  85%|████████▌ | 4822/5643 [00:16<00:02, 365.85 examples/s]Map:  86%|████████▋ | 4881/5643 [00:16<00:02, 368.86 examples/s]Map:  80%|███████▉  | 4490/5643 [00:15<00:03, 360.96 examples/s]Map:  88%|████████▊ | 4977/5643 [00:16<00:01, 365.60 examples/s]Map:  87%|████████▋ | 4920/5643 [00:16<00:02, 350.97 examples/s]Map:  88%|████████▊ | 4963/5643 [00:16<00:01, 359.78 examples/s]Map:  88%|████████▊ | 4959/5643 [00:16<00:01, 358.67 examples/s]Map:  80%|████████  | 4531/5643 [00:15<00:03, 354.45 examples/s]Map:  86%|████████▋ | 4878/5643 [00:16<00:02, 359.56 examples/s]Map:  87%|████████▋ | 4935/5643 [00:16<00:01, 359.46 examples/s]Map:  88%|████████▊ | 4961/5643 [00:16<00:01, 353.15 examples/s]Map:  81%|████████  | 4575/5643 [00:15<00:02, 362.46 examples/s]Map:  87%|████████▋ | 4921/5643 [00:16<00:01, 366.57 examples/s]Map:  88%|████████▊ | 4976/5643 [00:16<00:01, 360.12 examples/s]Map:  89%|████████▊ | 5000/5643 [00:17<00:04, 142.47 examples/s]Map:  82%|████████▏ | 4631/5643 [00:15<00:02, 354.09 examples/s]Map:  88%|████████▊ | 4978/5643 [00:16<00:01, 354.44 examples/s]Map:  89%|████████▉ | 5038/5643 [00:17<00:03, 170.61 examples/s]Map:  83%|████████▎ | 4669/5643 [00:15<00:02, 351.31 examples/s]Map:  90%|█████████ | 5083/5643 [00:17<00:02, 210.58 examples/s]Map:  83%|████████▎ | 4709/5643 [00:16<00:02, 357.76 examples/s]Map:  91%|█████████ | 5119/5643 [00:17<00:02, 234.55 examples/s]Map:  84%|████████▍ | 4756/5643 [00:16<00:02, 372.97 examples/s]Map:  91%|█████████▏| 5156/5643 [00:17<00:01, 258.05 examples/s]Map:  89%|████████▊ | 5000/5643 [00:17<00:04, 133.26 examples/s]Map:  89%|████████▉ | 5019/5643 [00:17<00:04, 138.09 examples/s]Map:  89%|████████▊ | 5000/5643 [00:17<00:04, 135.85 examples/s]Map:  85%|████████▌ | 4814/5643 [00:16<00:02, 365.09 examples/s]Map:  92%|█████████▏| 5201/5643 [00:17<00:01, 281.15 examples/s]Map:  89%|████████▉ | 5039/5643 [00:17<00:03, 162.87 examples/s]Map:  90%|████████▉ | 5063/5643 [00:17<00:03, 169.03 examples/s]Map:  89%|████████▊ | 5000/5643 [00:17<00:04, 130.18 examples/s]Map:  89%|████████▉ | 5040/5643 [00:17<00:03, 163.60 examples/s]Map:  93%|█████████▎| 5245/5643 [00:17<00:01, 306.81 examples/s]Map:  86%|████████▋ | 4871/5643 [00:16<00:02, 355.00 examples/s]Map:  90%|█████████ | 5088/5643 [00:17<00:02, 203.02 examples/s]Map:  89%|████████▉ | 5039/5643 [00:17<00:03, 159.80 examples/s]Map:  91%|█████████ | 5111/5643 [00:17<00:02, 205.34 examples/s]Map:  89%|████████▉ | 5020/5643 [00:17<00:04, 135.87 examples/s]Map:  90%|█████████ | 5088/5643 [00:17<00:02, 202.24 examples/s]Map:  94%|█████████▎| 5285/5643 [00:17<00:01, 326.37 examples/s]Map:  91%|█████████ | 5130/5643 [00:17<00:02, 236.40 examples/s]Map:  87%|████████▋ | 4911/5643 [00:16<00:02, 350.45 examples/s]Map:  90%|█████████ | 5088/5643 [00:17<00:02, 200.92 examples/s]Map:  90%|████████▉ | 5067/5643 [00:17<00:03, 169.68 examples/s]Map:  89%|████████▉ | 5028/5643 [00:17<00:04, 145.70 examples/s]Map:  91%|█████████▏| 5161/5643 [00:17<00:02, 239.00 examples/s]Map:  91%|█████████ | 5131/5643 [00:17<00:02, 235.01 examples/s]Map:  94%|█████████▍| 5322/5643 [00:17<00:00, 334.30 examples/s]Map:  92%|█████████▏| 5170/5643 [00:17<00:01, 263.84 examples/s]Map:  88%|████████▊ | 4951/5643 [00:16<00:01, 350.46 examples/s]Map:  91%|█████████ | 5134/5643 [00:17<00:02, 237.22 examples/s]Map:  91%|█████████ | 5111/5643 [00:17<00:02, 204.19 examples/s]Map:  90%|████████▉ | 5061/5643 [00:17<00:03, 165.99 examples/s]Map:  92%|█████████▏| 5201/5643 [00:17<00:01, 264.36 examples/s]Map:  92%|█████████▏| 5167/5643 [00:17<00:01, 251.50 examples/s]Map:  95%|█████████▌| 5361/5643 [00:18<00:00, 345.58 examples/s]Map:  92%|█████████▏| 5208/5643 [00:17<00:01, 283.86 examples/s]Map:  89%|████████▊ | 4996/5643 [00:16<00:01, 362.04 examples/s]Map:  91%|█████████▏| 5154/5643 [00:17<00:02, 237.51 examples/s]Map:  90%|█████████ | 5105/5643 [00:17<00:02, 201.69 examples/s]Map:  93%|█████████▎| 5241/5643 [00:17<00:01, 287.65 examples/s]Map:  92%|█████████▏| 5178/5643 [00:17<00:01, 260.49 examples/s]Map:  96%|█████████▌| 5403/5643 [00:18<00:00, 352.76 examples/s]Map:  92%|█████████▏| 5202/5643 [00:18<00:01, 259.82 examples/s]Map:  93%|█████████▎| 5245/5643 [00:18<00:01, 303.02 examples/s]Map:  91%|█████████ | 5146/5643 [00:17<00:02, 232.65 examples/s]Map:  92%|█████████▏| 5194/5643 [00:17<00:01, 259.10 examples/s]Map:  94%|█████████▎| 5286/5643 [00:17<00:01, 308.86 examples/s]Map:  93%|█████████▎| 5221/5643 [00:17<00:01, 280.92 examples/s]Map:  97%|█████████▋| 5449/5643 [00:18<00:00, 357.73 examples/s]Map:  93%|█████████▎| 5241/5643 [00:18<00:01, 276.75 examples/s]Map:  92%|█████████▏| 5185/5643 [00:18<00:01, 257.45 examples/s]Map:  93%|█████████▎| 5239/5643 [00:18<00:01, 292.15 examples/s]Map:  94%|█████████▍| 5304/5643 [00:18<00:01, 323.44 examples/s]Map:  94%|█████████▍| 5330/5643 [00:18<00:00, 328.42 examples/s]Map:  93%|█████████▎| 5262/5643 [00:18<00:01, 298.53 examples/s]Map:  97%|█████████▋| 5489/5643 [00:18<00:00, 362.53 examples/s]Map:  94%|█████████▎| 5281/5643 [00:18<00:01, 290.51 examples/s]Map:  93%|█████████▎| 5224/5643 [00:18<00:01, 277.68 examples/s]Map:  94%|█████████▎| 5278/5643 [00:18<00:01, 300.78 examples/s]Map:  95%|█████████▌| 5373/5643 [00:18<00:00, 349.38 examples/s]Map:  95%|█████████▍| 5352/5643 [00:18<00:00, 339.88 examples/s]Map:  98%|█████████▊| 5531/5643 [00:18<00:00, 370.27 examples/s]Map:  94%|█████████▍| 5306/5643 [00:18<00:01, 320.15 examples/s]Map:  94%|█████████▍| 5325/5643 [00:18<00:01, 315.46 examples/s]Map:  93%|█████████▎| 5265/5643 [00:18<00:01, 302.11 examples/s]Map:  96%|█████████▌| 5391/5643 [00:18<00:00, 345.87 examples/s]Map:  99%|█████████▊| 5572/5643 [00:18<00:00, 372.88 examples/s]Map:  94%|█████████▍| 5325/5643 [00:18<00:00, 318.23 examples/s]Map:  95%|█████████▍| 5348/5643 [00:18<00:00, 332.86 examples/s]Map:  96%|█████████▌| 5426/5643 [00:18<00:00, 344.30 examples/s]Map:  95%|█████████▌| 5377/5643 [00:18<00:00, 341.09 examples/s]Map:  94%|█████████▍| 5306/5643 [00:18<00:01, 321.95 examples/s]Map:  96%|█████████▌| 5430/5643 [00:18<00:00, 349.57 examples/s]Map:  99%|█████████▉| 5613/5643 [00:18<00:00, 375.98 examples/s]Map:  95%|█████████▌| 5368/5643 [00:18<00:00, 337.92 examples/s]Map:  96%|█████████▌| 5396/5643 [00:18<00:00, 355.81 examples/s]Map:  97%|█████████▋| 5470/5643 [00:18<00:00, 362.23 examples/s]Map:  96%|█████████▌| 5419/5643 [00:18<00:00, 349.19 examples/s]Map:  95%|█████████▍| 5345/5643 [00:18<00:00, 333.15 examples/s]Map:  97%|█████████▋| 5474/5643 [00:18<00:00, 366.70 examples/s]Map:  96%|█████████▌| 5411/5643 [00:18<00:00, 349.46 examples/s]Map:  96%|█████████▋| 5438/5643 [00:18<00:00, 359.68 examples/s]Map:  98%|█████████▊| 5511/5643 [00:18<00:00, 366.37 examples/s]Map:  97%|█████████▋| 5464/5643 [00:18<00:00, 362.17 examples/s]Map:  89%|████████▉ | 5036/5643 [00:17<00:04, 137.60 examples/s]Map:  96%|█████████▌| 5391/5643 [00:18<00:00, 353.11 examples/s]Map:  98%|█████████▊| 5515/5643 [00:18<00:00, 364.39 examples/s]Map:  97%|█████████▋| 5460/5643 [00:18<00:00, 362.76 examples/s]Map:  97%|█████████▋| 5482/5643 [00:18<00:00, 364.47 examples/s]Map:  99%|█████████▊| 5559/5643 [00:18<00:00, 375.60 examples/s]Map:  98%|█████████▊| 5502/5643 [00:18<00:00, 351.23 examples/s]Map:  96%|█████████▋| 5432/5643 [00:18<00:00, 358.37 examples/s]Map:  90%|█████████ | 5088/5643 [00:17<00:03, 176.80 examples/s]Map:  99%|█████████▊| 5560/5643 [00:18<00:00, 366.67 examples/s]Map:  97%|█████████▋| 5500/5643 [00:18<00:00, 363.88 examples/s]Map:  98%|█████████▊| 5522/5643 [00:18<00:00, 365.43 examples/s]Map:  99%|█████████▉| 5600/5643 [00:18<00:00, 371.08 examples/s]Map:  98%|█████████▊| 5545/5643 [00:19<00:00, 357.63 examples/s]Map:  97%|█████████▋| 5474/5643 [00:18<00:00, 361.51 examples/s]Map:  91%|█████████ | 5132/5643 [00:17<00:02, 209.50 examples/s]Map:  99%|█████████▉| 5612/5643 [00:19<00:00, 387.52 examples/s]Map:  99%|█████████▊| 5563/5643 [00:18<00:00, 371.23 examples/s]Map: 100%|██████████| 5643/5643 [00:19<00:00, 294.20 examples/s]
Map:  98%|█████████▊| 5543/5643 [00:18<00:00, 362.09 examples/s]Map:  99%|█████████▉| 5588/5643 [00:19<00:00, 362.52 examples/s]Map:  98%|█████████▊| 5519/5643 [00:18<00:00, 372.63 examples/s]Map:  92%|█████████▏| 5174/5643 [00:17<00:01, 238.38 examples/s]Map:  99%|█████████▉| 5606/5643 [00:18<00:00, 371.66 examples/s]Map:  99%|█████████▉| 5586/5643 [00:19<00:00, 365.59 examples/s]Map: 100%|█████████▉| 5628/5643 [00:19<00:00, 365.82 examples/s]Map:  99%|█████████▊| 5560/5643 [00:19<00:00, 378.18 examples/s]Map:  92%|█████████▏| 5212/5643 [00:18<00:01, 254.91 examples/s]Map: 100%|█████████▉| 5628/5643 [00:19<00:00, 366.68 examples/s]Map:  99%|█████████▉| 5600/5643 [00:19<00:00, 373.29 examples/s]Map:  93%|█████████▎| 5253/5643 [00:18<00:01, 278.49 examples/s]Map: 100%|█████████▉| 5642/5643 [00:19<00:00, 368.68 examples/s]Map:  94%|█████████▍| 5292/5643 [00:18<00:01, 296.64 examples/s]Map: 100%|██████████| 5643/5643 [00:19<00:00, 177.42 examples/s]Map: 100%|██████████| 5643/5643 [00:19<00:00, 291.20 examples/s]
Map:  95%|█████████▍| 5336/5643 [00:18<00:00, 316.41 examples/s]Map: 100%|██████████| 5643/5643 [00:19<00:00, 288.25 examples/s]
Map:  95%|█████████▌| 5373/5643 [00:18<00:00, 323.54 examples/s]Map: 100%|██████████| 5643/5643 [00:19<00:00, 285.42 examples/s]
Map: 100%|██████████| 5643/5643 [00:19<00:00, 288.57 examples/s]
Map: 100%|██████████| 5643/5643 [00:19<00:00, 287.38 examples/s]
Map:  96%|█████████▌| 5425/5643 [00:18<00:00, 323.08 examples/s]Map: 100%|██████████| 5643/5643 [00:19<00:00, 285.58 examples/s]
Map:  97%|█████████▋| 5473/5643 [00:18<00:00, 340.12 examples/s]Map:  98%|█████████▊| 5512/5643 [00:18<00:00, 348.80 examples/s]Map:  99%|█████████▊| 5568/5643 [00:19<00:00, 342.24 examples/s]Map:  99%|█████████▉| 5610/5643 [00:19<00:00, 358.73 examples/s]Map: 100%|██████████| 5643/5643 [00:19<00:00, 285.46 examples/s]
INFO 08-18 21:12:25 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 08-18 21:12:25 [__init__.py:239] Automatically detected platform cuda.
INFO 08-18 21:12:29 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 08-18 21:12:29 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 08-18 21:12:29 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 08-18 21:12:29 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 08-18 21:12:29 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 08-18 21:12:29 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 08-18 21:12:29 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 08-18 21:12:29 [__init__.py:239] Automatically detected platform cuda.
INFO 08-18 21:12:29 [__init__.py:239] Automatically detected platform cuda.
INFO 08-18 21:12:29 [__init__.py:239] Automatically detected platform cuda.
INFO 08-18 21:12:29 [__init__.py:239] Automatically detected platform cuda.
INFO 08-18 21:12:29 [__init__.py:239] Automatically detected platform cuda.
INFO 08-18 21:12:29 [__init__.py:239] Automatically detected platform cuda.
INFO 08-18 21:12:29 [__init__.py:239] Automatically detected platform cuda.
[2025-08-18 21:12:39,393] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-08-18 21:12:39,395] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-08-18 21:12:40,459] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:12:40,663] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-08-18 21:12:40,776] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-08-18 21:12:40,805] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-08-18 21:12:40,843] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-08-18 21:12:40,858] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-08-18 21:12:40,863] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-08-18 21:12:40,927] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-08-18 21:12:42,431] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:12:42,450] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:12:42,469] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:12:42,485] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:12:42,526] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:12:42,549] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:12:42,583] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:12:54,914] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 443, num_elems = 14.77B
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:11<00:57, 11.53s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:11<00:59, 11.92s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:12<01:00, 12.05s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:12<01:00, 12.17s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:12<01:01, 12.37s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:12<01:01, 12.35s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:14<01:12, 14.40s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:15<00:28,  7.12s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:15<00:28,  7.14s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:15<00:28,  7.20s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:15<00:28,  7.24s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:15<00:28,  7.23s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:15<00:28,  7.23s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:15<00:27,  6.84s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:20<01:43, 20.73s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:34<00:36, 12.32s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:34<00:36, 12.28s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:34<00:36, 12.31s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:34<00:36, 12.11s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:34<00:36, 12.28s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:34<00:36, 12.33s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:34<00:36, 12.33s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:38<01:14, 18.70s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:50<00:27, 13.99s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:50<00:27, 13.86s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:50<00:27, 14.00s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:50<00:27, 14.00s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:50<00:28, 14.00s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:50<00:27, 13.97s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:50<00:27, 13.98s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:55<00:53, 17.97s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [01:08<00:15, 15.39s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [01:08<00:15, 15.39s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [01:08<00:15, 15.41s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [01:08<00:15, 15.41s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [01:08<00:15, 15.33s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [01:08<00:15, 15.41s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [01:08<00:15, 15.41s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [01:12<00:35, 17.76s/it]Loading checkpoint shards: 100%|██████████| 6/6 [01:19<00:00, 13.83s/it]Loading checkpoint shards: 100%|██████████| 6/6 [01:19<00:00, 13.26s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [01:19<00:00, 13.84s/it]Loading checkpoint shards: 100%|██████████| 6/6 [01:19<00:00, 13.23s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [01:19<00:00, 13.84s/it]Loading checkpoint shards: 100%|██████████| 6/6 [01:19<00:00, 13.26s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [01:19<00:00, 13.78s/it]Loading checkpoint shards: 100%|██████████| 6/6 [01:19<00:00, 13.26s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [01:19<00:00, 13.84s/it]Loading checkpoint shards: 100%|██████████| 6/6 [01:19<00:00, 13.25s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [01:19<00:00, 13.83s/it]Loading checkpoint shards: 100%|██████████| 6/6 [01:19<00:00, 13.25s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [01:19<00:00, 13.84s/it]Loading checkpoint shards: 100%|██████████| 6/6 [01:19<00:00, 13.26s/it]
[2025-08-18 21:14:14,995] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:14:15,030] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:14:15,046] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:14:15,059] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:14:15,059] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:14:15,067] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:14:15,077] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
Loading checkpoint shards:  83%|████████▎ | 5/6 [01:27<00:16, 16.82s/it]Loading checkpoint shards: 100%|██████████| 6/6 [01:43<00:00, 16.32s/it]Loading checkpoint shards: 100%|██████████| 6/6 [01:43<00:00, 17.17s/it]
[2025-08-18 21:14:38,388] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:01,  2.52it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:01,  2.56it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:02,  2.45it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:02,  2.25it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:02,  2.25it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:02,  2.31it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:02,  1.72it/s][2025-08-18 21:14:42,104] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 886, num_elems = 29.54B
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:08<00:20,  5.02s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:08<00:20,  5.03s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:08<00:20,  5.05s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:08<00:20,  5.01s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:08<00:20,  5.03s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:08<00:20,  5.04s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:08<00:20,  5.06s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:11<00:55, 11.08s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:20<00:24,  8.06s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:20<00:24,  8.06s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:20<00:24,  8.06s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:20<00:24,  8.04s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:20<00:24,  8.06s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:20<00:24,  8.07s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:20<00:24,  8.06s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:22<00:44, 11.14s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:30<00:18,  9.06s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:30<00:18,  9.06s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:30<00:18,  9.06s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:30<00:18,  9.05s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:30<00:18,  9.06s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:30<00:18,  9.06s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:30<00:18,  9.06s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:33<00:33, 11.07s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:42<00:09,  9.95s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:42<00:09,  9.95s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:42<00:09,  9.95s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:42<00:09,  9.95s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:42<00:09,  9.95s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:42<00:09,  9.95s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:42<00:09,  9.94s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:44<00:22, 11.04s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:49<00:00,  9.05s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:49<00:00,  9.06s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:49<00:00,  8.30s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:49<00:00,  8.30s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:49<00:00,  9.06s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:49<00:00,  8.30s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:49<00:00,  9.06s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:49<00:00,  9.06s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:49<00:00,  8.30s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:49<00:00,  8.30s/it]

Loading checkpoint shards: 100%|██████████| 6/6 [00:49<00:00,  9.06s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:49<00:00,  8.30s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:49<00:00,  9.06s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:49<00:00,  8.30s/it]
Loading checkpoint shards:  83%|████████▎ | 5/6 [00:53<00:10, 10.34s/it]Loading checkpoint shards: 100%|██████████| 6/6 [01:03<00:00, 10.26s/it]Loading checkpoint shards: 100%|██████████| 6/6 [01:03<00:00, 10.58s/it]
Batch size input size for gen: 1 x 64 = 64
[2025-08-18 21:15:47,741][trainers.vllm_client.utils][INFO] - Server is up!
Initializing communicator...
INFO 08-18 21:15:48 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 08-18 21:15:48 [pynccl.py:69] vLLM is using nccl==2.21.5
Communicator initialized!
[2025-08-18 21:15:49,272][trainers.vllm_client.utils][INFO] - Server is up!
Initializing communicator...
INFO 08-18 21:15:49 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 08-18 21:15:49 [pynccl.py:69] vLLM is using nccl==2.21.5
Communicator initialized!
[2025-08-18 21:15:50,615][trainers.vllm_client.utils][INFO] - Server is up!
Initializing communicator...
INFO 08-18 21:15:51 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 08-18 21:15:51 [pynccl.py:69] vLLM is using nccl==2.21.5
Communicator initialized!
[2025-08-18 21:15:51,968][trainers.vllm_client.utils][INFO] - Server is up!
Initializing communicator...
INFO 08-18 21:15:52 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 08-18 21:15:52 [pynccl.py:69] vLLM is using nccl==2.21.5
Communicator initialized!
[2025-08-18 21:15:53,343][trainers.vllm_client.utils][INFO] - Server is up!
Initializing communicator...
INFO 08-18 21:15:53 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 08-18 21:15:53 [pynccl.py:69] vLLM is using nccl==2.21.5
Communicator initialized!
[2025-08-18 21:15:54,551][trainers.vllm_client.utils][INFO] - Server is up!
Initializing communicator...
INFO 08-18 21:15:54 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 08-18 21:15:54 [pynccl.py:69] vLLM is using nccl==2.21.5
Communicator initialized!
[2025-08-18 21:15:55,919][trainers.vllm_client.utils][INFO] - Server is up!
Initializing communicator...
INFO 08-18 21:15:56 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 08-18 21:15:56 [pynccl.py:69] vLLM is using nccl==2.21.5
Communicator initialized!
[2025-08-18 21:15:57,547][trainers.vllm_client.utils][INFO] - Server is up!
Initializing communicator...
INFO 08-18 21:15:57 [utils.py:1055] Found nccl from library libnccl.so.2
INFO 08-18 21:15:57 [pynccl.py:69] vLLM is using nccl==2.21.5
Communicator initialized!
[2025-08-18 21:15:59,367] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.15.4, git-hash=unknown, git-branch=unknown
[2025-08-18 21:15:59,368] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:15:59,368] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:15:59,368] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:15:59,372] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:15:59,372] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:15:59,377] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:15:59,377] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:15:59,380] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:15:59,431] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-08-18 21:15:59,435] [INFO] [logging.py:128:log_dist] [Rank 0] Creating ZeRO Offload
[2025-08-18 21:15:59,756] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2025-08-18 21:15:59,758] [INFO] [utils.py:782:see_memory_usage] MA 6.88 GB         Max_MA 11.04 GB         CA 19.65 GB         Max_CA 76 GB 
[2025-08-18 21:15:59,759] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 122.86 GB, percent = 8.1%
Parameter Offload: Total persistent parameters: 424960 in 161 params
[2025-08-18 21:15:59,839] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:15:59,847] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:15:59,853] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:15:59,857] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:15:59,861] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:15:59,872] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:15:59,877] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:16:00,291] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2025-08-18 21:16:00,301] [INFO] [utils.py:782:see_memory_usage] MA 6.88 GB         Max_MA 6.88 GB         CA 19.65 GB         Max_CA 20 GB 
[2025-08-18 21:16:00,302] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 122.87 GB, percent = 8.1%
[2025-08-18 21:16:00,312] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[2025-08-18 21:16:00,312] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-08-18 21:16:00,313] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-08-18 21:16:00,313] [INFO] [config.py:1003:print]   amp_enabled .................. False
[2025-08-18 21:16:00,314] [INFO] [config.py:1003:print]   amp_params ................... False
[2025-08-18 21:16:00,314] [INFO] [config.py:1003:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-08-18 21:16:00,315] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[2025-08-18 21:16:00,315] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[2025-08-18 21:16:00,316] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[2025-08-18 21:16:00,332] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[2025-08-18 21:16:00,333] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[2025-08-18 21:16:00,335] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x147cb8198550>
[2025-08-18 21:16:00,335] [INFO] [config.py:1003:print]   communication_data_type ...... None
[2025-08-18 21:16:00,336] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-08-18 21:16:00,337] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[2025-08-18 21:16:00,337] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[2025-08-18 21:16:00,337] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-08-18 21:16:00,338] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[2025-08-18 21:16:00,338] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[2025-08-18 21:16:00,338] [INFO] [config.py:1003:print]   disable_allgather ............ False
[2025-08-18 21:16:00,339] [INFO] [config.py:1003:print]   dump_state ................... False
[2025-08-18 21:16:00,339] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[2025-08-18 21:16:00,339] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[2025-08-18 21:16:00,339] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[2025-08-18 21:16:00,340] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-08-18 21:16:00,340] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[2025-08-18 21:16:00,340] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[2025-08-18 21:16:00,341] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[2025-08-18 21:16:00,341] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[2025-08-18 21:16:00,342] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[2025-08-18 21:16:00,343] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[2025-08-18 21:16:00,344] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-08-18 21:16:00,344] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[2025-08-18 21:16:00,345] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[2025-08-18 21:16:00,346] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[2025-08-18 21:16:00,347] [INFO] [config.py:1003:print]   global_rank .................. 0
[2025-08-18 21:16:00,347] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[2025-08-18 21:16:00,348] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 64
[2025-08-18 21:16:00,351] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[2025-08-18 21:16:00,351] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[2025-08-18 21:16:00,352] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[2025-08-18 21:16:00,355] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-08-18 21:16:00,356] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[2025-08-18 21:16:00,356] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[2025-08-18 21:16:00,356] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[2025-08-18 21:16:00,357] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[2025-08-18 21:16:00,357] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[2025-08-18 21:16:00,357] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[2025-08-18 21:16:00,358] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-08-18 21:16:00,358] [INFO] [config.py:1003:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-08-18 21:16:00,359] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[2025-08-18 21:16:00,359] [INFO] [config.py:1003:print]   optimizer_name ............... None
[2025-08-18 21:16:00,359] [INFO] [config.py:1003:print]   optimizer_params ............. None
[2025-08-18 21:16:00,360] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-08-18 21:16:00,362] [INFO] [config.py:1003:print]   pld_enabled .................. False
[2025-08-18 21:16:00,363] [INFO] [config.py:1003:print]   pld_params ................... False
[2025-08-18 21:16:00,368] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[2025-08-18 21:16:00,368] [INFO] [config.py:1003:print]   scheduler_name ............... None
[2025-08-18 21:16:00,369] [INFO] [config.py:1003:print]   scheduler_params ............. None
[2025-08-18 21:16:00,372] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[2025-08-18 21:16:00,373] [INFO] [config.py:1003:print]   sparse_attention ............. None
[2025-08-18 21:16:00,376] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[2025-08-18 21:16:00,376] [INFO] [config.py:1003:print]   steps_per_print .............. inf
[2025-08-18 21:16:00,376] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[2025-08-18 21:16:00,377] [INFO] [config.py:1003:print]   train_batch_size ............. 32768
[2025-08-18 21:16:00,377] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  64
[2025-08-18 21:16:00,377] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[2025-08-18 21:16:00,377] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[2025-08-18 21:16:00,378] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[2025-08-18 21:16:00,378] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[2025-08-18 21:16:00,380] [INFO] [config.py:1003:print]   world_size ................... 8
[2025-08-18 21:16:00,381] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[2025-08-18 21:16:00,382] [INFO] [config.py:1003:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-08-18 21:16:00,402] [INFO] [config.py:1003:print]   zero_enabled ................. True
[2025-08-18 21:16:00,403] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[2025-08-18 21:16:00,412] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 3
[2025-08-18 21:16:00,413] [INFO] [config.py:989:print_user_config]   json = {
    "train_batch_size": 3.276800e+04, 
    "train_micro_batch_size_per_gpu": 64, 
    "gradient_accumulation_steps": 64, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_optimization.reduce_bucket_size": 2.621440e+07, 
    "zero_optimization.stage3_param_persistence_threshold": 5.120000e+04, 
    "zero_optimization.stage3_prefetch_bucket_size": 2.359296e+07
}
[2025-08-18 21:16:00,664] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:02,  2.45it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  3.74it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:02,  2.74it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:03,  2.31it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:02,  3.29it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:02,  2.81it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:02,  2.42it/s][2025-08-18 21:16:01,732] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 1329, num_elems = 44.30B
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:05<00:19,  3.22s/it]Loading checkpoint shards:  25%|██▌       | 2/8 [00:05<00:18,  3.09s/it]Loading checkpoint shards:  25%|██▌       | 2/8 [00:05<00:18,  3.08s/it]Loading checkpoint shards:  25%|██▌       | 2/8 [00:05<00:19,  3.17s/it]Loading checkpoint shards:  25%|██▌       | 2/8 [00:05<00:18,  3.07s/it]Loading checkpoint shards:  25%|██▌       | 2/8 [00:05<00:19,  3.24s/it]Loading checkpoint shards:  25%|██▌       | 2/8 [00:05<00:19,  3.24s/it]Loading checkpoint shards:  12%|█▎        | 1/8 [00:11<01:22, 11.84s/it]Loading checkpoint shards:  38%|███▊      | 3/8 [00:19<00:39,  7.90s/it]Loading checkpoint shards:  38%|███▊      | 3/8 [00:18<00:39,  7.85s/it]Loading checkpoint shards:  38%|███▊      | 3/8 [00:18<00:39,  7.85s/it]Loading checkpoint shards:  38%|███▊      | 3/8 [00:19<00:39,  7.92s/it]Loading checkpoint shards:  38%|███▊      | 3/8 [00:19<00:39,  7.94s/it]Loading checkpoint shards:  38%|███▊      | 3/8 [00:19<00:39,  7.94s/it]Loading checkpoint shards:  38%|███▊      | 3/8 [00:18<00:39,  7.86s/it]Loading checkpoint shards:  25%|██▌       | 2/8 [00:25<01:18, 13.05s/it]Loading checkpoint shards:  50%|█████     | 4/8 [00:33<00:41, 10.33s/it]Loading checkpoint shards:  50%|█████     | 4/8 [00:33<00:41, 10.33s/it]Loading checkpoint shards:  50%|█████     | 4/8 [00:33<00:41, 10.38s/it]Loading checkpoint shards:  50%|█████     | 4/8 [00:33<00:41, 10.36s/it]Loading checkpoint shards:  50%|█████     | 4/8 [00:33<00:41, 10.38s/it]Loading checkpoint shards:  50%|█████     | 4/8 [00:32<00:41, 10.33s/it]Loading checkpoint shards:  50%|█████     | 4/8 [00:33<00:41, 10.37s/it]Loading checkpoint shards:  38%|███▊      | 3/8 [00:39<01:07, 13.60s/it]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:47<00:35, 11.73s/it]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:47<00:35, 11.71s/it]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:47<00:35, 11.71s/it]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:47<00:35, 11.70s/it]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:47<00:35, 11.74s/it]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:47<00:35, 11.73s/it]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:47<00:35, 11.74s/it]Loading checkpoint shards:  50%|█████     | 4/8 [00:53<00:54, 13.59s/it]Loading checkpoint shards:  75%|███████▌  | 6/8 [01:00<00:24, 12.32s/it]Loading checkpoint shards:  75%|███████▌  | 6/8 [01:00<00:24, 12.33s/it]Loading checkpoint shards:  75%|███████▌  | 6/8 [01:00<00:24, 12.34s/it]Loading checkpoint shards:  75%|███████▌  | 6/8 [01:00<00:24, 12.31s/it]Loading checkpoint shards:  75%|███████▌  | 6/8 [01:00<00:24, 12.34s/it]Loading checkpoint shards:  75%|███████▌  | 6/8 [01:00<00:24, 12.32s/it]Loading checkpoint shards:  75%|███████▌  | 6/8 [01:00<00:24, 12.33s/it]Loading checkpoint shards:  62%|██████▎   | 5/8 [01:07<00:41, 13.76s/it]Loading checkpoint shards:  88%|████████▊ | 7/8 [01:14<00:12, 12.91s/it]Loading checkpoint shards:  88%|████████▊ | 7/8 [01:14<00:12, 12.92s/it]Loading checkpoint shards:  88%|████████▊ | 7/8 [01:14<00:12, 12.92s/it]Loading checkpoint shards:  88%|████████▊ | 7/8 [01:15<00:12, 12.93s/it]Loading checkpoint shards:  88%|████████▊ | 7/8 [01:15<00:12, 12.93s/it]Loading checkpoint shards:  88%|████████▊ | 7/8 [01:15<00:12, 12.93s/it]Loading checkpoint shards:  88%|████████▊ | 7/8 [01:14<00:12, 12.91s/it]Loading checkpoint shards: 100%|██████████| 8/8 [01:16<00:00,  9.32s/it]Loading checkpoint shards: 100%|██████████| 8/8 [01:16<00:00,  9.32s/it]Loading checkpoint shards: 100%|██████████| 8/8 [01:16<00:00,  9.55s/it]Loading checkpoint shards: 100%|██████████| 8/8 [01:16<00:00,  9.55s/it]

Loading checkpoint shards: 100%|██████████| 8/8 [01:16<00:00,  9.33s/it]Loading checkpoint shards: 100%|██████████| 8/8 [01:16<00:00,  9.57s/it]
Loading checkpoint shards: 100%|██████████| 8/8 [01:16<00:00,  9.33s/it]Loading checkpoint shards: 100%|██████████| 8/8 [01:16<00:00,  9.33s/it]Loading checkpoint shards: 100%|██████████| 8/8 [01:16<00:00,  9.59s/it]
Loading checkpoint shards: 100%|██████████| 8/8 [01:16<00:00,  9.33s/it]Loading checkpoint shards: 100%|██████████| 8/8 [01:16<00:00,  9.59s/it]
Loading checkpoint shards: 100%|██████████| 8/8 [01:16<00:00,  9.32s/it]Loading checkpoint shards: 100%|██████████| 8/8 [01:16<00:00,  9.55s/it]
Loading checkpoint shards: 100%|██████████| 8/8 [01:16<00:00,  9.58s/it]
[2025-08-18 21:17:17,782] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:17:17,798] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:17:17,808] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:17:17,810] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:17:17,813] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:17:17,820] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:17:17,829] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
Loading checkpoint shards:  75%|███████▌  | 6/8 [01:20<00:27, 13.57s/it]Loading checkpoint shards:  88%|████████▊ | 7/8 [01:34<00:13, 13.65s/it]Model initialized!!!
Model initialized!!!
Model initialized!!!
Model initialized!!!
Model initialized!!!Model initialized!!!

Model initialized!!!
[2025-08-18 21:17:41,531][__main__][INFO] - No existing checkpoint, initializing new model
[2025-08-18 21:17:41,532][__main__][INFO] - Training  2025-08-18 21:17:41.532025
[2025-08-18 21:17:41,534][__main__][INFO] - No existing checkpoint, initializing new model
[2025-08-18 21:17:41,534][__main__][INFO] - Training  2025-08-18 21:17:41.534538
[2025-08-18 21:17:41,538][__main__][INFO] - No existing checkpoint, initializing new model
[2025-08-18 21:17:41,539][__main__][INFO] - Training  2025-08-18 21:17:41.539097
[2025-08-18 21:17:41,524][__main__][INFO] - No existing checkpoint, initializing new model
[2025-08-18 21:17:41,548][__main__][INFO] - Training  2025-08-18 21:17:41.548691
[2025-08-18 21:17:41,526][__main__][INFO] - No existing checkpoint, initializing new model
[2025-08-18 21:17:41,551][__main__][INFO] - Training  2025-08-18 21:17:41.551926
[2025-08-18 21:17:41,555][__main__][INFO] - No existing checkpoint, initializing new model
[2025-08-18 21:17:41,556][__main__][INFO] - Training  2025-08-18 21:17:41.556170
[2025-08-18 21:17:41,558][__main__][INFO] - No existing checkpoint, initializing new model
[2025-08-18 21:17:41,559][__main__][INFO] - Training  2025-08-18 21:17:41.559273
Loading checkpoint shards: 100%|██████████| 8/8 [01:39<00:00, 10.95s/it]Loading checkpoint shards: 100%|██████████| 8/8 [01:39<00:00, 12.47s/it]
[2025-08-18 21:17:41,783] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.15.4, git-hash=unknown, git-branch=unknown
[2025-08-18 21:17:41,783] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2025-08-18 21:17:41,814] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-08-18 21:17:41,826] [INFO] [logging.py:128:log_dist] [Rank 0] Creating ZeRO Offload
[2025-08-18 21:17:43,047] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2025-08-18 21:17:43,049] [INFO] [utils.py:782:see_memory_usage] MA 10.32 GB         Max_MA 14.48 GB         CA 26.35 GB         Max_CA 26 GB 
[2025-08-18 21:17:43,050] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 124.95 GB, percent = 8.3%
Parameter Offload: Total persistent parameters: 424960 in 161 params
[2025-08-18 21:17:43,316] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2025-08-18 21:17:43,317] [INFO] [utils.py:782:see_memory_usage] MA 10.32 GB         Max_MA 10.32 GB         CA 26.35 GB         Max_CA 26 GB 
[2025-08-18 21:17:43,318] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 124.93 GB, percent = 8.3%
[2025-08-18 21:17:43,320] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[2025-08-18 21:17:43,320] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-08-18 21:17:43,320] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-08-18 21:17:43,321] [INFO] [config.py:1003:print]   amp_enabled .................. False
[2025-08-18 21:17:43,321] [INFO] [config.py:1003:print]   amp_params ................... False
[2025-08-18 21:17:43,321] [INFO] [config.py:1003:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-08-18 21:17:43,322] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[2025-08-18 21:17:43,322] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[2025-08-18 21:17:43,322] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[2025-08-18 21:17:43,322] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[2025-08-18 21:17:43,322] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[2025-08-18 21:17:43,323] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x147cfd61c0d0>
[2025-08-18 21:17:43,323] [INFO] [config.py:1003:print]   communication_data_type ...... None
[2025-08-18 21:17:43,323] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-08-18 21:17:43,323] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[2025-08-18 21:17:43,324] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[2025-08-18 21:17:43,324] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-08-18 21:17:43,324] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[2025-08-18 21:17:43,324] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[2025-08-18 21:17:43,324] [INFO] [config.py:1003:print]   disable_allgather ............ False
[2025-08-18 21:17:43,325] [INFO] [config.py:1003:print]   dump_state ................... False
[2025-08-18 21:17:43,325] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[2025-08-18 21:17:43,325] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[2025-08-18 21:17:43,325] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[2025-08-18 21:17:43,325] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-08-18 21:17:43,325] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[2025-08-18 21:17:43,325] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[2025-08-18 21:17:43,326] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[2025-08-18 21:17:43,326] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[2025-08-18 21:17:43,326] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[2025-08-18 21:17:43,326] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[2025-08-18 21:17:43,326] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-08-18 21:17:43,327] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[2025-08-18 21:17:43,327] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[2025-08-18 21:17:43,327] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[2025-08-18 21:17:43,327] [INFO] [config.py:1003:print]   global_rank .................. 0
[2025-08-18 21:17:43,327] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[2025-08-18 21:17:43,327] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 64
[2025-08-18 21:17:43,327] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[2025-08-18 21:17:43,328] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[2025-08-18 21:17:43,328] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[2025-08-18 21:17:43,328] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-08-18 21:17:43,328] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[2025-08-18 21:17:43,328] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[2025-08-18 21:17:43,328] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[2025-08-18 21:17:43,328] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[2025-08-18 21:17:43,329] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[2025-08-18 21:17:43,329] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[2025-08-18 21:17:43,329] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-08-18 21:17:43,329] [INFO] [config.py:1003:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-08-18 21:17:43,330] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[2025-08-18 21:17:43,330] [INFO] [config.py:1003:print]   optimizer_name ............... None
[2025-08-18 21:17:43,330] [INFO] [config.py:1003:print]   optimizer_params ............. None
[2025-08-18 21:17:43,330] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-08-18 21:17:43,331] [INFO] [config.py:1003:print]   pld_enabled .................. False
[2025-08-18 21:17:43,331] [INFO] [config.py:1003:print]   pld_params ................... False
[2025-08-18 21:17:43,331] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[2025-08-18 21:17:43,331] [INFO] [config.py:1003:print]   scheduler_name ............... None
[2025-08-18 21:17:43,331] [INFO] [config.py:1003:print]   scheduler_params ............. None
[2025-08-18 21:17:43,332] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[2025-08-18 21:17:43,332] [INFO] [config.py:1003:print]   sparse_attention ............. None
[2025-08-18 21:17:43,332] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[2025-08-18 21:17:43,332] [INFO] [config.py:1003:print]   steps_per_print .............. inf
[2025-08-18 21:17:43,332] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[2025-08-18 21:17:43,333] [INFO] [config.py:1003:print]   train_batch_size ............. 32768
[2025-08-18 21:17:43,333] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  64
[2025-08-18 21:17:43,333] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[2025-08-18 21:17:43,333] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[2025-08-18 21:17:43,333] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[2025-08-18 21:17:43,333] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[2025-08-18 21:17:43,334] [INFO] [config.py:1003:print]   world_size ................... 8
[2025-08-18 21:17:43,334] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[2025-08-18 21:17:43,334] [INFO] [config.py:1003:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-08-18 21:17:43,335] [INFO] [config.py:1003:print]   zero_enabled ................. True
[2025-08-18 21:17:43,335] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[2025-08-18 21:17:43,335] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 3
[2025-08-18 21:17:43,335] [INFO] [config.py:989:print_user_config]   json = {
    "train_batch_size": 3.276800e+04, 
    "train_micro_batch_size_per_gpu": 64, 
    "gradient_accumulation_steps": 64, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_optimization.reduce_bucket_size": 2.621440e+07, 
    "zero_optimization.stage3_param_persistence_threshold": 5.120000e+04, 
    "zero_optimization.stage3_prefetch_bucket_size": 2.359296e+07
}
Model initialized!!!
[2025-08-18 21:17:43,356][__main__][INFO] - No existing checkpoint, initializing new model
[2025-08-18 21:17:43,357][__main__][INFO] - Training  2025-08-18 21:17:43.357265
Parameter Offload: Total persistent parameters: 424960 in 161 params
  0%|          | 0/1410 [00:00<?, ?it/s]Invalidate trace cache @ step 606 and module 1212: cache has only 606 modules
[2025-08-18 22:25:25,825] [WARNING] [stage3.py:2114:step] 173 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  0%|          | 1/1410 [1:07:18<1580:45:49, 4038.86s/it]                                                         {'loss': 0.0, 'grad_norm': 0.10591089230766557, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.75592041015625, 'unprocessed_answer_log_prob/_sum': -214.71875, 'unprocessed_answer_log_prob/_min': -21.0390625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -0.0005732327699661255, 'unprocessed_answer_log_prob/_first_quartile': -0.18054962158203125, 'unprocessed_answer_log_prob/_last_quartile': -6.51925802230835e-08, 'unprocessed_thought_kl/_mean': 0.13373565673828125, 'unprocessed_thought_kl/_sum': 297.609375, 'unprocessed_thought_kl/_min': -3.05615234375, 'unprocessed_thought_kl/_max': 9.275390625, 'unprocessed_thought_kl/_median': 2.088025212287903e-06, 'unprocessed_thought_kl/_first_quartile': -0.00021564820781350136, 'unprocessed_thought_kl/_last_quartile': 0.07061767578125, 'answer_log_prob_mean': -0.75592041015625, 'answer_log_prob_min': -21.0390625, 'solution_log_prob_reward': -0.96631102822721, 'reasoning_kl_mean': 0.13373565673828125, 'reasoning_kl_max': 9.275390625, 'thought_processed_kl': 0.133758544921875, 'thought_kl_scores': 4.704833984375, 'kl_reward': -0.6794686857610941, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.6457797102630138, 'processed_kl_no_entropy': 0.46746826171875, 'kl_scores_no_entropy': 6.466064453125, 'kl_reward_no_entropy': -1.7760754264891148, 'total_tl_reward_no_entropy': -2.7423864528536797, 'no_entropy_unprocessed_thought_kl/_mean': 0.467376708984375, 'no_entropy_unprocessed_thought_kl/_sum': 1089.0625, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 12.46484375, 'no_entropy_unprocessed_thought_kl/_median': 0.017699241638183594, 'no_entropy_unprocessed_thought_kl/_first_quartile': 5.173496901988983e-06, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.42009735107421875, 'no_entropy_reasoning_kl_mean': 0.467376708984375, 'no_entropy_reasoning_kl_max': 12.46484375, 'rewards/TeacherKLBasedReward': -1.705536961555481, 'reward': -1.705536961555481, 'reward_std': 0.14728812873363495, 'completion_length': 3830.578125, 'kl': 0.0, 'epoch': 0.0}
  0%|          | 1/1410 [1:07:18<1580:45:49, 4038.86s/it]Total time to update VLLMs: 34.184633 s
[2025-08-18 23:35:26,340] [WARNING] [stage3.py:2114:step] 329 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  0%|          | 2/1410 [2:17:19<1616:49:58, 4133.95s/it]                                                         {'loss': 0.0, 'grad_norm': 0.13962603523408681, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.4552001953125, 'unprocessed_answer_log_prob/_sum': -211.234375, 'unprocessed_answer_log_prob/_min': -13.7041015625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -1.562759280204773e-06, 'unprocessed_answer_log_prob/_first_quartile': -0.011931180953979492, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.10257720947265625, 'unprocessed_thought_kl/_sum': 739.1875, 'unprocessed_thought_kl/_min': -3.44189453125, 'unprocessed_thought_kl/_max': 11.68994140625, 'unprocessed_thought_kl/_median': 1.862645149230957e-09, 'unprocessed_thought_kl/_first_quartile': -1.889001578092575e-05, 'unprocessed_thought_kl/_last_quartile': 0.021373629570007324, 'answer_log_prob_mean': -0.4552001953125, 'answer_log_prob_min': -13.7041015625, 'solution_log_prob_reward': -0.5922412066720426, 'reasoning_kl_mean': 0.10257720947265625, 'reasoning_kl_max': 11.68994140625, 'thought_processed_kl': 0.1026763916015625, 'thought_kl_scores': 5.896484375, 'kl_reward': -0.6584298685193062, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.2506710728630424, 'processed_kl_no_entropy': 0.354461669921875, 'kl_scores_no_entropy': 6.8369140625, 'kl_reward_no_entropy': -1.4632141068577766, 'total_tl_reward_no_entropy': -2.0554553028196096, 'no_entropy_unprocessed_thought_kl/_mean': 0.354583740234375, 'no_entropy_unprocessed_thought_kl/_sum': 2580.125, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 13.3154296875, 'no_entropy_unprocessed_thought_kl/_median': 0.001974336802959442, 'no_entropy_unprocessed_thought_kl/_first_quartile': 2.6961788535118103e-07, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.21618270874023438, 'no_entropy_reasoning_kl_mean': 0.354583740234375, 'no_entropy_reasoning_kl_max': 13.3154296875, 'rewards/TeacherKLBasedReward': -1.5555943250656128, 'reward': -1.5555943250656128, 'reward_std': 0.11381802707910538, 'completion_length': 3504.50390625, 'kl': 0.00041800737380981445, 'epoch': 0.0}
  0%|          | 2/1410 [2:17:19<1616:49:58, 4133.95s/it]Total time to update VLLMs: 34.730368 s
[2025-08-19 00:56:41,283] [WARNING] [stage3.py:2114:step] 282 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  0%|          | 3/1410 [3:38:34<1747:55:38, 4472.31s/it]                                                         {'loss': 0.0, 'grad_norm': 0.06975581102889707, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.93292236328125, 'unprocessed_answer_log_prob/_sum': -529.84375, 'unprocessed_answer_log_prob/_min': -17.408203125, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -4.059635102748871e-05, 'unprocessed_answer_log_prob/_first_quartile': -0.12708282470703125, 'unprocessed_answer_log_prob/_last_quartile': -5.587935447692871e-09, 'unprocessed_thought_kl/_mean': 0.13227081298828125, 'unprocessed_thought_kl/_sum': 642.625, 'unprocessed_thought_kl/_min': -3.349365234375, 'unprocessed_thought_kl/_max': 15.18896484375, 'unprocessed_thought_kl/_median': 3.5762786865234375e-06, 'unprocessed_thought_kl/_first_quartile': -0.0002615880221128464, 'unprocessed_thought_kl/_last_quartile': 0.06539058685302734, 'answer_log_prob_mean': -0.93292236328125, 'answer_log_prob_min': -17.408203125, 'solution_log_prob_reward': -1.10700439568609, 'reasoning_kl_mean': 0.13227081298828125, 'reasoning_kl_max': 15.18896484375, 'thought_processed_kl': 0.132232666015625, 'thought_kl_scores': 7.65771484375, 'kl_reward': -0.8524813745170832, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.9594857711344957, 'processed_kl_no_entropy': 0.4708251953125, 'kl_scores_no_entropy': 8.18017578125, 'kl_reward_no_entropy': -1.8884692285209894, 'total_tl_reward_no_entropy': -2.995473627001047, 'no_entropy_unprocessed_thought_kl/_mean': 0.47064208984375, 'no_entropy_unprocessed_thought_kl/_sum': 2295.125, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 15.884765625, 'no_entropy_unprocessed_thought_kl/_median': 0.019477903842926025, 'no_entropy_unprocessed_thought_kl/_first_quartile': 1.745857298374176e-05, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.41402435302734375, 'no_entropy_reasoning_kl_mean': 0.47064208984375, 'no_entropy_reasoning_kl_max': 15.884765625, 'rewards/TeacherKLBasedReward': -1.4752061367034912, 'reward': -1.4752061367034912, 'reward_std': 0.12374002486467361, 'completion_length': 5163.630859375, 'kl': 0.00039207935333251953, 'epoch': 0.0}
  0%|          | 3/1410 [3:38:34<1747:55:38, 4472.31s/it]Total time to update VLLMs: 34.647865 s
[2025-08-19 02:26:54,310] [WARNING] [stage3.py:2114:step] 305 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  0%|          | 4/1410 [5:08:47<1891:43:53, 4843.69s/it]                                                         {'loss': 0.0, 'grad_norm': 0.05888606784316689, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.2735137939453125, 'unprocessed_answer_log_prob/_sum': -157.4921875, 'unprocessed_answer_log_prob/_min': -11.158203125, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -1.3224780559539795e-07, 'unprocessed_answer_log_prob/_first_quartile': -0.00021919934079051018, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.1228179931640625, 'unprocessed_thought_kl/_sum': 629.46875, 'unprocessed_thought_kl/_min': -3.42236328125, 'unprocessed_thought_kl/_max': 13.125, 'unprocessed_thought_kl/_median': 3.725290298461914e-09, 'unprocessed_thought_kl/_first_quartile': -4.443340003490448e-06, 'unprocessed_thought_kl/_last_quartile': 0.025949716567993164, 'answer_log_prob_mean': -0.2735137939453125, 'answer_log_prob_min': -11.158203125, 'solution_log_prob_reward': -0.3850958226248622, 'reasoning_kl_mean': 0.1228179931640625, 'reasoning_kl_max': 13.125, 'thought_processed_kl': 0.1227569580078125, 'thought_kl_scores': 6.62353515625, 'kl_reward': -0.7622039709240198, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.1472997972741723, 'processed_kl_no_entropy': 0.371826171875, 'kl_scores_no_entropy': 7.017578125, 'kl_reward_no_entropy': -1.5256164502352476, 'total_tl_reward_no_entropy': -1.9107122775167227, 'no_entropy_unprocessed_thought_kl/_mean': 0.371917724609375, 'no_entropy_unprocessed_thought_kl/_sum': 2011.1875, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 13.662109375, 'no_entropy_unprocessed_thought_kl/_median': 0.0010822825133800507, 'no_entropy_unprocessed_thought_kl/_first_quartile': 6.51925802230835e-08, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.2289886474609375, 'no_entropy_reasoning_kl_mean': 0.371917724609375, 'no_entropy_reasoning_kl_max': 13.662109375, 'rewards/TeacherKLBasedReward': -1.600261926651001, 'reward': -1.600261926651001, 'reward_std': 0.1887202113866806, 'completion_length': 8133.537109375, 'kl': 0.0003552734851837158, 'epoch': 0.0}
  0%|          | 4/1410 [5:08:47<1891:43:53, 4843.69s/it]Total time to update VLLMs: 34.603803 s
[2025-08-19 03:58:32,684] [WARNING] [stage3.py:2114:step] 299 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  0%|          | 5/1410 [6:40:25<1982:31:25, 5079.78s/it]                                                         {'loss': 0.0, 'grad_norm': 0.06349242566303887, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.67889404296875, 'unprocessed_answer_log_prob/_sum': -259.234375, 'unprocessed_answer_log_prob/_min': -14.294921875, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -0.0001431480050086975, 'unprocessed_answer_log_prob/_first_quartile': -0.160369873046875, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.19713592529296875, 'unprocessed_thought_kl/_sum': 1101.625, 'unprocessed_thought_kl/_min': -3.780517578125, 'unprocessed_thought_kl/_max': 17.7275390625, 'unprocessed_thought_kl/_median': 2.9802322387695312e-08, 'unprocessed_thought_kl/_first_quartile': -1.377379521727562e-05, 'unprocessed_thought_kl/_last_quartile': 0.016906261444091797, 'answer_log_prob_mean': -0.67889404296875, 'answer_log_prob_min': -14.294921875, 'solution_log_prob_reward': -0.821843252517283, 'reasoning_kl_mean': 0.19713592529296875, 'reasoning_kl_max': 17.7275390625, 'thought_processed_kl': 0.197174072265625, 'thought_kl_scores': 8.9716796875, 'kl_reward': -1.1232339348644018, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.9450771771371365, 'processed_kl_no_entropy': 0.417022705078125, 'kl_scores_no_entropy': 9.22509765625, 'kl_reward_no_entropy': -1.7920641861855984, 'total_tl_reward_no_entropy': -2.613907430320978, 'no_entropy_unprocessed_thought_kl/_mean': 0.417022705078125, 'no_entropy_unprocessed_thought_kl/_sum': 2326.5, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 18.033203125, 'no_entropy_unprocessed_thought_kl/_median': 0.0005155764520168304, 'no_entropy_unprocessed_thought_kl/_first_quartile': 1.7927959561347961e-07, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.17549896240234375, 'no_entropy_reasoning_kl_mean': 0.417022705078125, 'no_entropy_reasoning_kl_max': 18.033203125, 'rewards/TeacherKLBasedReward': -1.720678687095642, 'reward': -1.720678687095642, 'reward_std': 0.15457066893577576, 'completion_length': 7175.580078125, 'kl': 0.00039705634117126465, 'epoch': 0.0}
  0%|          | 5/1410 [6:40:25<1982:31:25, 5079.78s/it]Total time to update VLLMs: 34.952811 s
[2025-08-19 05:04:35,235] [WARNING] [stage3.py:2114:step] 241 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  0%|          | 6/1410 [7:46:28<1832:57:53, 4699.91s/it]                                                         {'loss': 0.0, 'grad_norm': 0.08097866143464556, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.39825439453125, 'unprocessed_answer_log_prob/_sum': -151.359375, 'unprocessed_answer_log_prob/_min': -16.1181640625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': 0.0, 'unprocessed_answer_log_prob/_first_quartile': -0.0006660819053649902, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.24764251708984375, 'unprocessed_thought_kl/_sum': 572.875, 'unprocessed_thought_kl/_min': -3.104248046875, 'unprocessed_thought_kl/_max': 16.3720703125, 'unprocessed_thought_kl/_median': 0.0, 'unprocessed_thought_kl/_first_quartile': -7.338821887969971e-07, 'unprocessed_thought_kl/_last_quartile': 0.010211169719696045, 'answer_log_prob_mean': -0.39825439453125, 'answer_log_prob_min': -16.1181640625, 'solution_log_prob_reward': -0.5594360302202404, 'reasoning_kl_mean': 0.24764251708984375, 'reasoning_kl_max': 16.3720703125, 'thought_processed_kl': 0.24755096435546875, 'thought_kl_scores': 8.31494140625, 'kl_reward': -1.2340896520763636, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.7935256771743298, 'processed_kl_no_entropy': 0.421905517578125, 'kl_scores_no_entropy': 8.51904296875, 'kl_reward_no_entropy': -1.7652612570673227, 'total_tl_reward_no_entropy': -2.3246972914785147, 'no_entropy_unprocessed_thought_kl/_mean': 0.42218017578125, 'no_entropy_unprocessed_thought_kl/_sum': 984.09375, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 16.6240234375, 'no_entropy_unprocessed_thought_kl/_median': 2.654455602169037e-05, 'no_entropy_unprocessed_thought_kl/_first_quartile': 0.0, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.10997295379638672, 'no_entropy_reasoning_kl_mean': 0.42218017578125, 'no_entropy_reasoning_kl_max': 16.6240234375, 'rewards/TeacherKLBasedReward': -1.6314973831176758, 'reward': -1.6314973831176758, 'reward_std': 0.22272460162639618, 'completion_length': 3494.13671875, 'kl': 0.0003421306610107422, 'epoch': 0.0}
  0%|          | 6/1410 [7:46:28<1832:57:53, 4699.91s/it]Total time to update VLLMs: 34.819467 s
[2025-08-19 06:46:12,950] [WARNING] [stage3.py:2114:step] 420 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  0%|          | 7/1410 [9:28:06<2009:45:19, 5156.89s/it]                                                         {'loss': 0.0, 'grad_norm': 0.04436027055181298, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.30230712890625, 'unprocessed_answer_log_prob/_sum': -168.15625, 'unprocessed_answer_log_prob/_min': -17.416015625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -1.1734664440155029e-07, 'unprocessed_answer_log_prob/_first_quartile': -0.0003498345613479614, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.10608673095703125, 'unprocessed_thought_kl/_sum': 1091.40625, 'unprocessed_thought_kl/_min': -3.8203125, 'unprocessed_thought_kl/_max': 12.529296875, 'unprocessed_thought_kl/_median': 3.725290298461914e-09, 'unprocessed_thought_kl/_first_quartile': -5.788169801235199e-06, 'unprocessed_thought_kl/_last_quartile': 0.00962384045124054, 'answer_log_prob_mean': -0.30230712890625, 'answer_log_prob_min': -17.416015625, 'solution_log_prob_reward': -0.47646727971732616, 'reasoning_kl_mean': 0.10608673095703125, 'reasoning_kl_max': 12.529296875, 'thought_processed_kl': 0.10601806640625, 'thought_kl_scores': 6.31640625, 'kl_reward': -0.69413908617571, 'match_reward': -0.125, 'total_teacher_likelihood_reward': -1.2956063691526651, 'processed_kl_no_entropy': 0.321075439453125, 'kl_scores_no_entropy': 7.19775390625, 'kl_reward_no_entropy': -1.3864929042756557, 'total_tl_reward_no_entropy': -1.9879601951688528, 'no_entropy_unprocessed_thought_kl/_mean': 0.321441650390625, 'no_entropy_unprocessed_thought_kl/_sum': 3341.5, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 14.072265625, 'no_entropy_unprocessed_thought_kl/_median': 0.00029722973704338074, 'no_entropy_unprocessed_thought_kl/_first_quartile': 1.0803341865539551e-07, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.1342334747314453, 'no_entropy_reasoning_kl_mean': 0.321441650390625, 'no_entropy_reasoning_kl_max': 14.072265625, 'rewards/TeacherKLBasedReward': -1.5865726470947266, 'reward': -1.5865726470947266, 'reward_std': 0.2601463496685028, 'completion_length': 8873.6328125, 'kl': 0.00042897462844848633, 'epoch': 0.0}
  0%|          | 7/1410 [9:28:06<2009:45:19, 5156.89s/it]Total time to update VLLMs: 34.981779 s
[2025-08-19 07:52:20,040] [WARNING] [stage3.py:2114:step] 237 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|          | 8/1410 [10:34:13<1860:48:38, 4778.12s/it]                                                          {'loss': 0.0, 'grad_norm': 0.11569862401015871, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.72271728515625, 'unprocessed_answer_log_prob/_sum': -333.84375, 'unprocessed_answer_log_prob/_min': -20.951171875, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -9.797513484954834e-06, 'unprocessed_answer_log_prob/_first_quartile': -0.06661510467529297, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.16132354736328125, 'unprocessed_thought_kl/_sum': 278.46875, 'unprocessed_thought_kl/_min': -2.88037109375, 'unprocessed_thought_kl/_max': 12.1484375, 'unprocessed_thought_kl/_median': 7.819384336471558e-06, 'unprocessed_thought_kl/_first_quartile': -0.0008543245494365692, 'unprocessed_thought_kl/_last_quartile': 0.09615135192871094, 'answer_log_prob_mean': -0.72271728515625, 'answer_log_prob_min': -20.951171875, 'solution_log_prob_reward': -0.9322289973497391, 'reasoning_kl_mean': 0.16132354736328125, 'reasoning_kl_max': 12.1484375, 'thought_processed_kl': 0.1612548828125, 'thought_kl_scores': 6.153564453125, 'kl_reward': -0.8484237510710955, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.7806527465581894, 'processed_kl_no_entropy': 0.524017333984375, 'kl_scores_no_entropy': 6.683837890625, 'kl_reward_no_entropy': -1.9582653678953648, 'total_tl_reward_no_entropy': -2.890494368970394, 'no_entropy_unprocessed_thought_kl/_mean': 0.524322509765625, 'no_entropy_unprocessed_thought_kl/_sum': 917.5625, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 12.84326171875, 'no_entropy_unprocessed_thought_kl/_median': 0.03667736053466797, 'no_entropy_unprocessed_thought_kl/_first_quartile': 3.989553079009056e-05, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.5039215087890625, 'no_entropy_reasoning_kl_mean': 0.524322509765625, 'no_entropy_reasoning_kl_max': 12.84326171875, 'rewards/TeacherKLBasedReward': -1.6878197193145752, 'reward': -1.6878197193145752, 'reward_std': 0.12592065334320068, 'completion_length': 3183.46484375, 'kl': 0.0004502832889556885, 'epoch': 0.01}
  1%|          | 8/1410 [10:34:13<1860:48:38, 4778.12s/it]Total time to update VLLMs: 34.786281 s
[2025-08-19 09:33:41,292] [WARNING] [stage3.py:2114:step] 378 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|          | 9/1410 [12:15:34<2018:01:19, 5185.50s/it]                                                          {'loss': 0.0, 'grad_norm': 0.10574989783078499, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.433685302734375, 'unprocessed_answer_log_prob/_sum': -275.796875, 'unprocessed_answer_log_prob/_min': -18.56640625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -6.839632987976074e-06, 'unprocessed_answer_log_prob/_first_quartile': -0.008271515369415283, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.08394622802734375, 'unprocessed_thought_kl/_sum': 821.78125, 'unprocessed_thought_kl/_min': -3.45166015625, 'unprocessed_thought_kl/_max': 11.3203125, 'unprocessed_thought_kl/_median': 3.725290298461914e-09, 'unprocessed_thought_kl/_first_quartile': -1.1818483471870422e-05, 'unprocessed_thought_kl/_last_quartile': 0.004679441452026367, 'answer_log_prob_mean': -0.433685302734375, 'answer_log_prob_min': -18.56640625, 'solution_log_prob_reward': -0.6193493576720357, 'reasoning_kl_mean': 0.08394622802734375, 'reasoning_kl_max': 11.3203125, 'thought_processed_kl': 0.08399200439453125, 'thought_kl_scores': 5.69677734375, 'kl_reward': -0.5914480485953391, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.2107974104583263, 'processed_kl_no_entropy': 0.2980499267578125, 'kl_scores_no_entropy': 6.681640625, 'kl_reward_no_entropy': -1.286292102187872, 'total_tl_reward_no_entropy': -1.90564145706594, 'no_entropy_unprocessed_thought_kl/_mean': 0.2980804443359375, 'no_entropy_unprocessed_thought_kl/_sum': 2907.75, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 13.068359375, 'no_entropy_unprocessed_thought_kl/_median': 0.00027934834361076355, 'no_entropy_unprocessed_thought_kl/_first_quartile': 1.3783574104309082e-07, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.11179733276367188, 'no_entropy_reasoning_kl_mean': 0.2980804443359375, 'no_entropy_reasoning_kl_max': 13.068359375, 'rewards/TeacherKLBasedReward': -1.3596911430358887, 'reward': -1.3596911430358887, 'reward_std': 0.17341147363185883, 'completion_length': 9222.181640625, 'kl': 0.0005062222480773926, 'epoch': 0.01}
  1%|          | 9/1410 [12:15:34<2018:01:19, 5185.50s/it]Total time to update VLLMs: 34.823192 s
[2025-08-19 10:51:38,696] [WARNING] [stage3.py:2114:step] 337 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|          | 10/1410 [13:33:31<1955:34:56, 5028.64s/it]                                                           {'loss': 0.0, 'grad_norm': 0.0716746447616676, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.6685791015625, 'unprocessed_answer_log_prob/_sum': -369.0625, 'unprocessed_answer_log_prob/_min': -18.46875, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -4.310347139835358e-05, 'unprocessed_answer_log_prob/_first_quartile': -0.04800605773925781, 'unprocessed_answer_log_prob/_last_quartile': -3.725290298461914e-08, 'unprocessed_thought_kl/_mean': 0.1172332763671875, 'unprocessed_thought_kl/_sum': 817.875, 'unprocessed_thought_kl/_min': -3.5234375, 'unprocessed_thought_kl/_max': 16.06396484375, 'unprocessed_thought_kl/_median': 5.960464477539063e-08, 'unprocessed_thought_kl/_first_quartile': -3.727572038769722e-05, 'unprocessed_thought_kl/_last_quartile': 0.029786109924316406, 'answer_log_prob_mean': -0.6685791015625, 'answer_log_prob_min': -18.46875, 'solution_log_prob_reward': -0.8532666070386767, 'reasoning_kl_mean': 0.1172332763671875, 'reasoning_kl_max': 16.06396484375, 'thought_processed_kl': 0.11721038818359375, 'thought_kl_scores': 8.09423828125, 'kl_reward': -0.833618763834238, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.6868853718042374, 'processed_kl_no_entropy': 0.387115478515625, 'kl_scores_no_entropy': 8.5263671875, 'kl_reward_no_entropy': -1.6617187354713678, 'total_tl_reward_no_entropy': -2.5149853341281414, 'no_entropy_unprocessed_thought_kl/_mean': 0.38720703125, 'no_entropy_unprocessed_thought_kl/_sum': 2761.375, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 16.669921875, 'no_entropy_unprocessed_thought_kl/_median': 0.0038166046142578125, 'no_entropy_unprocessed_thought_kl/_first_quartile': 1.0668300092220306e-06, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.2552490234375, 'no_entropy_reasoning_kl_mean': 0.38720703125, 'no_entropy_reasoning_kl_max': 16.669921875, 'rewards/TeacherKLBasedReward': -1.709280252456665, 'reward': -1.709280252456665, 'reward_std': 0.21814462542533875, 'completion_length': 5633.0390625, 'kl': 0.0003814697265625, 'epoch': 0.01}
  1%|          | 10/1410 [13:33:31<1955:34:56, 5028.64s/it]Total time to update VLLMs: 34.830286 s
[2025-08-19 12:17:35,166] [WARNING] [stage3.py:2114:step] 409 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|          | 11/1410 [14:59:28<1969:23:17, 5067.76s/it]                                                           {'loss': 0.0, 'grad_norm': 0.08115767821160584, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.86920166015625, 'unprocessed_answer_log_prob/_sum': -338.96875, 'unprocessed_answer_log_prob/_min': -18.123046875, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -0.008392095565795898, 'unprocessed_answer_log_prob/_first_quartile': -0.56805419921875, 'unprocessed_answer_log_prob/_last_quartile': -3.841239959001541e-06, 'unprocessed_thought_kl/_mean': 0.11319732666015625, 'unprocessed_thought_kl/_sum': 1214.625, 'unprocessed_thought_kl/_min': -3.6533203125, 'unprocessed_thought_kl/_max': 11.03515625, 'unprocessed_thought_kl/_median': 6.518326699733734e-05, 'unprocessed_thought_kl/_first_quartile': -0.00038324855268001556, 'unprocessed_thought_kl/_last_quartile': 0.08936500549316406, 'answer_log_prob_mean': -0.86920166015625, 'answer_log_prob_min': -18.123046875, 'solution_log_prob_reward': -1.0504321232438087, 'reasoning_kl_mean': 0.11319732666015625, 'reasoning_kl_max': 11.03515625, 'thought_processed_kl': 0.11319732666015625, 'thought_kl_scores': 5.5791015625, 'kl_reward': -0.6706466590985656, 'match_reward': -0.015625, 'total_teacher_likelihood_reward': -1.736703783273697, 'processed_kl_no_entropy': 0.489501953125, 'kl_scores_no_entropy': 7.11474609375, 'kl_reward_no_entropy': -1.8805627301335335, 'total_tl_reward_no_entropy': -2.946619864553213, 'no_entropy_unprocessed_thought_kl/_mean': 0.489471435546875, 'no_entropy_unprocessed_thought_kl/_sum': 5258.75, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 13.73828125, 'no_entropy_unprocessed_thought_kl/_median': 0.04614067077636719, 'no_entropy_unprocessed_thought_kl/_first_quartile': 0.0001343991607427597, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.497039794921875, 'no_entropy_reasoning_kl_mean': 0.489471435546875, 'no_entropy_reasoning_kl_max': 13.73828125, 'rewards/TeacherKLBasedReward': -1.798157811164856, 'reward': -1.798157811164856, 'reward_std': 0.15206599235534668, 'completion_length': 5669.224609375, 'kl': 0.0005505383014678955, 'epoch': 0.01}
  1%|          | 11/1410 [14:59:28<1969:23:17, 5067.76s/it]Total time to update VLLMs: 34.910010 s
[2025-08-19 13:36:02,644] [WARNING] [stage3.py:2114:step] 317 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|          | 12/1410 [16:17:55<1925:25:02, 4958.16s/it]                                                           {'loss': 0.0, 'grad_norm': 0.0719697538530736, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.67059326171875, 'unprocessed_answer_log_prob/_sum': -289.6875, 'unprocessed_answer_log_prob/_min': -17.1962890625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -7.091090083122253e-06, 'unprocessed_answer_log_prob/_first_quartile': -0.0380253791809082, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.11859893798828125, 'unprocessed_thought_kl/_sum': 677.015625, 'unprocessed_thought_kl/_min': -3.49169921875, 'unprocessed_thought_kl/_max': 11.6923828125, 'unprocessed_thought_kl/_median': 1.4901161193847656e-08, 'unprocessed_thought_kl/_first_quartile': -2.856692299246788e-05, 'unprocessed_thought_kl/_last_quartile': 0.023965954780578613, 'answer_log_prob_mean': -0.67059326171875, 'answer_log_prob_min': -17.1962890625, 'solution_log_prob_reward': -0.8425561487674713, 'reasoning_kl_mean': 0.11859893798828125, 'reasoning_kl_max': 11.6923828125, 'thought_processed_kl': 0.11853790283203125, 'thought_kl_scores': 5.90625, 'kl_reward': -0.7065682876855135, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.5491244439035654, 'processed_kl_no_entropy': 0.37408447265625, 'kl_scores_no_entropy': 7.037109375, 'kl_reward_no_entropy': -1.5323181133717299, 'total_tl_reward_no_entropy': -2.3748742640018463, 'no_entropy_unprocessed_thought_kl/_mean': 0.373809814453125, 'no_entropy_unprocessed_thought_kl/_sum': 2233.1875, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 13.6962890625, 'no_entropy_unprocessed_thought_kl/_median': 0.0019294451922178268, 'no_entropy_unprocessed_thought_kl/_first_quartile': 3.5297125577926636e-07, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.2237396240234375, 'no_entropy_reasoning_kl_mean': 0.373809814453125, 'no_entropy_reasoning_kl_max': 13.6962890625, 'rewards/TeacherKLBasedReward': -1.6764379739761353, 'reward': -1.6764379739761353, 'reward_std': 0.19325554370880127, 'completion_length': 5764.56640625, 'kl': 0.0004507303237915039, 'epoch': 0.01}
  1%|          | 12/1410 [16:17:55<1925:25:02, 4958.16s/it]Total time to update VLLMs: 34.814010 s
[2025-08-19 14:57:10,888] [WARNING] [stage3.py:2114:step] 249 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|          | 13/1410 [17:39:03<1913:28:28, 4930.93s/it]                                                           {'loss': 0.0, 'grad_norm': 0.09205111404218203, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.9716796875, 'unprocessed_answer_log_prob/_sum': -435.21875, 'unprocessed_answer_log_prob/_min': -19.390625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -0.0003446750342845917, 'unprocessed_answer_log_prob/_first_quartile': -0.413604736328125, 'unprocessed_answer_log_prob/_last_quartile': -1.210719347000122e-08, 'unprocessed_thought_kl/_mean': 0.1269683837890625, 'unprocessed_thought_kl/_sum': 301.515625, 'unprocessed_thought_kl/_min': -2.920166015625, 'unprocessed_thought_kl/_max': 12.439453125, 'unprocessed_thought_kl/_median': 6.891787052154541e-08, 'unprocessed_thought_kl/_first_quartile': -0.00011057732626795769, 'unprocessed_thought_kl/_last_quartile': 0.0451960563659668, 'answer_log_prob_mean': -0.9716796875, 'answer_log_prob_min': -19.390625, 'solution_log_prob_reward': -1.165585931390524, 'reasoning_kl_mean': 0.1269683837890625, 'reasoning_kl_max': 12.439453125, 'thought_processed_kl': 0.1270294189453125, 'thought_kl_scores': 6.2822265625, 'kl_reward': -0.7540887398645282, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.9196746721863747, 'processed_kl_no_entropy': 0.430389404296875, 'kl_scores_no_entropy': 7.00390625, 'kl_reward_no_entropy': -1.6982409581542015, 'total_tl_reward_no_entropy': -2.863826896995306, 'no_entropy_unprocessed_thought_kl/_mean': 0.430328369140625, 'no_entropy_unprocessed_thought_kl/_sum': 1047.1875, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 13.5751953125, 'no_entropy_unprocessed_thought_kl/_median': 0.009425163269042969, 'no_entropy_unprocessed_thought_kl/_first_quartile': 6.551854312419891e-07, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.3333282470703125, 'no_entropy_reasoning_kl_mean': 0.430328369140625, 'no_entropy_reasoning_kl_max': 13.5751953125, 'rewards/TeacherKLBasedReward': -1.682274341583252, 'reward': -1.682274341583252, 'reward_std': 0.13116689026355743, 'completion_length': 4475.541015625, 'kl': 0.0005078613758087158, 'epoch': 0.01}
  1%|          | 13/1410 [17:39:04<1913:28:28, 4930.93s/it]Total time to update VLLMs: 34.806376 s
[2025-08-19 16:23:21,889] [WARNING] [stage3.py:2114:step] 311 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|          | 14/1410 [19:05:14<1940:13:23, 5003.44s/it]                                                           {'loss': 0.0, 'grad_norm': 0.07112649421020492, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.6685791015625, 'unprocessed_answer_log_prob/_sum': -217.953125, 'unprocessed_answer_log_prob/_min': -13.8974609375, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -0.0009512901306152344, 'unprocessed_answer_log_prob/_first_quartile': -0.20381546020507812, 'unprocessed_answer_log_prob/_last_quartile': -2.4586915969848633e-07, 'unprocessed_thought_kl/_mean': 0.110992431640625, 'unprocessed_thought_kl/_sum': 679.21875, 'unprocessed_thought_kl/_min': -3.51708984375, 'unprocessed_thought_kl/_max': 10.8154296875, 'unprocessed_thought_kl/_median': 3.7066638469696045e-07, 'unprocessed_thought_kl/_first_quartile': -7.797079160809517e-05, 'unprocessed_thought_kl/_last_quartile': 0.04506111145019531, 'answer_log_prob_mean': -0.6685791015625, 'answer_log_prob_min': -13.8974609375, 'solution_log_prob_reward': -0.8075537076219916, 'reasoning_kl_mean': 0.110992431640625, 'reasoning_kl_max': 10.8154296875, 'thought_processed_kl': 0.11104583740234375, 'thought_kl_scores': 5.466064453125, 'kl_reward': -0.657440172508359, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.4649938773363829, 'processed_kl_no_entropy': 0.4027099609375, 'kl_scores_no_entropy': 6.81591796875, 'kl_reward_no_entropy': -1.6046447679400444, 'total_tl_reward_no_entropy': -2.4121984727680683, 'no_entropy_unprocessed_thought_kl/_mean': 0.402557373046875, 'no_entropy_unprocessed_thought_kl/_sum': 2488.125, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 13.232421875, 'no_entropy_unprocessed_thought_kl/_median': 0.010545432567596436, 'no_entropy_unprocessed_thought_kl/_first_quartile': 3.1990930438041687e-06, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.3169059753417969, 'no_entropy_reasoning_kl_mean': 0.402557373046875, 'no_entropy_reasoning_kl_max': 13.232421875, 'rewards/TeacherKLBasedReward': -1.6286389827728271, 'reward': -1.6286389827728271, 'reward_std': 0.16626191139221191, 'completion_length': 6970.875, 'kl': 0.0004911124706268311, 'epoch': 0.01}
  1%|          | 14/1410 [19:05:14<1940:13:23, 5003.44s/it]Total time to update VLLMs: 34.698168 s
[2025-08-19 17:54:41,879] [WARNING] [stage3.py:2114:step] 409 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|          | 15/1410 [20:36:34<1994:29:32, 5147.08s/it]                                                           {'loss': 0.0, 'grad_norm': 0.057583194825210356, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.610809326171875, 'unprocessed_answer_log_prob/_sum': -278.53125, 'unprocessed_answer_log_prob/_min': -18.7431640625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -1.2930482625961304e-05, 'unprocessed_answer_log_prob/_first_quartile': -0.06092977523803711, 'unprocessed_answer_log_prob/_last_quartile': -9.313225746154785e-09, 'unprocessed_thought_kl/_mean': 0.134307861328125, 'unprocessed_thought_kl/_sum': 1397.90625, 'unprocessed_thought_kl/_min': -3.84716796875, 'unprocessed_thought_kl/_max': 14.892578125, 'unprocessed_thought_kl/_median': 7.450580596923828e-08, 'unprocessed_thought_kl/_first_quartile': -2.88989394903183e-06, 'unprocessed_thought_kl/_last_quartile': 0.027285456657409668, 'answer_log_prob_mean': -0.610809326171875, 'answer_log_prob_min': -18.7431640625, 'solution_log_prob_reward': -0.7982409615069628, 'reasoning_kl_mean': 0.134307861328125, 'reasoning_kl_max': 14.892578125, 'thought_processed_kl': 0.13433074951171875, 'thought_kl_scores': 7.51611328125, 'kl_reward': -0.8497009081766009, 'match_reward': -0.0625, 'total_teacher_likelihood_reward': -1.7104418687522411, 'processed_kl_no_entropy': 0.38275146484375, 'kl_scores_no_entropy': 8.07421875, 'kl_reward_no_entropy': -1.6211096178740263, 'total_tl_reward_no_entropy': -2.4818505831062794, 'no_entropy_unprocessed_thought_kl/_mean': 0.382781982421875, 'no_entropy_unprocessed_thought_kl/_sum': 3940.125, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 15.7587890625, 'no_entropy_unprocessed_thought_kl/_median': 0.00213603675365448, 'no_entropy_unprocessed_thought_kl/_first_quartile': 2.1420419216156006e-07, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.2309722900390625, 'no_entropy_reasoning_kl_mean': 0.382781982421875, 'no_entropy_reasoning_kl_max': 15.7587890625, 'rewards/TeacherKLBasedReward': -1.6170439720153809, 'reward': -1.6170439720153809, 'reward_std': 0.22270384430885315, 'completion_length': 7029.59375, 'kl': 0.0005218088626861572, 'epoch': 0.01}
  1%|          | 15/1410 [20:36:34<1994:29:32, 5147.08s/it]Total time to update VLLMs: 34.772565 s
[2025-08-19 19:14:02,642] [WARNING] [stage3.py:2114:step] 254 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|          | 16/1410 [21:55:55<1948:02:11, 5030.80s/it]                                                           {'loss': 0.0, 'grad_norm': 0.0776152740342756, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.473175048828125, 'unprocessed_answer_log_prob/_sum': -255.453125, 'unprocessed_answer_log_prob/_min': -16.4736328125, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -2.738088369369507e-07, 'unprocessed_answer_log_prob/_first_quartile': -0.0015842467546463013, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.14713287353515625, 'unprocessed_thought_kl/_sum': 325.4375, 'unprocessed_thought_kl/_min': -3.010009765625, 'unprocessed_thought_kl/_max': 13.9541015625, 'unprocessed_thought_kl/_median': 1.862645149230957e-09, 'unprocessed_thought_kl/_first_quartile': -6.7087821662425995e-06, 'unprocessed_thought_kl/_last_quartile': 0.04143476486206055, 'answer_log_prob_mean': -0.473175048828125, 'answer_log_prob_min': -16.4736328125, 'solution_log_prob_reward': -0.6379113690927625, 'reasoning_kl_mean': 0.14713287353515625, 'reasoning_kl_max': 13.9541015625, 'thought_processed_kl': 0.147125244140625, 'thought_kl_scores': 7.048095703125, 'kl_reward': -0.8600216573104262, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.4979330264031887, 'processed_kl_no_entropy': 0.400054931640625, 'kl_scores_no_entropy': 7.4951171875, 'kl_reward_no_entropy': -1.6384680103510618, 'total_tl_reward_no_entropy': -2.276379380375147, 'no_entropy_unprocessed_thought_kl/_mean': 0.400238037109375, 'no_entropy_unprocessed_thought_kl/_sum': 904.71875, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 14.591796875, 'no_entropy_unprocessed_thought_kl/_median': 0.002248486503958702, 'no_entropy_unprocessed_thought_kl/_first_quartile': 2.1420419216156006e-08, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.2623138427734375, 'no_entropy_reasoning_kl_mean': 0.400238037109375, 'no_entropy_reasoning_kl_max': 14.591796875, 'rewards/TeacherKLBasedReward': -1.6051065921783447, 'reward': -1.6051065921783447, 'reward_std': 0.17320413887500763, 'completion_length': 5431.953125, 'kl': 0.0005370974540710449, 'epoch': 0.01}
  1%|          | 16/1410 [21:55:55<1948:02:11, 5030.80s/it]Total time to update VLLMs: 34.738149 s
[2025-08-19 20:42:23,328] [WARNING] [stage3.py:2114:step] 357 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|          | 17/1410 [23:24:16<1978:02:34, 5111.96s/it]                                                           {'loss': 0.0, 'grad_norm': 0.08096320017712652, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.4415283203125, 'unprocessed_answer_log_prob/_sum': -213.75, 'unprocessed_answer_log_prob/_min': -18.97265625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -5.114823579788208e-06, 'unprocessed_answer_log_prob/_first_quartile': -0.0057335346937179565, 'unprocessed_answer_log_prob/_last_quartile': -9.313225746154785e-09, 'unprocessed_thought_kl/_mean': 0.09348297119140625, 'unprocessed_thought_kl/_sum': 625.625, 'unprocessed_thought_kl/_min': -3.3778076171875, 'unprocessed_thought_kl/_max': 13.91259765625, 'unprocessed_thought_kl/_median': 1.862645149230957e-09, 'unprocessed_thought_kl/_first_quartile': -1.6339588910341263e-05, 'unprocessed_thought_kl/_last_quartile': 0.009411884471774101, 'answer_log_prob_mean': -0.4415283203125, 'answer_log_prob_min': -18.97265625, 'solution_log_prob_reward': -0.6312548751011491, 'reasoning_kl_mean': 0.09348297119140625, 'reasoning_kl_max': 13.91259765625, 'thought_processed_kl': 0.093414306640625, 'thought_kl_scores': 7.007568359375, 'kl_reward': -0.6978268320672214, 'match_reward': -0.078125, 'total_teacher_likelihood_reward': -1.4072067067027092, 'processed_kl_no_entropy': 0.3094482421875, 'kl_scores_no_entropy': 7.84375, 'kl_reward_no_entropy': -1.3898034542798996, 'total_tl_reward_no_entropy': -2.099183313548565, 'no_entropy_unprocessed_thought_kl/_mean': 0.309478759765625, 'no_entropy_unprocessed_thought_kl/_sum': 2149.375, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 15.37890625, 'no_entropy_unprocessed_thought_kl/_median': 0.00048342347145080566, 'no_entropy_unprocessed_thought_kl/_first_quartile': 8.381903171539307e-08, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.12914228439331055, 'no_entropy_reasoning_kl_mean': 0.309478759765625, 'no_entropy_reasoning_kl_max': 15.37890625, 'rewards/TeacherKLBasedReward': -1.5329017639160156, 'reward': -1.5329017639160156, 'reward_std': 0.1841721534729004, 'completion_length': 5867.23046875, 'kl': 0.0006456971168518066, 'epoch': 0.01}
  1%|          | 17/1410 [23:24:16<1978:02:34, 5111.96s/it]Total time to update VLLMs: 34.991253 s
[2025-08-19 21:54:20,301] [WARNING] [stage3.py:2114:step] 288 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|▏         | 18/1410 [24:36:13<1884:15:14, 4873.07s/it]                                                           {'loss': 0.0, 'grad_norm': 0.08507883751460556, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.423583984375, 'unprocessed_answer_log_prob/_sum': -210.046875, 'unprocessed_answer_log_prob/_min': -21.69140625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': 0.0, 'unprocessed_answer_log_prob/_first_quartile': -0.0009704232215881348, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.09603500366210938, 'unprocessed_thought_kl/_sum': 436.84375, 'unprocessed_thought_kl/_min': -3.474365234375, 'unprocessed_thought_kl/_max': 11.05078125, 'unprocessed_thought_kl/_median': 0.0, 'unprocessed_thought_kl/_first_quartile': -5.220528692007065e-06, 'unprocessed_thought_kl/_last_quartile': 0.007217122241854668, 'answer_log_prob_mean': -0.423583984375, 'answer_log_prob_min': -21.69140625, 'solution_log_prob_reward': -0.6404980374500155, 'reasoning_kl_mean': 0.09603500366210938, 'reasoning_kl_max': 11.05078125, 'thought_processed_kl': 0.09603500366210938, 'thought_kl_scores': 5.57568359375, 'kl_reward': -0.6196284415200353, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.2601264845579863, 'processed_kl_no_entropy': 0.3123931884765625, 'kl_scores_no_entropy': 6.607421875, 'kl_reward_no_entropy': -1.3238543588668108, 'total_tl_reward_no_entropy': -1.9643524028360844, 'no_entropy_unprocessed_thought_kl/_mean': 0.3122711181640625, 'no_entropy_unprocessed_thought_kl/_sum': 1450.0625, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 12.9013671875, 'no_entropy_unprocessed_thought_kl/_median': 7.641315460205078e-05, 'no_entropy_unprocessed_thought_kl/_first_quartile': 0.0, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.1317119598388672, 'no_entropy_reasoning_kl_mean': 0.3122711181640625, 'no_entropy_reasoning_kl_max': 12.9013671875, 'rewards/TeacherKLBasedReward': -1.448734998703003, 'reward': -1.448734998703003, 'reward_std': 0.12207581102848053, 'completion_length': 4212.892578125, 'kl': 0.0005159378051757812, 'epoch': 0.01}
  1%|▏         | 18/1410 [24:36:13<1884:15:14, 4873.07s/it]Total time to update VLLMs: 34.967043 s
[2025-08-19 23:24:27,060] [WARNING] [stage3.py:2114:step] 329 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|▏         | 19/1410 [26:06:20<1944:50:07, 5033.36s/it]                                                           {'loss': 0.0, 'grad_norm': 0.07923614161281113, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.411956787109375, 'unprocessed_answer_log_prob/_sum': -318.0625, 'unprocessed_answer_log_prob/_min': -15.1181640625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -4.5634806156158447e-07, 'unprocessed_answer_log_prob/_first_quartile': -0.0015530586242675781, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.114532470703125, 'unprocessed_thought_kl/_sum': 736.25, 'unprocessed_thought_kl/_min': -3.663330078125, 'unprocessed_thought_kl/_max': 11.1650390625, 'unprocessed_thought_kl/_median': 8.754432201385498e-08, 'unprocessed_thought_kl/_first_quartile': -2.3259781301021576e-06, 'unprocessed_thought_kl/_last_quartile': 0.039392948150634766, 'answer_log_prob_mean': -0.411956787109375, 'answer_log_prob_min': -15.1181640625, 'solution_log_prob_reward': -0.5631384300068021, 'reasoning_kl_mean': 0.114532470703125, 'reasoning_kl_max': 11.1650390625, 'thought_processed_kl': 0.1144866943359375, 'thought_kl_scores': 5.641845703125, 'kl_reward': -0.6785485735163093, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.2416870016604662, 'processed_kl_no_entropy': 0.38824462890625, 'kl_scores_no_entropy': 6.91943359375, 'kl_reward_no_entropy': -1.5684228371828794, 'total_tl_reward_no_entropy': -2.131561279296875, 'no_entropy_unprocessed_thought_kl/_mean': 0.3883056640625, 'no_entropy_unprocessed_thought_kl/_sum': 2527.75, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 13.4501953125, 'no_entropy_unprocessed_thought_kl/_median': 0.0038048624992370605, 'no_entropy_unprocessed_thought_kl/_first_quartile': 1.3131648302078247e-07, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.2819023132324219, 'no_entropy_reasoning_kl_mean': 0.3883056640625, 'no_entropy_reasoning_kl_max': 13.4501953125, 'rewards/TeacherKLBasedReward': -1.3357120752334595, 'reward': -1.3357120752334595, 'reward_std': 0.14122062921524048, 'completion_length': 6750.73828125, 'kl': 0.0006008148193359375, 'epoch': 0.01}
  1%|▏         | 19/1410 [26:06:20<1944:50:07, 5033.36s/it]Total time to update VLLMs: 34.659384 s
[2025-08-20 00:55:35,524] [WARNING] [stage3.py:2114:step] 245 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|▏         | 20/1410 [27:37:28<1993:52:34, 5164.00s/it]                                                           {'loss': 0.0, 'grad_norm': 0.09497726516738429, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.7333984375, 'unprocessed_answer_log_prob/_sum': -437.09375, 'unprocessed_answer_log_prob/_min': -18.326171875, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -9.531155228614807e-06, 'unprocessed_answer_log_prob/_first_quartile': -0.05786705017089844, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.1571197509765625, 'unprocessed_thought_kl/_sum': 270.0, 'unprocessed_thought_kl/_min': -2.829833984375, 'unprocessed_thought_kl/_max': 13.0048828125, 'unprocessed_thought_kl/_median': 3.7066638469696045e-07, 'unprocessed_thought_kl/_first_quartile': -0.0006890296936035156, 'unprocessed_thought_kl/_last_quartile': 0.0658116340637207, 'answer_log_prob_mean': -0.7333984375, 'answer_log_prob_min': -18.326171875, 'solution_log_prob_reward': -0.9166601533070207, 'reasoning_kl_mean': 0.1571197509765625, 'reasoning_kl_max': 13.0048828125, 'thought_processed_kl': 0.1570281982421875, 'thought_kl_scores': 6.580078125, 'kl_reward': -0.8615057249553502, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.7781658787280321, 'processed_kl_no_entropy': 0.486175537109375, 'kl_scores_no_entropy': 7.44189453125, 'kl_reward_no_entropy': -1.8908862210810184, 'total_tl_reward_no_entropy': -2.807546366006136, 'no_entropy_unprocessed_thought_kl/_mean': 0.48638916015625, 'no_entropy_unprocessed_thought_kl/_sum': 850.375, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 14.390625, 'no_entropy_unprocessed_thought_kl/_median': 0.019514083862304688, 'no_entropy_unprocessed_thought_kl/_first_quartile': 1.1289026588201523e-05, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.4058380126953125, 'no_entropy_reasoning_kl_mean': 0.48638916015625, 'no_entropy_reasoning_kl_max': 14.390625, 'rewards/TeacherKLBasedReward': -1.8725762367248535, 'reward': -1.8725762367248535, 'reward_std': 0.21151015162467957, 'completion_length': 6924.138671875, 'kl': 0.0007345080375671387, 'epoch': 0.01}
  1%|▏         | 20/1410 [27:37:28<1993:52:34, 5164.00s/it]Total time to update VLLMs: 34.854904 s
[2025-08-20 02:09:40,023] [WARNING] [stage3.py:2114:step] 242 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|▏         | 21/1410 [28:51:33<1909:07:00, 4948.04s/it]                                                           {'loss': 0.0, 'grad_norm': 0.08369661156800162, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.54486083984375, 'unprocessed_answer_log_prob/_sum': -180.875, 'unprocessed_answer_log_prob/_min': -17.8642578125, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -4.079192876815796e-07, 'unprocessed_answer_log_prob/_first_quartile': -0.0013534724712371826, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.17059326171875, 'unprocessed_thought_kl/_sum': 425.46875, 'unprocessed_thought_kl/_min': -3.0125732421875, 'unprocessed_thought_kl/_max': 15.2451171875, 'unprocessed_thought_kl/_median': 0.0, 'unprocessed_thought_kl/_first_quartile': -0.00024582957848906517, 'unprocessed_thought_kl/_last_quartile': 0.02944236993789673, 'answer_log_prob_mean': -0.54486083984375, 'answer_log_prob_min': -17.8642578125, 'solution_log_prob_reward': -0.7235034182667732, 'reasoning_kl_mean': 0.17059326171875, 'reasoning_kl_max': 15.2451171875, 'thought_processed_kl': 0.17066192626953125, 'thought_kl_scores': 7.708251953125, 'kl_reward': -0.9691332941874862, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.6926367040723562, 'processed_kl_no_entropy': 0.432159423828125, 'kl_scores_no_entropy': 8.42578125, 'kl_reward_no_entropy': -1.789163799956441, 'total_tl_reward_no_entropy': -2.5126672238111496, 'no_entropy_unprocessed_thought_kl/_mean': 0.432159423828125, 'no_entropy_unprocessed_thought_kl/_sum': 1057.625, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 16.4228515625, 'no_entropy_unprocessed_thought_kl/_median': 0.0029381122440099716, 'no_entropy_unprocessed_thought_kl/_first_quartile': 3.175809979438782e-07, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.24920654296875, 'no_entropy_reasoning_kl_mean': 0.432159423828125, 'no_entropy_reasoning_kl_max': 16.4228515625, 'rewards/TeacherKLBasedReward': -1.6630972623825073, 'reward': -1.6630972623825073, 'reward_std': 0.17560213804244995, 'completion_length': 3385.09375, 'kl': 0.0007506608963012695, 'epoch': 0.01}
  1%|▏         | 21/1410 [28:51:33<1909:07:00, 4948.04s/it]Total time to update VLLMs: 34.942940 s
[2025-08-20 03:23:37,344] [WARNING] [stage3.py:2114:step] 328 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 22/1410 [30:05:30<1848:38:42, 4794.76s/it]                                                           {'loss': 0.0, 'grad_norm': 0.0847253421626898, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.72564697265625, 'unprocessed_answer_log_prob/_sum': -265.65625, 'unprocessed_answer_log_prob/_min': -16.947265625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -0.001679152250289917, 'unprocessed_answer_log_prob/_first_quartile': -0.29505157470703125, 'unprocessed_answer_log_prob/_last_quartile': -7.674098014831543e-07, 'unprocessed_thought_kl/_mean': 0.10250091552734375, 'unprocessed_thought_kl/_sum': 733.65625, 'unprocessed_thought_kl/_min': -3.505615234375, 'unprocessed_thought_kl/_max': 10.24658203125, 'unprocessed_thought_kl/_median': 1.3094395399093628e-06, 'unprocessed_thought_kl/_first_quartile': -0.00019498169422149658, 'unprocessed_thought_kl/_last_quartile': 0.04252290725708008, 'answer_log_prob_mean': -0.72564697265625, 'answer_log_prob_min': -16.947265625, 'solution_log_prob_reward': -0.8951196260750294, 'reasoning_kl_mean': 0.10250091552734375, 'reasoning_kl_max': 10.24658203125, 'thought_processed_kl': 0.10247039794921875, 'thought_kl_scores': 5.175537109375, 'kl_reward': -0.6149001996964216, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.5100198276340961, 'processed_kl_no_entropy': 0.407745361328125, 'kl_scores_no_entropy': 7.05029296875, 'kl_reward_no_entropy': -1.634494623169303, 'total_tl_reward_no_entropy': -2.529614258557558, 'no_entropy_unprocessed_thought_kl/_mean': 0.40789794921875, 'no_entropy_unprocessed_thought_kl/_sum': 2965.75, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 13.693359375, 'no_entropy_unprocessed_thought_kl/_median': 0.011611342430114746, 'no_entropy_unprocessed_thought_kl/_first_quartile': 5.204230546951294e-06, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.32869720458984375, 'no_entropy_reasoning_kl_mean': 0.40789794921875, 'no_entropy_reasoning_kl_max': 13.693359375, 'rewards/TeacherKLBasedReward': -1.4679734706878662, 'reward': -1.4679734706878662, 'reward_std': 0.16720305383205414, 'completion_length': 4844.712890625, 'kl': 0.0008031129837036133, 'epoch': 0.02}
  2%|▏         | 22/1410 [30:05:30<1848:38:42, 4794.76s/it]Total time to update VLLMs: 34.667006 s
[2025-08-20 04:59:19,933] [WARNING] [stage3.py:2114:step] 276 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 23/1410 [31:41:12<1956:53:42, 5079.18s/it]                                                           {'loss': 0.0, 'grad_norm': 0.08299170434765868, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.57244873046875, 'unprocessed_answer_log_prob/_sum': -297.09375, 'unprocessed_answer_log_prob/_min': -20.94140625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -6.016343832015991e-07, 'unprocessed_answer_log_prob/_first_quartile': -0.02042865753173828, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.1407318115234375, 'unprocessed_thought_kl/_sum': 558.625, 'unprocessed_thought_kl/_min': -3.393310546875, 'unprocessed_thought_kl/_max': 11.7080078125, 'unprocessed_thought_kl/_median': 3.7439167499542236e-07, 'unprocessed_thought_kl/_first_quartile': -8.083879947662354e-07, 'unprocessed_thought_kl/_last_quartile': 0.049849510192871094, 'answer_log_prob_mean': -0.57244873046875, 'answer_log_prob_min': -20.94140625, 'solution_log_prob_reward': -0.7818627934902906, 'reasoning_kl_mean': 0.1407318115234375, 'reasoning_kl_max': 11.7080078125, 'thought_processed_kl': 0.14083099365234375, 'thought_kl_scores': 5.921875, 'kl_reward': -0.7734356606379151, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.5552984457463026, 'processed_kl_no_entropy': 0.39691162109375, 'kl_scores_no_entropy': 6.56396484375, 'kl_reward_no_entropy': -1.572949206456542, 'total_tl_reward_no_entropy': -2.3548119962215424, 'no_entropy_unprocessed_thought_kl/_mean': 0.39697265625, 'no_entropy_unprocessed_thought_kl/_sum': 1605.5, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 12.734375, 'no_entropy_unprocessed_thought_kl/_median': 0.0036664530634880066, 'no_entropy_unprocessed_thought_kl/_first_quartile': 1.280568540096283e-07, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.2771759033203125, 'no_entropy_reasoning_kl_mean': 0.39697265625, 'no_entropy_reasoning_kl_max': 12.734375, 'rewards/TeacherKLBasedReward': -1.7838658094406128, 'reward': -1.7838658094406128, 'reward_std': 0.2319330871105194, 'completion_length': 6372.521484375, 'kl': 0.0007729530334472656, 'epoch': 0.02}
  2%|▏         | 23/1410 [31:41:13<1956:53:42, 5079.18s/it]Total time to update VLLMs: 34.757622 s
[2025-08-20 06:45:31,385] [WARNING] [stage3.py:2114:step] 288 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 24/1410 [33:27:24<2104:46:03, 5466.93s/it]                                                           {'loss': 0.0, 'grad_norm': 0.05027371826491354, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.70257568359375, 'unprocessed_answer_log_prob/_sum': -342.875, 'unprocessed_answer_log_prob/_min': -19.3173828125, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -1.304037868976593e-05, 'unprocessed_answer_log_prob/_first_quartile': -0.05796051025390625, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.21245574951171875, 'unprocessed_thought_kl/_sum': 1002.96875, 'unprocessed_thought_kl/_min': -3.616943359375, 'unprocessed_thought_kl/_max': 17.9404296875, 'unprocessed_thought_kl/_median': 2.7939677238464355e-08, 'unprocessed_thought_kl/_first_quartile': -2.176966518163681e-06, 'unprocessed_thought_kl/_last_quartile': 0.030079960823059082, 'answer_log_prob_mean': -0.70257568359375, 'answer_log_prob_min': -19.3173828125, 'solution_log_prob_reward': -0.8957495065405965, 'reasoning_kl_mean': 0.21245574951171875, 'reasoning_kl_max': 17.9404296875, 'thought_processed_kl': 0.21244049072265625, 'thought_kl_scores': 9.076171875, 'kl_reward': -1.1755801364779472, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -2.0713296439498663, 'processed_kl_no_entropy': 0.428436279296875, 'kl_scores_no_entropy': 9.54736328125, 'kl_reward_no_entropy': -1.8462304286658764, 'total_tl_reward_no_entropy': -2.7419799380004406, 'no_entropy_unprocessed_thought_kl/_mean': 0.4287109375, 'no_entropy_unprocessed_thought_kl/_sum': 2089.0, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 18.669921875, 'no_entropy_unprocessed_thought_kl/_median': 0.0006768945604562759, 'no_entropy_unprocessed_thought_kl/_first_quartile': 6.51925802230835e-08, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.21120643615722656, 'no_entropy_reasoning_kl_mean': 0.4287109375, 'no_entropy_reasoning_kl_max': 18.669921875, 'rewards/TeacherKLBasedReward': -1.6870830059051514, 'reward': -1.6870830059051514, 'reward_std': 0.2966487407684326, 'completion_length': 10080.05859375, 'kl': 0.0007042288780212402, 'epoch': 0.02}
  2%|▏         | 24/1410 [33:27:24<2104:46:03, 5466.93s/it]Total time to update VLLMs: 34.854047 s
[2025-08-20 08:15:51,017] [WARNING] [stage3.py:2114:step] 297 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 25/1410 [34:57:44<2097:47:33, 5452.75s/it]                                                           {'loss': 0.0, 'grad_norm': 0.07178036025034897, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.8048095703125, 'unprocessed_answer_log_prob/_sum': -396.125, 'unprocessed_answer_log_prob/_min': -22.27734375, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -1.648254692554474e-05, 'unprocessed_answer_log_prob/_first_quartile': -0.061730384826660156, 'unprocessed_answer_log_prob/_last_quartile': -9.313225746154785e-09, 'unprocessed_thought_kl/_mean': 0.11969757080078125, 'unprocessed_thought_kl/_sum': 611.0, 'unprocessed_thought_kl/_min': -3.3304443359375, 'unprocessed_thought_kl/_max': 9.8671875, 'unprocessed_thought_kl/_median': 1.4901161193847656e-07, 'unprocessed_thought_kl/_first_quartile': -4.0827784687280655e-05, 'unprocessed_thought_kl/_last_quartile': 0.04907798767089844, 'answer_log_prob_mean': -0.8048095703125, 'answer_log_prob_min': -22.27734375, 'solution_log_prob_reward': -1.0275830086320639, 'reasoning_kl_mean': 0.11969757080078125, 'reasoning_kl_max': 9.8671875, 'thought_processed_kl': 0.11972808837890625, 'thought_kl_scores': 4.9921875, 'kl_reward': -0.6551083247177303, 'match_reward': -0.015625, 'total_teacher_likelihood_reward': -1.6983163356781006, 'processed_kl_no_entropy': 0.418731689453125, 'kl_scores_no_entropy': 6.8779296875, 'kl_reward_no_entropy': -1.656364744529128, 'total_tl_reward_no_entropy': -2.699572764337063, 'no_entropy_unprocessed_thought_kl/_mean': 0.41876220703125, 'no_entropy_unprocessed_thought_kl/_sum': 2257.1875, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 13.3359375, 'no_entropy_unprocessed_thought_kl/_median': 0.0077707767486572266, 'no_entropy_unprocessed_thought_kl/_first_quartile': 9.313225746154785e-07, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.3458290100097656, 'no_entropy_reasoning_kl_mean': 0.41876220703125, 'no_entropy_reasoning_kl_max': 13.3359375, 'rewards/TeacherKLBasedReward': -1.6079275608062744, 'reward': -1.6079275608062744, 'reward_std': 0.16791826486587524, 'completion_length': 6282.361328125, 'kl': 0.0009299516677856445, 'epoch': 0.02}
  2%|▏         | 25/1410 [34:57:44<2097:47:33, 5452.75s/it]Total time to update VLLMs: 35.071161 s
[2025-08-20 09:18:50,098] [WARNING] [stage3.py:2114:step] 267 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 26/1410 [36:00:43<1903:13:41, 4950.59s/it]                                                           {'loss': 0.0, 'grad_norm': 0.11095331247865142, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.74517822265625, 'unprocessed_answer_log_prob/_sum': -429.25, 'unprocessed_answer_log_prob/_min': -24.001953125, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -0.00031107664108276367, 'unprocessed_answer_log_prob/_first_quartile': -0.2226715087890625, 'unprocessed_answer_log_prob/_last_quartile': -1.862645149230957e-09, 'unprocessed_thought_kl/_mean': 0.12119293212890625, 'unprocessed_thought_kl/_sum': 439.78125, 'unprocessed_thought_kl/_min': -3.294921875, 'unprocessed_thought_kl/_max': 11.14111328125, 'unprocessed_thought_kl/_median': 1.6763806343078613e-08, 'unprocessed_thought_kl/_first_quartile': -8.727097883820534e-05, 'unprocessed_thought_kl/_last_quartile': 0.047425270080566406, 'answer_log_prob_mean': -0.74517822265625, 'answer_log_prob_min': -24.001953125, 'solution_log_prob_reward': -0.9851977517828345, 'reasoning_kl_mean': 0.12119293212890625, 'reasoning_kl_max': 11.14111328125, 'thought_processed_kl': 0.1212615966796875, 'thought_kl_scores': 5.632568359375, 'kl_reward': -0.6978121856227517, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.6830099262297153, 'processed_kl_no_entropy': 0.423553466796875, 'kl_scores_no_entropy': 6.948486328125, 'kl_reward_no_entropy': -1.6752355825155973, 'total_tl_reward_no_entropy': -2.6604333259165287, 'no_entropy_unprocessed_thought_kl/_mean': 0.423675537109375, 'no_entropy_unprocessed_thought_kl/_sum': 1593.75, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 13.4736328125, 'no_entropy_unprocessed_thought_kl/_median': 0.008384227752685547, 'no_entropy_unprocessed_thought_kl/_first_quartile': 1.0677613317966461e-06, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.3432273864746094, 'no_entropy_reasoning_kl_mean': 0.423675537109375, 'no_entropy_reasoning_kl_max': 13.4736328125, 'rewards/TeacherKLBasedReward': -1.598284363746643, 'reward': -1.598284363746643, 'reward_std': 0.12439887225627899, 'completion_length': 2608.384765625, 'kl': 0.0010488629341125488, 'epoch': 0.02}
  2%|▏         | 26/1410 [36:00:43<1903:13:41, 4950.59s/it]Total time to update VLLMs: 35.087792 s
[2025-08-20 10:53:17,556] [WARNING] [stage3.py:2114:step] 306 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 27/1410 [37:35:10<1984:28:37, 5165.67s/it]                                                           {'loss': 0.0, 'grad_norm': 0.04936179861986419, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.6439208984375, 'unprocessed_answer_log_prob/_sum': -231.796875, 'unprocessed_answer_log_prob/_min': -15.6728515625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -4.148110747337341e-06, 'unprocessed_answer_log_prob/_first_quartile': -0.017854690551757812, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.15196990966796875, 'unprocessed_thought_kl/_sum': 876.0625, 'unprocessed_thought_kl/_min': -3.331787109375, 'unprocessed_thought_kl/_max': 14.8896484375, 'unprocessed_thought_kl/_median': 1.862645149230957e-09, 'unprocessed_thought_kl/_first_quartile': -5.30388206243515e-07, 'unprocessed_thought_kl/_last_quartile': 0.006189916282892227, 'answer_log_prob_mean': -0.6439208984375, 'answer_log_prob_min': -15.6728515625, 'solution_log_prob_reward': -0.8006494101136923, 'reasoning_kl_mean': 0.15196990966796875, 'reasoning_kl_max': 14.8896484375, 'thought_processed_kl': 0.1519775390625, 'thought_kl_scores': 7.52392578125, 'kl_reward': -0.9025991540402174, 'match_reward': -0.015625, 'total_teacher_likelihood_reward': -1.7188735622912645, 'processed_kl_no_entropy': 0.336669921875, 'kl_scores_no_entropy': 8.03857421875, 'kl_reward_no_entropy': -1.4825866613537073, 'total_tl_reward_no_entropy': -2.2988610602915287, 'no_entropy_unprocessed_thought_kl/_mean': 0.336822509765625, 'no_entropy_unprocessed_thought_kl/_sum': 1956.4375, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 15.7373046875, 'no_entropy_unprocessed_thought_kl/_median': 9.470246732234955e-05, 'no_entropy_unprocessed_thought_kl/_first_quartile': 5.587935447692871e-09, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.09404325485229492, 'no_entropy_reasoning_kl_mean': 0.336822509765625, 'no_entropy_reasoning_kl_max': 15.7373046875, 'rewards/TeacherKLBasedReward': -1.5071552991867065, 'reward': -1.5071552991867065, 'reward_std': 0.21511995792388916, 'completion_length': 7606.71484375, 'kl': 0.0008786320686340332, 'epoch': 0.02}
  2%|▏         | 27/1410 [37:35:10<1984:28:37, 5165.67s/it]Total time to update VLLMs: 34.823883 s
[2025-08-20 12:38:55,018] [WARNING] [stage3.py:2114:step] 693 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 28/1410 [39:20:48<2118:00:02, 5517.22s/it]                                                           {'loss': 0.0, 'grad_norm': 0.04566823688659119, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.489227294921875, 'unprocessed_answer_log_prob/_sum': -266.015625, 'unprocessed_answer_log_prob/_min': -18.9765625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -3.1869858503341675e-06, 'unprocessed_answer_log_prob/_first_quartile': -0.020838499069213867, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.07276535034179688, 'unprocessed_thought_kl/_sum': 1186.3125, 'unprocessed_thought_kl/_min': -4.025146484375, 'unprocessed_thought_kl/_max': 9.9462890625, 'unprocessed_thought_kl/_median': 0.0, 'unprocessed_thought_kl/_first_quartile': -2.5173649191856384e-06, 'unprocessed_thought_kl/_last_quartile': 0.0007149246521294117, 'answer_log_prob_mean': -0.489227294921875, 'answer_log_prob_min': -18.9765625, 'solution_log_prob_reward': -0.6789929149672389, 'reasoning_kl_mean': 0.07276535034179688, 'reasoning_kl_max': 9.9462890625, 'thought_processed_kl': 0.07276535034179688, 'thought_kl_scores': 5.005859375, 'kl_reward': -0.5166847221553326, 'match_reward': -0.9375, 'total_teacher_likelihood_reward': -2.133177638053894, 'processed_kl_no_entropy': 0.258453369140625, 'kl_scores_no_entropy': 6.76220703125, 'kl_reward_no_entropy': -1.1735046310350299, 'total_tl_reward_no_entropy': -2.7899975441396236, 'no_entropy_unprocessed_thought_kl/_mean': 0.258453369140625, 'no_entropy_unprocessed_thought_kl/_sum': 4213.5, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 13.271484375, 'no_entropy_unprocessed_thought_kl/_median': 1.646392047405243e-05, 'no_entropy_unprocessed_thought_kl/_first_quartile': 2.421438694000244e-08, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.055422425270080566, 'no_entropy_reasoning_kl_mean': 0.258453369140625, 'no_entropy_reasoning_kl_max': 13.271484375, 'rewards/TeacherKLBasedReward': -1.503251075744629, 'reward': -1.503251075744629, 'reward_std': 0.21875335276126862, 'completion_length': 10127.328125, 'kl': 0.0008489489555358887, 'epoch': 0.02}
  2%|▏         | 28/1410 [39:20:48<2118:00:02, 5517.22s/it]Total time to update VLLMs: 35.137422 s
[2025-08-20 14:21:21,276] [WARNING] [stage3.py:2114:step] 282 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 29/1410 [41:03:14<2188:51:42, 5705.94s/it]                                                           {'loss': 0.0, 'grad_norm': 0.06582823623169533, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.6302490234375, 'unprocessed_answer_log_prob/_sum': -297.5, 'unprocessed_answer_log_prob/_min': -18.2509765625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -5.0514936447143555e-06, 'unprocessed_answer_log_prob/_first_quartile': -0.020097970962524414, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.1349639892578125, 'unprocessed_thought_kl/_sum': 509.90625, 'unprocessed_thought_kl/_min': -3.2591552734375, 'unprocessed_thought_kl/_max': 11.03564453125, 'unprocessed_thought_kl/_median': 7.860362529754639e-07, 'unprocessed_thought_kl/_first_quartile': -0.00020767468959093094, 'unprocessed_thought_kl/_last_quartile': 0.05440068244934082, 'answer_log_prob_mean': -0.6302490234375, 'answer_log_prob_min': -18.2509765625, 'solution_log_prob_reward': -0.8127587772905827, 'reasoning_kl_mean': 0.1349639892578125, 'reasoning_kl_max': 11.03564453125, 'thought_processed_kl': 0.13495635986328125, 'thought_kl_scores': 5.587646484375, 'kl_reward': -0.7359612947329879, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.5487200673669577, 'processed_kl_no_entropy': 0.44976806640625, 'kl_scores_no_entropy': 6.76806640625, 'kl_reward_no_entropy': -1.7425231728702784, 'total_tl_reward_no_entropy': -2.555281937122345, 'no_entropy_unprocessed_thought_kl/_mean': 0.449981689453125, 'no_entropy_unprocessed_thought_kl/_sum': 1766.75, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 13.0859375, 'no_entropy_unprocessed_thought_kl/_median': 0.017655551433563232, 'no_entropy_unprocessed_thought_kl/_first_quartile': 8.433591574430466e-06, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.3676795959472656, 'no_entropy_reasoning_kl_mean': 0.449981689453125, 'no_entropy_reasoning_kl_max': 13.0859375, 'rewards/TeacherKLBasedReward': -1.4839476346969604, 'reward': -1.4839476346969604, 'reward_std': 0.2368122935295105, 'completion_length': 7869.0859375, 'kl': 0.0010944604873657227, 'epoch': 0.02}
  2%|▏         | 29/1410 [41:03:14<2188:51:42, 5705.94s/it]Total time to update VLLMs: 34.929450 s
[2025-08-20 15:46:07,127] [WARNING] [stage3.py:2114:step] 537 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 30/1410 [42:28:00<2115:57:59, 5519.91s/it]                                                           {'loss': 0.0001, 'grad_norm': 0.07959764628685842, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.7415771484375, 'unprocessed_answer_log_prob/_sum': -330.75, 'unprocessed_answer_log_prob/_min': -15.876953125, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -0.0009274780750274658, 'unprocessed_answer_log_prob/_first_quartile': -0.23728179931640625, 'unprocessed_answer_log_prob/_last_quartile': -3.7299469113349915e-07, 'unprocessed_thought_kl/_mean': 0.08096694946289062, 'unprocessed_thought_kl/_sum': 1163.5, 'unprocessed_thought_kl/_min': -3.67578125, 'unprocessed_thought_kl/_max': 9.619140625, 'unprocessed_thought_kl/_median': 9.313225746154785e-09, 'unprocessed_thought_kl/_first_quartile': -4.462897777557373e-05, 'unprocessed_thought_kl/_last_quartile': 0.006516352295875549, 'answer_log_prob_mean': -0.7415771484375, 'answer_log_prob_min': -15.876953125, 'solution_log_prob_reward': -0.9003466749563813, 'reasoning_kl_mean': 0.08096694946289062, 'reasoning_kl_max': 9.619140625, 'thought_processed_kl': 0.08097457885742188, 'thought_kl_scores': 4.84423828125, 'kl_reward': -0.5314750727266073, 'match_reward': -0.265625, 'total_teacher_likelihood_reward': -1.6974467560648918, 'processed_kl_no_entropy': 0.313720703125, 'kl_scores_no_entropy': 6.8115234375, 'kl_reward_no_entropy': -1.3404199164360762, 'total_tl_reward_no_entropy': -2.5063916221261024, 'no_entropy_unprocessed_thought_kl/_mean': 0.313720703125, 'no_entropy_unprocessed_thought_kl/_sum': 4504.25, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 13.30859375, 'no_entropy_unprocessed_thought_kl/_median': 0.0006143972277641296, 'no_entropy_unprocessed_thought_kl/_first_quartile': 4.5821070671081543e-07, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.138824462890625, 'no_entropy_reasoning_kl_mean': 0.313720703125, 'no_entropy_reasoning_kl_max': 13.30859375, 'rewards/TeacherKLBasedReward': -1.5811866521835327, 'reward': -1.5811866521835327, 'reward_std': 0.19803175330162048, 'completion_length': 6388.11328125, 'kl': 0.0013394355773925781, 'epoch': 0.02}
  2%|▏         | 30/1410 [42:28:00<2115:57:59, 5519.91s/it]Total time to update VLLMs: 35.085337 s
[2025-08-20 17:04:47,956] [WARNING] [stage3.py:2114:step] 254 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 31/1410 [43:46:41<2022:36:07, 5280.18s/it]                                                           {'loss': 0.0001, 'grad_norm': 0.09063857317219914, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.94183349609375, 'unprocessed_answer_log_prob/_sum': -376.71875, 'unprocessed_answer_log_prob/_min': -20.80859375, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -0.0008137822151184082, 'unprocessed_answer_log_prob/_first_quartile': -0.1802825927734375, 'unprocessed_answer_log_prob/_last_quartile': -3.7439167499542236e-07, 'unprocessed_thought_kl/_mean': 0.1364898681640625, 'unprocessed_thought_kl/_sum': 337.46875, 'unprocessed_thought_kl/_min': -2.9501953125, 'unprocessed_thought_kl/_max': 11.75146484375, 'unprocessed_thought_kl/_median': 1.1276453733444214e-05, 'unprocessed_thought_kl/_first_quartile': -0.0017278343439102173, 'unprocessed_thought_kl/_last_quartile': 0.0808563232421875, 'answer_log_prob_mean': -0.94183349609375, 'answer_log_prob_min': -20.80859375, 'solution_log_prob_reward': -1.1499194242060184, 'reasoning_kl_mean': 0.1364898681640625, 'reasoning_kl_max': 11.75146484375, 'thought_processed_kl': 0.1363983154296875, 'thought_kl_scores': 5.940673828125, 'kl_reward': -0.7620135666802526, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.9119329899549484, 'processed_kl_no_entropy': 0.505157470703125, 'kl_scores_no_entropy': 6.947265625, 'kl_reward_no_entropy': -1.9169750846922398, 'total_tl_reward_no_entropy': -3.0668945014476776, 'no_entropy_unprocessed_thought_kl/_mean': 0.50506591796875, 'no_entropy_unprocessed_thought_kl/_sum': 1271.3125, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 13.392578125, 'no_entropy_unprocessed_thought_kl/_median': 0.03490638732910156, 'no_entropy_unprocessed_thought_kl/_first_quartile': 0.00010417960584163666, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.474761962890625, 'no_entropy_reasoning_kl_mean': 0.50506591796875, 'no_entropy_reasoning_kl_max': 13.392578125, 'rewards/TeacherKLBasedReward': -1.6468679904937744, 'reward': -1.6468679904937744, 'reward_std': 0.12412240356206894, 'completion_length': 4387.189453125, 'kl': 0.0015462636947631836, 'epoch': 0.02}
  2%|▏         | 31/1410 [43:46:41<2022:36:07, 5280.18s/it]Total time to update VLLMs: 34.831533 s
[2025-08-20 18:29:43,044] [WARNING] [stage3.py:2114:step] 327 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 32/1410 [45:11:36<1999:53:04, 5224.66s/it]                                                           {'loss': 0.0001, 'grad_norm': 0.07649173436804518, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.343536376953125, 'unprocessed_answer_log_prob/_sum': -332.53125, 'unprocessed_answer_log_prob/_min': -23.294921875, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -9.313225746154785e-08, 'unprocessed_answer_log_prob/_first_quartile': -0.00038693472743034363, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.08898162841796875, 'unprocessed_thought_kl/_sum': 570.75, 'unprocessed_thought_kl/_min': -3.3203125, 'unprocessed_thought_kl/_max': 10.7626953125, 'unprocessed_thought_kl/_median': 0.0, 'unprocessed_thought_kl/_first_quartile': -1.16787850856781e-06, 'unprocessed_thought_kl/_last_quartile': 0.005319759249687195, 'answer_log_prob_mean': -0.343536376953125, 'answer_log_prob_min': -23.294921875, 'solution_log_prob_reward': -0.5764855900779366, 'reasoning_kl_mean': 0.08898162841796875, 'reasoning_kl_max': 10.7626953125, 'thought_processed_kl': 0.08898162841796875, 'thought_kl_scores': 5.423095703125, 'kl_reward': -0.5898257344961166, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.1663113348186016, 'processed_kl_no_entropy': 0.2808837890625, 'kl_scores_no_entropy': 6.3232421875, 'kl_reward_no_entropy': -1.21394163928926, 'total_tl_reward_no_entropy': -1.7904272209852934, 'no_entropy_unprocessed_thought_kl/_mean': 0.280975341796875, 'no_entropy_unprocessed_thought_kl/_sum': 1816.875, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 12.3671875, 'no_entropy_unprocessed_thought_kl/_median': 4.820898175239563e-05, 'no_entropy_unprocessed_thought_kl/_first_quartile': 0.0, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.09880828857421875, 'no_entropy_reasoning_kl_mean': 0.280975341796875, 'no_entropy_reasoning_kl_max': 12.3671875, 'rewards/TeacherKLBasedReward': -1.4751560688018799, 'reward': -1.4751560688018799, 'reward_std': 0.1516587734222412, 'completion_length': 6444.189453125, 'kl': 0.0015480518341064453, 'epoch': 0.02}
  2%|▏         | 32/1410 [45:11:36<1999:53:04, 5224.66s/it]Total time to update VLLMs: 34.919629 s
[2025-08-20 20:09:32,224] [WARNING] [stage3.py:2114:step] 437 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 33/1410 [46:51:25<2086:09:39, 5454.02s/it]                                                           {'loss': 0.0001, 'grad_norm': 0.08041039632872321, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.54986572265625, 'unprocessed_answer_log_prob/_sum': -272.796875, 'unprocessed_answer_log_prob/_min': -16.916015625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -2.3983418941497803e-05, 'unprocessed_answer_log_prob/_first_quartile': -0.020720481872558594, 'unprocessed_answer_log_prob/_last_quartile': -9.12696123123169e-08, 'unprocessed_thought_kl/_mean': 0.07130050659179688, 'unprocessed_thought_kl/_sum': 829.0, 'unprocessed_thought_kl/_min': -3.58837890625, 'unprocessed_thought_kl/_max': 7.86669921875, 'unprocessed_thought_kl/_median': 0.0, 'unprocessed_thought_kl/_first_quartile': -1.158611848950386e-05, 'unprocessed_thought_kl/_last_quartile': 0.003458857536315918, 'answer_log_prob_mean': -0.54986572265625, 'answer_log_prob_min': -16.916015625, 'solution_log_prob_reward': -0.7190258782356977, 'reasoning_kl_mean': 0.07130050659179688, 'reasoning_kl_max': 7.86669921875, 'thought_processed_kl': 0.07129669189453125, 'thought_kl_scores': 3.96728515625, 'kl_reward': -0.449902490247041, 'match_reward': -0.0625, 'total_teacher_likelihood_reward': -1.2314283773303032, 'processed_kl_no_entropy': 0.2801055908203125, 'kl_scores_no_entropy': 6.36962890625, 'kl_reward_no_entropy': -1.214252920821309, 'total_tl_reward_no_entropy': -1.9957787971943617, 'no_entropy_unprocessed_thought_kl/_mean': 0.2801513671875, 'no_entropy_unprocessed_thought_kl/_sum': 3266.5, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 12.4599609375, 'no_entropy_unprocessed_thought_kl/_median': 0.00015356391668319702, 'no_entropy_unprocessed_thought_kl/_first_quartile': 1.5972182154655457e-07, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.10385322570800781, 'no_entropy_reasoning_kl_mean': 0.2801513671875, 'no_entropy_reasoning_kl_max': 12.4599609375, 'rewards/TeacherKLBasedReward': -1.670412540435791, 'reward': -1.670412540435791, 'reward_std': 0.2269621193408966, 'completion_length': 7779.017578125, 'kl': 0.0014307498931884766, 'epoch': 0.02}
  2%|▏         | 33/1410 [46:51:25<2086:09:39, 5454.02s/it]Total time to update VLLMs: 35.058460 s
[2025-08-20 21:51:12,522] [WARNING] [stage3.py:2114:step] 318 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 34/1410 [48:33:05<2158:45:20, 5647.91s/it]                                                           {'loss': 0.0, 'grad_norm': 0.048943633918629596, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.86627197265625, 'unprocessed_answer_log_prob/_sum': -419.21875, 'unprocessed_answer_log_prob/_min': -17.41015625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -0.0010840892791748047, 'unprocessed_answer_log_prob/_first_quartile': -0.3125495910644531, 'unprocessed_answer_log_prob/_last_quartile': -4.032626748085022e-07, 'unprocessed_thought_kl/_mean': 0.09906005859375, 'unprocessed_thought_kl/_sum': 656.90625, 'unprocessed_thought_kl/_min': -3.284912109375, 'unprocessed_thought_kl/_max': 8.97021484375, 'unprocessed_thought_kl/_median': 6.282702088356018e-06, 'unprocessed_thought_kl/_first_quartile': -0.00044137611985206604, 'unprocessed_thought_kl/_last_quartile': 0.054320335388183594, 'answer_log_prob_mean': -0.86627197265625, 'answer_log_prob_min': -17.41015625, 'solution_log_prob_reward': -1.0403735311701894, 'reasoning_kl_mean': 0.09906005859375, 'reasoning_kl_max': 8.97021484375, 'thought_processed_kl': 0.09911346435546875, 'thought_kl_scores': 4.535400390625, 'kl_reward': -0.5662866183556616, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.6066601518541574, 'processed_kl_no_entropy': 0.424224853515625, 'kl_scores_no_entropy': 6.474609375, 'kl_reward_no_entropy': -1.648498522117734, 'total_tl_reward_no_entropy': -2.6888720355927944, 'no_entropy_unprocessed_thought_kl/_mean': 0.42425537109375, 'no_entropy_unprocessed_thought_kl/_sum': 2816.375, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 12.5244140625, 'no_entropy_unprocessed_thought_kl/_median': 0.022583484649658203, 'no_entropy_unprocessed_thought_kl/_first_quartile': 4.644133150577545e-05, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.37673187255859375, 'no_entropy_reasoning_kl_mean': 0.42425537109375, 'no_entropy_reasoning_kl_max': 12.5244140625, 'rewards/TeacherKLBasedReward': -1.4809608459472656, 'reward': -1.4809608459472656, 'reward_std': 0.2643769383430481, 'completion_length': 9788.833984375, 'kl': 0.0011083483695983887, 'epoch': 0.02}
  2%|▏         | 34/1410 [48:33:05<2158:45:20, 5647.91s/it]Total time to update VLLMs: 35.006238 s
[2025-08-20 23:33:32,765] [WARNING] [stage3.py:2114:step] 276 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 35/1410 [50:15:25<2213:35:55, 5795.60s/it]                                                           {'loss': 0.0001, 'grad_norm': 0.06081202760685209, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.30926513671875, 'unprocessed_answer_log_prob/_sum': -222.671875, 'unprocessed_answer_log_prob/_min': -17.19140625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -2.086162567138672e-07, 'unprocessed_answer_log_prob/_first_quartile': -0.0019001364707946777, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.1294708251953125, 'unprocessed_thought_kl/_sum': 473.515625, 'unprocessed_thought_kl/_min': -3.4208984375, 'unprocessed_thought_kl/_max': 17.115234375, 'unprocessed_thought_kl/_median': 0.0, 'unprocessed_thought_kl/_first_quartile': -5.308538675308228e-07, 'unprocessed_thought_kl/_last_quartile': 0.005650602281093597, 'answer_log_prob_mean': -0.30926513671875, 'answer_log_prob_min': -17.19140625, 'solution_log_prob_reward': -0.4811791954562068, 'reasoning_kl_mean': 0.1294708251953125, 'reasoning_kl_max': 17.115234375, 'thought_processed_kl': 0.1295013427734375, 'thought_kl_scores': 8.619140625, 'kl_reward': -0.9018694944679737, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.3830487001687288, 'processed_kl_no_entropy': 0.2889251708984375, 'kl_scores_no_entropy': 8.962890625, 'kl_reward_no_entropy': -1.3960107546299696, 'total_tl_reward_no_entropy': -1.8771899584680796, 'no_entropy_unprocessed_thought_kl/_mean': 0.2889404296875, 'no_entropy_unprocessed_thought_kl/_sum': 1075.03125, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 17.6396484375, 'no_entropy_unprocessed_thought_kl/_median': 1.954101026058197e-05, 'no_entropy_unprocessed_thought_kl/_first_quartile': 0.0, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.06679153442382812, 'no_entropy_reasoning_kl_mean': 0.2889404296875, 'no_entropy_reasoning_kl_max': 17.6396484375, 'rewards/TeacherKLBasedReward': -1.620713472366333, 'reward': -1.620713472366333, 'reward_std': 0.22187955677509308, 'completion_length': 8236.435546875, 'kl': 0.0014160871505737305, 'epoch': 0.02}
  2%|▏         | 35/1410 [50:15:25<2213:35:55, 5795.60s/it]Total time to update VLLMs: 34.928835 s
[2025-08-21 01:13:47,579] [WARNING] [stage3.py:2114:step] 319 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 36/1410 [51:55:40<2237:05:05, 5861.36s/it]                                                           {'loss': 0.0001, 'grad_norm': 0.07445642013267145, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.71826171875, 'unprocessed_answer_log_prob/_sum': -408.0625, 'unprocessed_answer_log_prob/_min': -20.89453125, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -5.007721483707428e-05, 'unprocessed_answer_log_prob/_first_quartile': -0.06426858901977539, 'unprocessed_answer_log_prob/_last_quartile': -7.916241884231567e-09, 'unprocessed_thought_kl/_mean': 0.1056060791015625, 'unprocessed_thought_kl/_sum': 525.46875, 'unprocessed_thought_kl/_min': -3.264892578125, 'unprocessed_thought_kl/_max': 8.716796875, 'unprocessed_thought_kl/_median': 2.738088369369507e-07, 'unprocessed_thought_kl/_first_quartile': -0.000138050876557827, 'unprocessed_thought_kl/_last_quartile': 0.04635882377624512, 'answer_log_prob_mean': -0.71826171875, 'answer_log_prob_min': -20.89453125, 'solution_log_prob_reward': -0.9272070210427046, 'reasoning_kl_mean': 0.1056060791015625, 'reasoning_kl_max': 8.716796875, 'thought_processed_kl': 0.105621337890625, 'thought_kl_scores': 4.413818359375, 'kl_reward': -0.5783221400342882, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.5055291596800089, 'processed_kl_no_entropy': 0.415435791015625, 'kl_scores_no_entropy': 6.43359375, 'kl_reward_no_entropy': -1.6196557525545359, 'total_tl_reward_no_entropy': -2.546862781047821, 'no_entropy_unprocessed_thought_kl/_mean': 0.41534423828125, 'no_entropy_unprocessed_thought_kl/_sum': 2144.5, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 12.4541015625, 'no_entropy_unprocessed_thought_kl/_median': 0.011310458183288574, 'no_entropy_unprocessed_thought_kl/_first_quartile': 4.13600355386734e-06, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.3406982421875, 'no_entropy_reasoning_kl_mean': 0.41534423828125, 'no_entropy_reasoning_kl_max': 12.4541015625, 'rewards/TeacherKLBasedReward': -1.53306245803833, 'reward': -1.53306245803833, 'reward_std': 0.20695394277572632, 'completion_length': 8604.048828125, 'kl': 0.0015250444412231445, 'epoch': 0.03}
  3%|▎         | 36/1410 [51:55:40<2237:05:05, 5861.36s/it]Total time to update VLLMs: 34.846000 s
[2025-08-21 02:44:41,969] [WARNING] [stage3.py:2114:step] 297 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 37/1410 [53:26:34<2188:53:30, 5739.27s/it]                                                           {'loss': 0.0001, 'grad_norm': 0.07771852961488827, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.499603271484375, 'unprocessed_answer_log_prob/_sum': -279.734375, 'unprocessed_answer_log_prob/_min': -15.2802734375, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -2.421438694000244e-08, 'unprocessed_answer_log_prob/_first_quartile': -0.0019397102296352386, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.09836578369140625, 'unprocessed_thought_kl/_sum': 467.125, 'unprocessed_thought_kl/_min': -3.1715087890625, 'unprocessed_thought_kl/_max': 8.6943359375, 'unprocessed_thought_kl/_median': 8.381903171539307e-08, 'unprocessed_thought_kl/_first_quartile': -7.018400356173515e-05, 'unprocessed_thought_kl/_last_quartile': 0.03513979911804199, 'answer_log_prob_mean': -0.499603271484375, 'answer_log_prob_min': -15.2802734375, 'solution_log_prob_reward': -0.6524059996008873, 'reasoning_kl_mean': 0.09836578369140625, 'reasoning_kl_max': 8.6943359375, 'thought_processed_kl': 0.09838104248046875, 'thought_kl_scores': 4.395263671875, 'kl_reward': -0.555927422363311, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.208333421498537, 'processed_kl_no_entropy': 0.397857666015625, 'kl_scores_no_entropy': 6.07470703125, 'kl_reward_no_entropy': -1.545937491580844, 'total_tl_reward_no_entropy': -2.198343487456441, 'no_entropy_unprocessed_thought_kl/_mean': 0.3978271484375, 'no_entropy_unprocessed_thought_kl/_sum': 1940.125, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 11.74853515625, 'no_entropy_unprocessed_thought_kl/_median': 0.0084439218044281, 'no_entropy_unprocessed_thought_kl/_first_quartile': 6.989575922489166e-07, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.3059234619140625, 'no_entropy_reasoning_kl_mean': 0.3978271484375, 'no_entropy_reasoning_kl_max': 11.74853515625, 'rewards/TeacherKLBasedReward': -1.5850666761398315, 'reward': -1.5850666761398315, 'reward_std': 0.13143357634544373, 'completion_length': 6338.111328125, 'kl': 0.0018264055252075195, 'epoch': 0.03}
  3%|▎         | 37/1410 [53:26:35<2188:53:30, 5739.27s/it]Total time to update VLLMs: 35.091670 s
[2025-08-21 03:56:35,673] [WARNING] [stage3.py:2114:step] 229 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 38/1410 [54:38:28<2024:18:35, 5311.60s/it]                                                           {'loss': 0.0001, 'grad_norm': 0.08966099044945422, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.928955078125, 'unprocessed_answer_log_prob/_sum': -234.828125, 'unprocessed_answer_log_prob/_min': -19.548828125, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -0.0006433650851249695, 'unprocessed_answer_log_prob/_first_quartile': -0.19068145751953125, 'unprocessed_answer_log_prob/_last_quartile': -3.781169652938843e-07, 'unprocessed_thought_kl/_mean': 0.12102508544921875, 'unprocessed_thought_kl/_sum': 213.8515625, 'unprocessed_thought_kl/_min': -2.61572265625, 'unprocessed_thought_kl/_max': 7.49072265625, 'unprocessed_thought_kl/_median': 2.980232238769531e-07, 'unprocessed_thought_kl/_first_quartile': -0.0015132278203964233, 'unprocessed_thought_kl/_last_quartile': 0.057430267333984375, 'answer_log_prob_mean': -0.928955078125, 'answer_log_prob_min': -19.548828125, 'solution_log_prob_reward': -1.1244433503597975, 'reasoning_kl_mean': 0.12102508544921875, 'reasoning_kl_max': 7.49072265625, 'thought_processed_kl': 0.1210784912109375, 'thought_kl_scores': 3.80712890625, 'kl_reward': -0.5877969306893647, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.7122402805835009, 'processed_kl_no_entropy': 0.44146728515625, 'kl_scores_no_entropy': 5.8525390625, 'kl_reward_no_entropy': -1.6620812974870205, 'total_tl_reward_no_entropy': -2.786524649709463, 'no_entropy_unprocessed_thought_kl/_mean': 0.441375732421875, 'no_entropy_unprocessed_thought_kl/_sum': 798.25, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 11.26513671875, 'no_entropy_unprocessed_thought_kl/_median': 0.02215576171875, 'no_entropy_unprocessed_thought_kl/_first_quartile': 3.174552693963051e-05, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.3769378662109375, 'no_entropy_reasoning_kl_mean': 0.441375732421875, 'no_entropy_reasoning_kl_max': 11.26513671875, 'rewards/TeacherKLBasedReward': -1.5992521047592163, 'reward': -1.5992521047592163, 'reward_std': 0.1954953521490097, 'completion_length': 3727.955078125, 'kl': 0.0027087926864624023, 'epoch': 0.03}
  3%|▎         | 38/1410 [54:38:28<2024:18:35, 5311.60s/it]Total time to update VLLMs: 35.077926 s
[2025-08-21 05:33:14,439] [WARNING] [stage3.py:2114:step] 244 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 39/1410 [56:15:07<2078:29:29, 5457.75s/it]                                                           {'loss': 0.0001, 'grad_norm': 0.08816919839856176, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.69683837890625, 'unprocessed_answer_log_prob/_sum': -207.640625, 'unprocessed_answer_log_prob/_min': -15.7734375, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -0.0001619253307580948, 'unprocessed_answer_log_prob/_first_quartile': -0.08642816543579102, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.146881103515625, 'unprocessed_thought_kl/_sum': 266.640625, 'unprocessed_thought_kl/_min': -2.92529296875, 'unprocessed_thought_kl/_max': 8.9892578125, 'unprocessed_thought_kl/_median': 4.559755325317383e-06, 'unprocessed_thought_kl/_first_quartile': -0.002118721604347229, 'unprocessed_thought_kl/_last_quartile': 0.08563232421875, 'answer_log_prob_mean': -0.69683837890625, 'answer_log_prob_min': -15.7734375, 'solution_log_prob_reward': -0.8545727487653494, 'reasoning_kl_mean': 0.146881103515625, 'reasoning_kl_max': 8.9892578125, 'thought_processed_kl': 0.1469268798828125, 'thought_kl_scores': 4.566650390625, 'kl_reward': -0.7103210361674428, 'match_reward': 0.0, 'total_teacher_likelihood_reward': -1.564893789589405, 'processed_kl_no_entropy': 0.495819091796875, 'kl_scores_no_entropy': 6.34619140625, 'kl_reward_no_entropy': -1.8544116094708443, 'total_tl_reward_no_entropy': -2.708984375, 'no_entropy_unprocessed_thought_kl/_mean': 0.49615478515625, 'no_entropy_unprocessed_thought_kl/_sum': 923.28125, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 12.1982421875, 'no_entropy_unprocessed_thought_kl/_median': 0.03360462188720703, 'no_entropy_unprocessed_thought_kl/_first_quartile': 9.556720033288002e-05, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.462982177734375, 'no_entropy_reasoning_kl_mean': 0.49615478515625, 'no_entropy_reasoning_kl_max': 12.1982421875, 'rewards/TeacherKLBasedReward': -1.6906001567840576, 'reward': -1.6906001567840576, 'reward_std': 0.18955722451210022, 'completion_length': 7177.712890625, 'kl': 0.0021256208419799805, 'epoch': 0.03}
  3%|▎         | 39/1410 [56:15:07<2078:29:29, 5457.75s/it]Total time to update VLLMs: 34.938880 s
[2025-08-21 07:25:20,710] [WARNING] [stage3.py:2114:step] 413 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 40/1410 [58:07:13<2221:48:03, 5838.31s/it]                                                           {'loss': 0.0, 'grad_norm': 0.04578629045488592, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.520233154296875, 'unprocessed_answer_log_prob/_sum': -205.953125, 'unprocessed_answer_log_prob/_min': -19.19921875, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -1.3154000043869019e-05, 'unprocessed_answer_log_prob/_first_quartile': -0.04302024841308594, 'unprocessed_answer_log_prob/_last_quartile': 0.0, 'unprocessed_thought_kl/_mean': 0.0961151123046875, 'unprocessed_thought_kl/_sum': 927.78125, 'unprocessed_thought_kl/_min': -3.446533203125, 'unprocessed_thought_kl/_max': 8.9189453125, 'unprocessed_thought_kl/_median': 2.5015324354171753e-06, 'unprocessed_thought_kl/_first_quartile': -3.337673842906952e-05, 'unprocessed_thought_kl/_last_quartile': 0.046656131744384766, 'answer_log_prob_mean': -0.520233154296875, 'answer_log_prob_min': -19.19921875, 'solution_log_prob_reward': -0.712225335650146, 'reasoning_kl_mean': 0.0961151123046875, 'reasoning_kl_max': 8.9189453125, 'thought_processed_kl': 0.0960845947265625, 'thought_kl_scores': 4.5087890625, 'kl_reward': -0.5559136942028999, 'match_reward': -0.046875, 'total_teacher_likelihood_reward': -1.3150140270590782, 'processed_kl_no_entropy': 0.392303466796875, 'kl_scores_no_entropy': 6.69580078125, 'kl_reward_no_entropy': -1.5667858757078648, 'total_tl_reward_no_entropy': -2.3258862122893333, 'no_entropy_unprocessed_thought_kl/_mean': 0.392242431640625, 'no_entropy_unprocessed_thought_kl/_sum': 3826.5, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 13.001953125, 'no_entropy_unprocessed_thought_kl/_median': 0.012425065040588379, 'no_entropy_unprocessed_thought_kl/_first_quartile': 4.298985004425049e-06, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.3258171081542969, 'no_entropy_reasoning_kl_mean': 0.392242431640625, 'no_entropy_reasoning_kl_max': 13.001953125, 'rewards/TeacherKLBasedReward': -1.5644575357437134, 'reward': -1.5644575357437134, 'reward_std': 0.31240344047546387, 'completion_length': 11559.251953125, 'kl': 0.0011773109436035156, 'epoch': 0.03}
  3%|▎         | 40/1410 [58:07:13<2221:48:03, 5838.31s/it]Total time to update VLLMs: 35.039640 s
[2025-08-21 09:08:53,022] [WARNING] [stage3.py:2114:step] 332 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 41/1410 [59:50:46<2262:51:01, 5950.52s/it]                                                           {'loss': 0.0001, 'grad_norm': 0.04532790119458976, 'learning_rate': 1e-06, 'unprocessed_answer_log_prob/_mean': -0.6312255859375, 'unprocessed_answer_log_prob/_sum': -210.875, 'unprocessed_answer_log_prob/_min': -17.5244140625, 'unprocessed_answer_log_prob/_max': 0.0, 'unprocessed_answer_log_prob/_median': -5.932711064815521e-05, 'unprocessed_answer_log_prob/_first_quartile': -0.05024147033691406, 'unprocessed_answer_log_prob/_last_quartile': -9.825453162193298e-08, 'unprocessed_thought_kl/_mean': 0.11513519287109375, 'unprocessed_thought_kl/_sum': 752.0, 'unprocessed_thought_kl/_min': -3.522705078125, 'unprocessed_thought_kl/_max': 8.2578125, 'unprocessed_thought_kl/_median': 1.955777406692505e-07, 'unprocessed_thought_kl/_first_quartile': -0.00019436050206422806, 'unprocessed_thought_kl/_last_quartile': 0.05807066895067692, 'answer_log_prob_mean': -0.6312255859375, 'answer_log_prob_min': -17.5244140625, 'solution_log_prob_reward': -0.8064697226509452, 'reasoning_kl_mean': 0.11513519287109375, 'reasoning_kl_max': 8.2578125, 'thought_processed_kl': 0.1150360107421875, 'thought_kl_scores': 4.18798828125, 'kl_reward': -0.5931399534456432, 'match_reward': -0.015625, 'total_teacher_likelihood_reward': -1.415234673768282, 'processed_kl_no_entropy': 0.44232177734375, 'kl_scores_no_entropy': 6.5166015625, 'kl_reward_no_entropy': -1.7051147362217307, 'total_tl_reward_no_entropy': -2.52720944583416, 'no_entropy_unprocessed_thought_kl/_mean': 0.44244384765625, 'no_entropy_unprocessed_thought_kl/_sum': 2928.0, 'no_entropy_unprocessed_thought_kl/_min': 0.0, 'no_entropy_unprocessed_thought_kl/_max': 12.5927734375, 'no_entropy_unprocessed_thought_kl/_median': 0.02012050151824951, 'no_entropy_unprocessed_thought_kl/_first_quartile': 6.252899765968323e-06, 'no_entropy_unprocessed_thought_kl/_last_quartile': 0.3834192752838135, 'no_entropy_reasoning_kl_mean': 0.44244384765625, 'no_entropy_reasoning_kl_max': 12.5927734375, 'rewards/TeacherKLBasedReward': -1.4575848579406738, 'reward': -1.4575848579406738, 'reward_std': 0.13357728719711304, 'completion_length': 9407.423828125, 'kl': 0.0014157295227050781, 'epoch': 0.03}
  3%|▎         | 41/1410 [59:50:46<2262:51:01, 5950.52s/it]Total time to update VLLMs: 35.015811 s
slurmstepd: error: *** JOB 376355 ON osk-gpu71 CANCELLED AT 2025-08-21T09:33:25 ***
