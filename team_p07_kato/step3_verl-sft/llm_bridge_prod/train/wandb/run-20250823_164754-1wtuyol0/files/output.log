Epoch 1/1:   1%|          | 31/3440 [05:11<9:24:15,  9.93s/it]
step:1 - train/loss:0.8974639177322388 - train/lr(1e-3):0.00029069767441860465
step:2 - train/loss:1.361262321472168 - train/lr(1e-3):0.0005813953488372093
step:3 - train/loss:1.3249799013137817 - train/lr(1e-3):0.0008720930232558139
step:4 - train/loss:1.0417250394821167 - train/lr(1e-3):0.0011627906976744186
step:5 - train/loss:0.9964918494224548 - train/lr(1e-3):0.0014534883720930235
step:6 - train/loss:1.2340110540390015 - train/lr(1e-3):0.0017441860465116279
step:7 - train/loss:1.2273083925247192 - train/lr(1e-3):0.002034883720930233
step:8 - train/loss:1.1638233661651611 - train/lr(1e-3):0.002325581395348837
step:9 - train/loss:1.2883789539337158 - train/lr(1e-3):0.002616279069767442
step:10 - train/loss:1.313858151435852 - train/lr(1e-3):0.002906976744186047
step:11 - train/loss:1.0665308237075806 - train/lr(1e-3):0.0031976744186046516
step:12 - train/loss:1.0663862228393555 - train/lr(1e-3):0.0034883720930232558
step:13 - train/loss:1.3662118911743164 - train/lr(1e-3):0.0037790697674418604
step:14 - train/loss:0.9106855988502502 - train/lr(1e-3):0.004069767441860466
step:15 - train/loss:1.2691004276275635 - train/lr(1e-3):0.004360465116279071
step:16 - train/loss:0.9107788801193237 - train/lr(1e-3):0.004651162790697674
step:17 - train/loss:1.0680135488510132 - train/lr(1e-3):0.004941860465116279
step:18 - train/loss:1.1634554862976074 - train/lr(1e-3):0.005232558139534884
step:19 - train/loss:1.289276123046875 - train/lr(1e-3):0.005523255813953488
step:20 - train/loss:0.9540577530860901 - train/lr(1e-3):0.005813953488372094
step:21 - train/loss:1.300014853477478 - train/lr(1e-3):0.006104651162790698
step:22 - train/loss:1.0948853492736816 - train/lr(1e-3):0.006395348837209303
step:23 - train/loss:1.0701441764831543 - train/lr(1e-3):0.006686046511627907
step:24 - train/loss:0.8435136079788208 - train/lr(1e-3):0.0069767441860465115
step:25 - train/loss:0.9357538223266602 - train/lr(1e-3):0.007267441860465117
step:26 - train/loss:0.8453605771064758 - train/lr(1e-3):0.007558139534883721
step:27 - train/loss:0.8268795013427734 - train/lr(1e-3):0.007848837209302325
step:28 - train/loss:0.7057469487190247 - train/lr(1e-3):0.008139534883720932
step:29 - train/loss:0.9246121048927307 - train/lr(1e-3):0.008430232558139536
step:30 - train/loss:0.753232479095459 - train/lr(1e-3):0.008720930232558141
step:31 - train/loss:0.8450802564620972 - train/lr(1e-3):0.009011627906976745
step:32 - train/loss:0.8764693737030029 - train/lr(1e-3):0.009302325581395349
step:33 - train/loss:0.6833200454711914 - train/lr(1e-3):0.009593023255813954
step:34 - train/loss:0.6643710136413574 - train/lr(1e-3):0.009883720930232558
step:35 - train/loss:0.7861436605453491 - train/lr(1e-3):0.010174418604651164
step:36 - train/loss:0.6631001234054565 - train/lr(1e-3):0.010465116279069767
step:37 - train/loss:0.6962591409683228 - train/lr(1e-3):0.010755813953488371
step:38 - train/loss:0.8034102916717529 - train/lr(1e-3):0.011046511627906977
step:39 - train/loss:0.7299047708511353 - train/lr(1e-3):0.011337209302325582
step:40 - train/loss:0.7807413935661316 - train/lr(1e-3):0.011627906976744188
step:41 - train/loss:0.7537792921066284 - train/lr(1e-3):0.011918604651162791
step:42 - train/loss:0.7228553891181946 - train/lr(1e-3):0.012209302325581395
step:43 - train/loss:0.6432340145111084 - train/lr(1e-3):0.0125
step:44 - train/loss:0.8073855638504028 - train/lr(1e-3):0.012790697674418606
step:45 - train/loss:0.8017814755439758 - train/lr(1e-3):0.01308139534883721
step:46 - train/loss:0.7240966558456421 - train/lr(1e-3):0.013372093023255814
step:47 - train/loss:0.7556363940238953 - train/lr(1e-3):0.013662790697674418
step:48 - train/loss:0.6973284482955933 - train/lr(1e-3):0.013953488372093023
step:49 - train/loss:0.7149648666381836 - train/lr(1e-3):0.014244186046511629
step:50 - train/loss:0.7868728637695312 - train/lr(1e-3):0.014534883720930234
step:51 - train/loss:0.7215502858161926 - train/lr(1e-3):0.01482558139534884
step:52 - train/loss:0.6356416344642639 - train/lr(1e-3):0.015116279069767442
step:53 - train/loss:0.6966888904571533 - train/lr(1e-3):0.015406976744186045
step:54 - train/loss:0.9694409966468811 - train/lr(1e-3):0.01569767441860465
step:55 - train/loss:0.6899625062942505 - train/lr(1e-3):0.015988372093023256
step:56 - train/loss:0.779242992401123 - train/lr(1e-3):0.016279069767441864
step:57 - train/loss:0.6494481563568115 - train/lr(1e-3):0.016569767441860464
step:58 - train/loss:0.8788080215454102 - train/lr(1e-3):0.01686046511627907
step:59 - train/loss:0.6263972520828247 - train/lr(1e-3):0.017151162790697675
step:60 - train/loss:0.5702786445617676 - train/lr(1e-3):0.017441860465116282
step:61 - train/loss:0.6717758178710938 - train/lr(1e-3):0.017732558139534886
step:62 - train/loss:0.6982014179229736 - train/lr(1e-3):0.01802325581395349
step:63 - train/loss:0.6744555234909058 - train/lr(1e-3):0.01831395348837209
step:64 - train/loss:0.7549484968185425 - train/lr(1e-3):0.018604651162790697
step:65 - train/loss:0.6222826242446899 - train/lr(1e-3):0.0188953488372093
step:66 - train/loss:0.6883084177970886 - train/lr(1e-3):0.01918604651162791
step:67 - train/loss:0.7171046733856201 - train/lr(1e-3):0.019476744186046516
step:68 - train/loss:0.7649893164634705 - train/lr(1e-3):0.019767441860465116
step:69 - train/loss:0.6953111886978149 - train/lr(1e-3):0.020058139534883723
step:70 - train/loss:0.6019997596740723 - train/lr(1e-3):0.020348837209302327
step:71 - train/loss:0.5081264972686768 - train/lr(1e-3):0.020639534883720934
step:72 - train/loss:0.7648681402206421 - train/lr(1e-3):0.020930232558139535
step:73 - train/loss:0.6141468286514282 - train/lr(1e-3):0.02122093023255814
step:74 - train/loss:0.7067673206329346 - train/lr(1e-3):0.021511627906976742
step:75 - train/loss:0.6212670803070068 - train/lr(1e-3):0.02180232558139535
step:76 - train/loss:0.694983720779419 - train/lr(1e-3):0.022093023255813953
step:77 - train/loss:0.6892916560173035 - train/lr(1e-3):0.02238372093023256
step:78 - train/loss:0.6052898168563843 - train/lr(1e-3):0.022674418604651164
step:79 - train/loss:0.6930991411209106 - train/lr(1e-3):0.022965116279069768
step:80 - train/loss:0.7360043525695801 - train/lr(1e-3):0.023255813953488375
step:81 - train/loss:0.5928797125816345 - train/lr(1e-3):0.02354651162790698
step:82 - train/loss:0.6234909296035767 - train/lr(1e-3):0.023837209302325583
step:83 - train/loss:0.7739361524581909 - train/lr(1e-3):0.024127906976744187
step:84 - train/loss:0.4368267059326172 - train/lr(1e-3):0.02441860465116279
step:85 - train/loss:0.6233232617378235 - train/lr(1e-3):0.024709302325581394
step:86 - train/loss:0.6462885737419128 - train/lr(1e-3):0.025
step:87 - train/loss:0.720653772354126 - train/lr(1e-3):0.025290697674418605
step:88 - train/loss:0.7912856340408325 - train/lr(1e-3):0.025581395348837212
step:89 - train/loss:0.6977953910827637 - train/lr(1e-3):0.02587209302325582
step:90 - train/loss:0.5152426362037659 - train/lr(1e-3):0.02616279069767442
step:91 - train/loss:0.632091760635376 - train/lr(1e-3):0.026453488372093027
step:92 - train/loss:0.6094988584518433 - train/lr(1e-3):0.026744186046511628
step:93 - train/loss:0.6029471755027771 - train/lr(1e-3):0.02703488372093023
step:94 - train/loss:0.7923966646194458 - train/lr(1e-3):0.027325581395348835
step:95 - train/loss:0.7465742826461792 - train/lr(1e-3):0.027616279069767442
step:96 - train/loss:0.6641185283660889 - train/lr(1e-3):0.027906976744186046
step:97 - train/loss:0.638292133808136 - train/lr(1e-3):0.028197674418604653
step:98 - train/loss:0.6325891613960266 - train/lr(1e-3):0.028488372093023257
step:99 - train/loss:0.6478533744812012 - train/lr(1e-3):0.028779069767441864
step:100 - train/loss:0.7027191519737244 - train/lr(1e-3):0.029069767441860468
step:101 - train/loss:0.5974307656288147 - train/lr(1e-3):0.029360465116279072
step:102 - train/loss:0.6845263242721558 - train/lr(1e-3):0.02965116279069768
step:103 - train/loss:0.6847895383834839 - train/lr(1e-3):0.029941860465116276
step:104 - train/loss:0.5880193710327148 - train/lr(1e-3):0.030232558139534883
step:105 - train/loss:0.6429524421691895 - train/lr(1e-3):0.030523255813953487
step:106 - train/loss:0.5427761673927307 - train/lr(1e-3):0.03081395348837209
step:107 - train/loss:0.6392512917518616 - train/lr(1e-3):0.031104651162790698
step:108 - train/loss:0.6330981850624084 - train/lr(1e-3):0.0313953488372093
step:109 - train/loss:0.6646715998649597 - train/lr(1e-3):0.03168604651162791
step:110 - train/loss:0.656804084777832 - train/lr(1e-3):0.03197674418604651
step:111 - train/loss:0.6084256768226624 - train/lr(1e-3):0.032267441860465124
step:112 - train/loss:0.6356775164604187 - train/lr(1e-3):0.03255813953488373
step:113 - train/loss:0.5044342279434204 - train/lr(1e-3):0.032848837209302324
step:114 - train/loss:0.577328085899353 - train/lr(1e-3):0.03313953488372093
step:115 - train/loss:0.6232317686080933 - train/lr(1e-3):0.03343023255813954
step:116 - train/loss:0.49188369512557983 - train/lr(1e-3):0.03372093023255814
step:117 - train/loss:0.6636642217636108 - train/lr(1e-3):0.03401162790697674
step:118 - train/loss:0.6593043804168701 - train/lr(1e-3):0.03430232558139535
step:119 - train/loss:0.6376910209655762 - train/lr(1e-3):0.034593023255813954
step:120 - train/loss:0.6736676692962646 - train/lr(1e-3):0.034883720930232565
step:121 - train/loss:0.6711122393608093 - train/lr(1e-3):0.03517441860465117
step:122 - train/loss:0.5827603340148926 - train/lr(1e-3):0.03546511627906977
step:123 - train/loss:0.618183434009552 - train/lr(1e-3):0.035755813953488376
step:124 - train/loss:0.7812044620513916 - train/lr(1e-3):0.03604651162790698
step:125 - train/loss:0.7007108926773071 - train/lr(1e-3):0.036337209302325583
step:126 - train/loss:0.6369636654853821 - train/lr(1e-3):0.03662790697674418
step:127 - train/loss:0.5280190110206604 - train/lr(1e-3):0.03691860465116279
step:128 - train/loss:0.6777480244636536 - train/lr(1e-3):0.037209302325581395
step:129 - train/loss:0.5834999680519104 - train/lr(1e-3):0.037500000000000006
step:130 - train/loss:0.49848681688308716 - train/lr(1e-3):0.0377906976744186
step:131 - train/loss:0.739371657371521 - train/lr(1e-3):0.03808139534883721
step:132 - train/loss:0.5623592138290405 - train/lr(1e-3):0.03837209302325582
step:133 - train/loss:0.6115210056304932 - train/lr(1e-3):0.03866279069767442
step:134 - train/loss:0.6725435256958008 - train/lr(1e-3):0.03895348837209303
step:135 - train/loss:0.6726015210151672 - train/lr(1e-3):0.03924418604651163
step:136 - train/loss:0.6442877054214478 - train/lr(1e-3):0.03953488372093023
step:137 - train/loss:0.6536517143249512 - train/lr(1e-3):0.039825581395348836
step:138 - train/loss:0.5199561715126038 - train/lr(1e-3):0.040116279069767447
step:139 - train/loss:0.5153564214706421 - train/lr(1e-3):0.04040697674418604
step:140 - train/loss:0.5970557332038879 - train/lr(1e-3):0.040697674418604654
step:141 - train/loss:0.5950694680213928 - train/lr(1e-3):0.04098837209302326
step:142 - train/loss:0.6737152338027954 - train/lr(1e-3):0.04127906976744187
step:143 - train/loss:0.7017706632614136 - train/lr(1e-3):0.04156976744186047
step:144 - train/loss:0.5781734585762024 - train/lr(1e-3):0.04186046511627907
step:145 - train/loss:0.5714752674102783 - train/lr(1e-3):0.04215116279069768
step:146 - train/loss:0.5738462209701538 - train/lr(1e-3):0.04244186046511628
step:147 - train/loss:0.7101094722747803 - train/lr(1e-3):0.04273255813953489
step:148 - train/loss:0.6365765929222107 - train/lr(1e-3):0.043023255813953484
step:149 - train/loss:0.744108259677887 - train/lr(1e-3):0.043313953488372095
step:150 - train/loss:0.6860994100570679 - train/lr(1e-3):0.0436046511627907
step:151 - train/loss:0.6083139181137085 - train/lr(1e-3):0.04389534883720931
step:152 - train/loss:0.6879174113273621 - train/lr(1e-3):0.044186046511627906
step:153 - train/loss:0.590604841709137 - train/lr(1e-3):0.04447674418604651
step:154 - train/loss:0.7422551512718201 - train/lr(1e-3):0.04476744186046512
step:155 - train/loss:0.7847902774810791 - train/lr(1e-3):0.045058139534883725
step:156 - train/loss:0.7970210313796997 - train/lr(1e-3):0.04534883720930233
step:157 - train/loss:0.6455631256103516 - train/lr(1e-3):0.045639534883720925
step:158 - train/loss:0.5865516662597656 - train/lr(1e-3):0.045930232558139536
step:159 - train/loss:0.7136459350585938 - train/lr(1e-3):0.04622093023255814
step:160 - train/loss:0.5754280090332031 - train/lr(1e-3):0.04651162790697675
step:161 - train/loss:0.6348567008972168 - train/lr(1e-3):0.04680232558139535
step:162 - train/loss:0.5223808884620667 - train/lr(1e-3):0.04709302325581396
step:163 - train/loss:0.5695423483848572 - train/lr(1e-3):0.04738372093023256
step:164 - train/loss:0.4804186522960663 - train/lr(1e-3):0.047674418604651166
step:165 - train/loss:0.5681452751159668 - train/lr(1e-3):0.047965116279069776
step:166 - train/loss:0.5861116647720337 - train/lr(1e-3):0.04825581395348837
step:167 - train/loss:0.5545450448989868 - train/lr(1e-3):0.04854651162790698
step:168 - train/loss:0.6402904987335205 - train/lr(1e-3):0.04883720930232558
step:169 - train/loss:0.6207824349403381 - train/lr(1e-3):0.04912790697674419
step:170 - train/loss:0.7286694049835205 - train/lr(1e-3):0.04941860465116279
step:171 - train/loss:0.6587229371070862 - train/lr(1e-3):0.0497093023255814
step:172 - train/loss:0.5145504474639893 - train/lr(1e-3):0.05
step:173 - train/loss:0.5877397060394287 - train/lr(1e-3):0.05029069767441861
step:174 - train/loss:0.5994479656219482 - train/lr(1e-3):0.05058139534883721
step:175 - train/loss:0.46517521142959595 - train/lr(1e-3):0.050872093023255814
step:176 - train/loss:0.5978925824165344 - train/lr(1e-3):0.051162790697674425
step:177 - train/loss:0.6040958762168884 - train/lr(1e-3):0.05145348837209303
step:178 - train/loss:0.6996203064918518 - train/lr(1e-3):0.05174418604651164
step:179 - train/loss:0.6550235748291016 - train/lr(1e-3):0.052034883720930236
step:180 - train/loss:0.6748896837234497 - train/lr(1e-3):0.05232558139534884
step:181 - train/loss:0.6383956074714661 - train/lr(1e-3):0.05261627906976745
step:182 - train/loss:0.6916016340255737 - train/lr(1e-3):0.052906976744186054
step:183 - train/loss:0.5765678882598877 - train/lr(1e-3):0.053197674418604644
step:184 - train/loss:0.5543432831764221 - train/lr(1e-3):0.053488372093023255
step:185 - train/loss:0.608370840549469 - train/lr(1e-3):0.05377906976744186
step:186 - train/loss:0.5261199474334717 - train/lr(1e-3):0.05406976744186046
step:187 - train/loss:0.6082315444946289 - train/lr(1e-3):0.05436046511627907
step:188 - train/loss:0.756725013256073 - train/lr(1e-3):0.05465116279069767
step:189 - train/loss:0.561010479927063 - train/lr(1e-3):0.05494186046511628
step:190 - train/loss:0.6242022514343262 - train/lr(1e-3):0.055232558139534885
step:191 - train/loss:0.6047595143318176 - train/lr(1e-3):0.055523255813953495
step:192 - train/loss:0.5066665410995483 - train/lr(1e-3):0.05581395348837209
step:193 - train/loss:0.6091127395629883 - train/lr(1e-3):0.056104651162790696
step:194 - train/loss:0.5439061522483826 - train/lr(1e-3):0.05639534883720931
step:195 - train/loss:0.5723037123680115 - train/lr(1e-3):0.05668604651162791
step:196 - train/loss:0.5892271995544434 - train/lr(1e-3):0.056976744186046514
step:197 - train/loss:0.5551703572273254 - train/lr(1e-3):0.05726744186046512
step:198 - train/loss:0.6512243151664734 - train/lr(1e-3):0.05755813953488373
step:199 - train/loss:0.6985534429550171 - train/lr(1e-3):0.05784883720930233
step:200 - train/loss:0.5735005140304565 - train/lr(1e-3):0.058139534883720936
step:201 - train/loss:0.5774365663528442 - train/lr(1e-3):0.05843023255813954
step:202 - train/loss:0.6854473352432251 - train/lr(1e-3):0.058720930232558144
step:203 - train/loss:0.6644076108932495 - train/lr(1e-3):0.059011627906976755
step:204 - train/loss:0.5763206481933594 - train/lr(1e-3):0.05930232558139536
step:205 - train/loss:0.632632315158844 - train/lr(1e-3):0.05959302325581395
step:206 - train/loss:0.5161043405532837 - train/lr(1e-3):0.05988372093023255
step:207 - train/loss:0.6480716466903687 - train/lr(1e-3):0.06017441860465116
step:208 - train/loss:0.7806277275085449 - train/lr(1e-3):0.06046511627906977
step:209 - train/loss:0.6676326394081116 - train/lr(1e-3):0.06075581395348838
step:210 - train/loss:0.5844702124595642 - train/lr(1e-3):0.061046511627906974
step:211 - train/loss:0.6150110363960266 - train/lr(1e-3):0.06133720930232558
step:212 - train/loss:0.7287296056747437 - train/lr(1e-3):0.06162790697674418
step:213 - train/loss:0.6431350708007812 - train/lr(1e-3):0.0619186046511628
step:214 - train/loss:0.6723447442054749 - train/lr(1e-3):0.062209302325581396
step:215 - train/loss:0.579186737537384 - train/lr(1e-3):0.0625
step:216 - train/loss:0.6623425483703613 - train/lr(1e-3):0.0627906976744186
step:217 - train/loss:0.7161689400672913 - train/lr(1e-3):0.06308139534883722
step:218 - train/loss:0.6046993136405945 - train/lr(1e-3):0.06337209302325582
step:219 - train/loss:0.689714789390564 - train/lr(1e-3):0.06366279069767443
step:220 - train/loss:0.6726977825164795 - train/lr(1e-3):0.06395348837209303
step:221 - train/loss:0.6204363107681274 - train/lr(1e-3):0.06424418604651162
step:222 - train/loss:0.5918700695037842 - train/lr(1e-3):0.06453488372093025
step:223 - train/loss:0.6109989285469055 - train/lr(1e-3):0.06482558139534884
step:224 - train/loss:0.6125002503395081 - train/lr(1e-3):0.06511627906976745
step:225 - train/loss:0.5738018155097961 - train/lr(1e-3):0.06540697674418605
step:226 - train/loss:0.7225789427757263 - train/lr(1e-3):0.06569767441860465
step:227 - train/loss:0.7057924866676331 - train/lr(1e-3):0.06598837209302326
step:228 - train/loss:0.6294992566108704 - train/lr(1e-3):0.06627906976744186
step:229 - train/loss:0.6613690853118896 - train/lr(1e-3):0.06656976744186047
step:230 - train/loss:0.5466867089271545 - train/lr(1e-3):0.06686046511627908
step:231 - train/loss:0.6777349710464478 - train/lr(1e-3):0.06715116279069767
step:232 - train/loss:0.6040230989456177 - train/lr(1e-3):0.06744186046511629
step:233 - train/loss:0.5449941754341125 - train/lr(1e-3):0.06773255813953488
step:234 - train/loss:0.6169288754463196 - train/lr(1e-3):0.06802325581395348
step:235 - train/loss:0.6575273871421814 - train/lr(1e-3):0.0683139534883721
step:236 - train/loss:0.5314134359359741 - train/lr(1e-3):0.0686046511627907
step:237 - train/loss:0.5726909637451172 - train/lr(1e-3):0.06889534883720931
step:238 - train/loss:0.6809842586517334 - train/lr(1e-3):0.06918604651162791
step:239 - train/loss:0.5680147409439087 - train/lr(1e-3):0.0694767441860465
step:240 - train/loss:0.597801685333252 - train/lr(1e-3):0.06976744186046513
step:241 - train/loss:0.6695804595947266 - train/lr(1e-3):0.07005813953488373
step:242 - train/loss:0.5540549159049988 - train/lr(1e-3):0.07034883720930234
step:243 - train/loss:0.660074770450592 - train/lr(1e-3):0.07063953488372093
step:244 - train/loss:0.6708853244781494 - train/lr(1e-3):0.07093023255813954
step:245 - train/loss:0.7742011547088623 - train/lr(1e-3):0.07122093023255816
step:246 - train/loss:0.5919494032859802 - train/lr(1e-3):0.07151162790697675
step:247 - train/loss:0.49822431802749634 - train/lr(1e-3):0.07180232558139535
step:248 - train/loss:0.5346558094024658 - train/lr(1e-3):0.07209302325581396
step:249 - train/loss:0.5957947373390198 - train/lr(1e-3):0.07238372093023256
step:250 - train/loss:0.561632513999939 - train/lr(1e-3):0.07267441860465117
step:251 - train/loss:0.5212008357048035 - train/lr(1e-3):0.07296511627906976
step:252 - train/loss:0.614863932132721 - train/lr(1e-3):0.07325581395348836
step:253 - train/loss:0.5859298706054688 - train/lr(1e-3):0.07354651162790699
step:254 - train/loss:0.5680106282234192 - train/lr(1e-3):0.07383720930232558
step:255 - train/loss:0.6574649214744568 - train/lr(1e-3):0.07412790697674419
step:256 - train/loss:0.6189020872116089 - train/lr(1e-3):0.07441860465116279
step:257 - train/loss:0.6205968260765076 - train/lr(1e-3):0.0747093023255814
step:258 - train/loss:0.740222692489624 - train/lr(1e-3):0.07500000000000001
step:259 - train/loss:0.5967039465904236 - train/lr(1e-3):0.07529069767441861
step:260 - train/loss:0.6384611129760742 - train/lr(1e-3):0.0755813953488372
step:261 - train/loss:0.6630908250808716 - train/lr(1e-3):0.07587209302325582
step:262 - train/loss:0.6274747848510742 - train/lr(1e-3):0.07616279069767443
step:263 - train/loss:0.6621541380882263 - train/lr(1e-3):0.07645348837209304
step:264 - train/loss:0.6082965731620789 - train/lr(1e-3):0.07674418604651163
step:265 - train/loss:0.6528512239456177 - train/lr(1e-3):0.07703488372093023
step:266 - train/loss:0.6883166432380676 - train/lr(1e-3):0.07732558139534884
step:267 - train/loss:0.517219066619873 - train/lr(1e-3):0.07761627906976745
step:268 - train/loss:0.6514647006988525 - train/lr(1e-3):0.07790697674418606
step:269 - train/loss:0.6039888858795166 - train/lr(1e-3):0.07819767441860465
step:270 - train/loss:0.69106125831604 - train/lr(1e-3):0.07848837209302326
step:271 - train/loss:0.5220142006874084 - train/lr(1e-3):0.07877906976744187
step:272 - train/loss:0.5995723605155945 - train/lr(1e-3):0.07906976744186046
step:273 - train/loss:0.5985957980155945 - train/lr(1e-3):0.07936046511627907
step:274 - train/loss:0.6556792259216309 - train/lr(1e-3):0.07965116279069767
step:275 - train/loss:0.6933935284614563 - train/lr(1e-3):0.07994186046511628
step:276 - train/loss:0.7254833579063416 - train/lr(1e-3):0.08023255813953489
step:277 - train/loss:0.612806499004364 - train/lr(1e-3):0.08052325581395349
step:278 - train/loss:0.5845646858215332 - train/lr(1e-3):0.08081395348837209
step:279 - train/loss:0.7338516116142273 - train/lr(1e-3):0.0811046511627907
step:280 - train/loss:0.7081038951873779 - train/lr(1e-3):0.08139534883720931
step:281 - train/loss:0.6467826962471008 - train/lr(1e-3):0.08168604651162792
step:282 - train/loss:0.63467937707901 - train/lr(1e-3):0.08197674418604652
step:283 - train/loss:0.7847216129302979 - train/lr(1e-3):0.08226744186046511
step:284 - train/loss:0.6047754287719727 - train/lr(1e-3):0.08255813953488374
step:285 - train/loss:0.6311558485031128 - train/lr(1e-3):0.08284883720930233
step:286 - train/loss:0.5695776343345642 - train/lr(1e-3):0.08313953488372094
step:287 - train/loss:0.6264868378639221 - train/lr(1e-3):0.08343023255813954
step:288 - train/loss:0.6369231343269348 - train/lr(1e-3):0.08372093023255814
step:289 - train/loss:0.6852895021438599 - train/lr(1e-3):0.08401162790697676
step:290 - train/loss:0.6573025584220886 - train/lr(1e-3):0.08430232558139536
step:291 - train/loss:0.7111361026763916 - train/lr(1e-3):0.08459302325581394
step:292 - train/loss:0.5722395777702332 - train/lr(1e-3):0.08488372093023255
step:293 - train/loss:0.629523515701294 - train/lr(1e-3):0.08517441860465116
step:294 - train/loss:0.699712872505188 - train/lr(1e-3):0.08546511627906977
step:295 - train/loss:0.6697916984558105 - train/lr(1e-3):0.08575581395348837
step:296 - train/loss:0.6290311813354492 - train/lr(1e-3):0.08604651162790697
step:297 - train/loss:0.6916407942771912 - train/lr(1e-3):0.0863372093023256
step:298 - train/loss:0.6570127010345459 - train/lr(1e-3):0.08662790697674419
step:299 - train/loss:0.6184845566749573 - train/lr(1e-3):0.0869186046511628
step:300 - train/loss:0.7963529825210571 - train/lr(1e-3):0.0872093023255814
step:301 - train/loss:0.6597431302070618 - train/lr(1e-3):0.0875
step:302 - train/loss:0.5525804758071899 - train/lr(1e-3):0.08779069767441862
step:303 - train/loss:0.6201528310775757 - train/lr(1e-3):0.08808139534883722
step:304 - train/loss:0.6193090677261353 - train/lr(1e-3):0.08837209302325581
step:305 - train/loss:0.6586489677429199 - train/lr(1e-3):0.08866279069767442
step:306 - train/loss:0.5626441836357117 - train/lr(1e-3):0.08895348837209302
step:307 - train/loss:0.6240302324295044 - train/lr(1e-3):0.08924418604651164
step:308 - train/loss:0.6539910435676575 - train/lr(1e-3):0.08953488372093024
step:309 - train/loss:0.6567196846008301 - train/lr(1e-3):0.08982558139534884
step:310 - train/loss:0.7949144840240479 - train/lr(1e-3):0.09011627906976745
step:311 - train/loss:0.6077100038528442 - train/lr(1e-3):0.09040697674418606
step:312 - train/loss:0.707858145236969 - train/lr(1e-3):0.09069767441860466
step:313 - train/loss:0.6950730681419373 - train/lr(1e-3):0.09098837209302325
step:314 - train/loss:0.8571469783782959 - train/lr(1e-3):0.09127906976744185
step:315 - train/loss:0.5649352073669434 - train/lr(1e-3):0.09156976744186048
step:316 - train/loss:0.8637227416038513 - train/lr(1e-3):0.09186046511627907
step:317 - train/loss:0.686766505241394 - train/lr(1e-3):0.09215116279069768
step:318 - train/loss:0.5203981399536133 - train/lr(1e-3):0.09244186046511628
step:319 - train/loss:0.6714228391647339 - train/lr(1e-3):0.09273255813953488
step:320 - train/loss:0.6892592906951904 - train/lr(1e-3):0.0930232558139535
step:321 - train/loss:0.6345142722129822 - train/lr(1e-3):0.0933139534883721
step:322 - train/loss:0.7104839086532593 - train/lr(1e-3):0.0936046511627907
step:323 - train/loss:0.5634521245956421 - train/lr(1e-3):0.0938953488372093
step:324 - train/loss:0.7312701344490051 - train/lr(1e-3):0.09418604651162792
step:325 - train/loss:0.5562554001808167 - train/lr(1e-3):0.09447674418604653
step:326 - train/loss:0.6867997050285339 - train/lr(1e-3):0.09476744186046512
step:327 - train/loss:0.5950547456741333 - train/lr(1e-3):0.09505813953488372
step:328 - train/loss:0.55799400806427 - train/lr(1e-3):0.09534883720930233
step:329 - train/loss:0.593652606010437 - train/lr(1e-3):0.09563953488372094
step:330 - train/loss:0.6391681432723999 - train/lr(1e-3):0.09593023255813955
step:331 - train/loss:0.6765735149383545 - train/lr(1e-3):0.09622093023255815
step:332 - train/loss:0.6805208921432495 - train/lr(1e-3):0.09651162790697675
step:333 - train/loss:0.6919270157814026 - train/lr(1e-3):0.09680232558139536
step:334 - train/loss:0.6173089146614075 - train/lr(1e-3):0.09709302325581395
step:335 - train/loss:0.6458494067192078 - train/lr(1e-3):0.09738372093023255
step:336 - train/loss:0.5652973651885986 - train/lr(1e-3):0.09767441860465116
step:337 - train/loss:0.5531538128852844 - train/lr(1e-3):0.09796511627906976
step:338 - train/loss:0.6949012875556946 - train/lr(1e-3):0.09825581395348838
step:339 - train/loss:0.7391330599784851 - train/lr(1e-3):0.09854651162790698
step:340 - train/loss:0.6238315105438232 - train/lr(1e-3):0.09883720930232558
step:341 - train/loss:0.7516869306564331 - train/lr(1e-3):0.09912790697674419
step:342 - train/loss:0.5506523847579956 - train/lr(1e-3):0.0994186046511628
step:343 - train/loss:0.6685898900032043 - train/lr(1e-3):0.09970930232558141
step:344 - train/loss:0.6172367334365845 - train/lr(1e-3):0.1
step:345 - train/loss:0.5955726504325867 - train/lr(1e-3):0.09999997425826514
step:346 - train/loss:0.6847540140151978 - train/lr(1e-3):0.09999989703308707
step:347 - train/loss:0.6648800373077393 - train/lr(1e-3):0.0999997683245453
step:348 - train/loss:0.5715738534927368 - train/lr(1e-3):0.09999958813277235
step:349 - train/loss:0.7694739699363708 - train/lr(1e-3):0.09999935645795374
step:350 - train/loss:0.6090496182441711 - train/lr(1e-3):0.09999907330032809
step:351 - train/loss:0.5329684615135193 - train/lr(1e-3):0.0999987386601869
step:352 - train/loss:0.7637103796005249 - train/lr(1e-3):0.09999835253787473
step:353 - train/loss:0.6350807547569275 - train/lr(1e-3):0.0999979149337892
step:354 - train/loss:0.6144869327545166 - train/lr(1e-3):0.09999742584838088
step:355 - train/loss:0.5826394557952881 - train/lr(1e-3):0.09999688528215334
step:356 - train/loss:0.7301633954048157 - train/lr(1e-3):0.09999629323566324
step:357 - train/loss:0.7258481979370117 - train/lr(1e-3):0.09999564970952013
step:358 - train/loss:0.6869711875915527 - train/lr(1e-3):0.09999495470438667
step:359 - train/loss:0.7147557139396667 - train/lr(1e-3):0.09999420822097849
step:360 - train/loss:0.5950344800949097 - train/lr(1e-3):0.0999934102600642
step:361 - train/loss:0.5568032264709473 - train/lr(1e-3):0.09999256082246541
step:362 - train/loss:0.7163898944854736 - train/lr(1e-3):0.09999165990905683
step:363 - train/loss:0.5170671939849854 - train/lr(1e-3):0.09999070752076605
step:364 - train/loss:0.7045683860778809 - train/lr(1e-3):0.09998970365857374
step:365 - train/loss:0.6919775605201721 - train/lr(1e-3):0.09998864832351351
step:366 - train/loss:0.6091659665107727 - train/lr(1e-3):0.09998754151667205
step:367 - train/loss:0.728868842124939 - train/lr(1e-3):0.099986383239189
step:368 - train/loss:0.8011088967323303 - train/lr(1e-3):0.09998517349225698
step:369 - train/loss:0.8341230154037476 - train/lr(1e-3):0.09998391227712163
step:370 - train/loss:0.6333433389663696 - train/lr(1e-3):0.0999825995950816
step:371 - train/loss:0.6769809722900391 - train/lr(1e-3):0.09998123544748852
step:372 - train/loss:0.7150930166244507 - train/lr(1e-3):0.09997981983574701
step:373 - train/loss:0.7071666717529297 - train/lr(1e-3):0.09997835276131464
step:374 - train/loss:0.684594988822937 - train/lr(1e-3):0.09997683422570207
step:375 - train/loss:0.7493551969528198 - train/lr(1e-3):0.09997526423047287
step:376 - train/loss:0.8148800730705261 - train/lr(1e-3):0.0999736427772436
step:377 - train/loss:0.6507487297058105 - train/lr(1e-3):0.09997196986768386
step:378 - train/loss:0.6886899471282959 - train/lr(1e-3):0.09997024550351616
step:379 - train/loss:0.695266604423523 - train/lr(1e-3):0.09996846968651603
step:380 - train/loss:0.6533514857292175 - train/lr(1e-3):0.09996664241851197
step:381 - train/loss:0.5633113384246826 - train/lr(1e-3):0.09996476370138548
step:382 - train/loss:0.7432408332824707 - train/lr(1e-3):0.09996283353707099
step:383 - train/loss:0.7099732160568237 - train/lr(1e-3):0.09996085192755597
step:384 - train/loss:0.6299788951873779 - train/lr(1e-3):0.0999588188748808
step:385 - train/loss:0.7209419012069702 - train/lr(1e-3):0.09995673438113882
step:386 - train/loss:0.9026141166687012 - train/lr(1e-3):0.09995459844847643
step:387 - train/loss:0.7053197026252747 - train/lr(1e-3):0.0999524110790929
step:388 - train/loss:0.6330170631408691 - train/lr(1e-3):0.09995017227524049
step:389 - train/loss:0.6472854614257812 - train/lr(1e-3):0.09994788203922447
step:390 - train/loss:0.5880323052406311 - train/lr(1e-3):0.09994554037340299
step:391 - train/loss:0.6614865660667419 - train/lr(1e-3):0.09994314728018716
step:392 - train/loss:0.7002824544906616 - train/lr(1e-3):0.09994070276204116
step:393 - train/loss:0.6302693486213684 - train/lr(1e-3):0.09993820682148197
step:394 - train/loss:0.6010385751724243 - train/lr(1e-3):0.09993565946107962
step:395 - train/loss:0.7102068066596985 - train/lr(1e-3):0.099933060683457
step:396 - train/loss:0.6931586265563965 - train/lr(1e-3):0.09993041049129005
step:397 - train/loss:0.7205472588539124 - train/lr(1e-3):0.09992770888730756
step:398 - train/loss:0.7380473017692566 - train/lr(1e-3):0.09992495587429129
step:399 - train/loss:0.6667919158935547 - train/lr(1e-3):0.09992215145507595
step:400 - train/loss:0.7949756383895874 - train/lr(1e-3):0.09991929563254914
step:401 - train/loss:0.712078332901001 - train/lr(1e-3):0.09991638840965143
step:402 - train/loss:0.7286338210105896 - train/lr(1e-3):0.09991342978937631
step:403 - train/loss:0.6668077707290649 - train/lr(1e-3):0.09991041977477014
step:404 - train/loss:0.6471076011657715 - train/lr(1e-3):0.09990735836893226
step:405 - train/loss:0.6557776927947998 - train/lr(1e-3):0.09990424557501494
step:406 - train/loss:0.8275486826896667 - train/lr(1e-3):0.09990108139622328
step:407 - train/loss:0.7068772315979004 - train/lr(1e-3):0.09989786583581535
step:408 - train/loss:0.6693412661552429 - train/lr(1e-3):0.09989459889710213
step:409 - train/loss:0.8065383434295654 - train/lr(1e-3):0.09989128058344748
step:410 - train/loss:0.7027559280395508 - train/lr(1e-3):0.09988791089826816
step:411 - train/loss:0.6762745380401611 - train/lr(1e-3):0.09988448984503384
step:412 - train/loss:0.7183217406272888 - train/lr(1e-3):0.09988101742726709
step:413 - train/loss:0.6610946655273438 - train/lr(1e-3):0.0998774936485433
step:414 - train/loss:0.5612598657608032 - train/lr(1e-3):0.09987391851249083
step:415 - train/loss:0.6944994926452637 - train/lr(1e-3):0.0998702920227909
step:416 - train/loss:0.6282320022583008 - train/lr(1e-3):0.09986661418317759
step:417 - train/loss:0.8258435726165771 - train/lr(1e-3):0.09986288499743783
step:418 - train/loss:0.8350525498390198 - train/lr(1e-3):0.0998591044694115
step:419 - train/loss:0.6447429060935974 - train/lr(1e-3):0.09985527260299124
step:420 - train/loss:0.666993260383606 - train/lr(1e-3):0.09985138940212264
step:421 - train/loss:0.6241564750671387 - train/lr(1e-3):0.09984745487080408
step:422 - train/loss:0.6268699765205383 - train/lr(1e-3):0.09984346901308687
step:423 - train/loss:0.6628585457801819 - train/lr(1e-3):0.0998394318330751
step:424 - train/loss:0.6883113980293274 - train/lr(1e-3):0.09983534333492575
step:425 - train/loss:0.6235180497169495 - train/lr(1e-3):0.0998312035228486
step:426 - train/loss:0.6022124886512756 - train/lr(1e-3):0.09982701240110628
step:427 - train/loss:0.7204362154006958 - train/lr(1e-3):0.09982276997401429
step:428 - train/loss:0.6635340452194214 - train/lr(1e-3):0.09981847624594091
step:429 - train/loss:0.8558810353279114 - train/lr(1e-3):0.09981413122130726
step:430 - train/loss:0.5666254162788391 - train/lr(1e-3):0.09980973490458728
step:431 - train/loss:0.646040678024292 - train/lr(1e-3):0.09980528730030773
step:432 - train/loss:0.6120603084564209 - train/lr(1e-3):0.09980078841304815
step:433 - train/loss:0.6925473213195801 - train/lr(1e-3):0.09979623824744094
step:434 - train/loss:0.7386723160743713 - train/lr(1e-3):0.09979163680817124
step:435 - train/loss:0.6393066048622131 - train/lr(1e-3):0.09978698409997701
step:436 - train/loss:0.5891312956809998 - train/lr(1e-3):0.09978228012764903
step:437 - train/loss:0.7544394731521606 - train/lr(1e-3):0.09977752489603083
step:438 - train/loss:0.6775882840156555 - train/lr(1e-3):0.09977271841001867
step:439 - train/loss:0.6634899973869324 - train/lr(1e-3):0.09976786067456173
step:440 - train/loss:0.5836308598518372 - train/lr(1e-3):0.09976295169466179
step:441 - train/loss:0.7387523055076599 - train/lr(1e-3):0.09975799147537354
step:442 - train/loss:0.7138044834136963 - train/lr(1e-3):0.09975298002180433
step:443 - train/loss:0.6495704054832458 - train/lr(1e-3):0.0997479173391143
step:444 - train/loss:0.7006523609161377 - train/lr(1e-3):0.09974280343251636
step:445 - train/loss:0.639123797416687 - train/lr(1e-3):0.09973763830727614
step:446 - train/loss:0.738364040851593 - train/lr(1e-3):0.09973242196871199
step:447 - train/loss:0.5842288136482239 - train/lr(1e-3):0.09972715442219501
step:448 - train/loss:0.6196275949478149 - train/lr(1e-3):0.0997218356731491
step:449 - train/loss:0.7127507925033569 - train/lr(1e-3):0.09971646572705073
step:450 - train/loss:0.6452469825744629 - train/lr(1e-3):0.0997110445894292
step:451 - train/loss:0.8432744741439819 - train/lr(1e-3):0.0997055722658665
step:452 - train/loss:0.6021639704704285 - train/lr(1e-3):0.0997000487619973
step:453 - train/loss:0.548084020614624 - train/lr(1e-3):0.099694474083509
step:454 - train/loss:0.6987460851669312 - train/lr(1e-3):0.09968884823614164
step:455 - train/loss:0.6040146350860596 - train/lr(1e-3):0.09968317122568802
step:456 - train/loss:0.6791510581970215 - train/lr(1e-3):0.09967744305799357
step:457 - train/loss:0.7796626687049866 - train/lr(1e-3):0.09967166373895642
step:458 - train/loss:0.6974351406097412 - train/lr(1e-3):0.09966583327452733
step:459 - train/loss:0.5722787976264954 - train/lr(1e-3):0.09965995167070978
step:460 - train/loss:0.8717119097709656 - train/lr(1e-3):0.09965401893355985
step:461 - train/loss:0.6846944689750671 - train/lr(1e-3):0.09964803506918635
step:462 - train/loss:0.6960383057594299 - train/lr(1e-3):0.09964200008375061
step:463 - train/loss:0.7167510986328125 - train/lr(1e-3):0.09963591398346672
step:464 - train/loss:0.5924798250198364 - train/lr(1e-3):0.09962977677460133
step:465 - train/loss:0.5972700715065002 - train/lr(1e-3):0.09962358846347374
step:466 - train/loss:0.6958422064781189 - train/lr(1e-3):0.09961734905645588
step:467 - train/loss:0.7465701699256897 - train/lr(1e-3):0.09961105855997225
step:468 - train/loss:0.8772835731506348 - train/lr(1e-3):0.0996047169805
step:469 - train/loss:0.7050590515136719 - train/lr(1e-3):0.09959832432456886
step:470 - train/loss:0.7868350744247437 - train/lr(1e-3):0.09959188059876115
step:471 - train/loss:0.541954755783081 - train/lr(1e-3):0.09958538580971178
step:472 - train/loss:0.6599891185760498 - train/lr(1e-3):0.09957883996410821
step:473 - train/loss:0.7888264060020447 - train/lr(1e-3):0.09957224306869053
step:474 - train/loss:0.7076878547668457 - train/lr(1e-3):0.09956559513025134
step:475 - train/loss:0.6148937344551086 - train/lr(1e-3):0.09955889615563583
step:476 - train/loss:0.6010707020759583 - train/lr(1e-3):0.09955214615174174
step:477 - train/loss:0.7825306057929993 - train/lr(1e-3):0.09954534512551932
step:478 - train/loss:0.730390727519989 - train/lr(1e-3):0.09953849308397138
step:479 - train/loss:0.6259020566940308 - train/lr(1e-3):0.09953159003415328
step:480 - train/loss:0.7992088198661804 - train/lr(1e-3):0.09952463598317285
step:481 - train/loss:0.6625586152076721 - train/lr(1e-3):0.09951763093819051
step:482 - train/loss:0.6836032867431641 - train/lr(1e-3):0.09951057490641906
step:483 - train/loss:0.7446547746658325 - train/lr(1e-3):0.09950346789512397
step:484 - train/loss:0.6409192085266113 - train/lr(1e-3):0.09949630991162305
step:485 - train/loss:0.6454178690910339 - train/lr(1e-3):0.09948910096328668
step:486 - train/loss:0.7070632576942444 - train/lr(1e-3):0.09948184105753768
step:487 - train/loss:0.6974253058433533 - train/lr(1e-3):0.09947453020185137
step:488 - train/loss:0.6512832045555115 - train/lr(1e-3):0.09946716840375551
step:489 - train/loss:0.7115002870559692 - train/lr(1e-3):0.09945975567083032
step:490 - train/loss:0.6399871110916138 - train/lr(1e-3):0.09945229201070845
step:491 - train/loss:0.611215353012085 - train/lr(1e-3):0.09944477743107502
step:492 - train/loss:0.701008677482605 - train/lr(1e-3):0.09943721193966755
step:493 - train/loss:0.6910562515258789 - train/lr(1e-3):0.09942959554427601
step:494 - train/loss:0.7133954763412476 - train/lr(1e-3):0.09942192825274275
step:495 - train/loss:0.4989106059074402 - train/lr(1e-3):0.09941421007296254
step:496 - train/loss:0.7420908212661743 - train/lr(1e-3):0.09940644101288258
step:497 - train/loss:0.5928396582603455 - train/lr(1e-3):0.09939862108050243
step:498 - train/loss:0.6258751749992371 - train/lr(1e-3):0.09939075028387401
step:499 - train/loss:0.6205784678459167 - train/lr(1e-3):0.09938282863110168
step:500 - train/loss:0.7568017840385437 - train/lr(1e-3):0.09937485613034208
step:501 - train/loss:0.6258999705314636 - train/lr(1e-3):0.09936683278980427
step:502 - train/loss:0.6280940771102905 - train/lr(1e-3):0.09935875861774963
step:503 - train/loss:0.832048237323761 - train/lr(1e-3):0.09935063362249191
step:504 - train/loss:0.6249812245368958 - train/lr(1e-3):0.09934245781239713
step:505 - train/loss:0.7431341409683228 - train/lr(1e-3):0.09933423119588372
step:506 - train/loss:0.5881052613258362 - train/lr(1e-3):0.09932595378142234
step:507 - train/loss:0.8216650485992432 - train/lr(1e-3):0.099317625577536
step:508 - train/loss:0.6234878897666931 - train/lr(1e-3):0.0993092465928
step:509 - train/loss:0.9228244423866272 - train/lr(1e-3):0.0993008168358419
step:510 - train/loss:0.6370072364807129 - train/lr(1e-3):0.09929233631534161
step:511 - train/loss:0.7460943460464478 - train/lr(1e-3):0.09928380504003123
step:512 - train/loss:0.6468977928161621 - train/lr(1e-3):0.09927522301869515
step:513 - train/loss:0.5779993534088135 - train/lr(1e-3):0.09926659026017003
step:514 - train/loss:0.7613202333450317 - train/lr(1e-3):0.09925790677334474
step:515 - train/loss:0.7370665669441223 - train/lr(1e-3):0.09924917256716041
step:516 - train/loss:0.6364776492118835 - train/lr(1e-3):0.09924038765061041
step:517 - train/loss:0.8226079344749451 - train/lr(1e-3):0.09923155203274027
step:518 - train/loss:0.5937306880950928 - train/lr(1e-3):0.09922266572264775
step:519 - train/loss:0.7084755897521973 - train/lr(1e-3):0.09921372872948282
step:520 - train/loss:0.6531898975372314 - train/lr(1e-3):0.09920474106244763
step:521 - train/loss:0.6503112316131592 - train/lr(1e-3):0.09919570273079653
step:522 - train/loss:0.5926519632339478 - train/lr(1e-3):0.09918661374383599
step:523 - train/loss:0.7327067852020264 - train/lr(1e-3):0.09917747411092463
step:524 - train/loss:0.739972710609436 - train/lr(1e-3):0.09916828384147332
step:525 - train/loss:0.5561934113502502 - train/lr(1e-3):0.09915904294494494
step:526 - train/loss:0.636558473110199 - train/lr(1e-3):0.09914975143085457
step:527 - train/loss:0.7812444567680359 - train/lr(1e-3):0.09914040930876941
step:528 - train/loss:0.6533622145652771 - train/lr(1e-3):0.09913101658830879
step:529 - train/loss:0.5474337339401245 - train/lr(1e-3):0.09912157327914405
step:530 - train/loss:0.7505905628204346 - train/lr(1e-3):0.0991120793909987
step:531 - train/loss:0.6336061954498291 - train/lr(1e-3):0.09910253493364829
step:532 - train/loss:0.774327278137207 - train/lr(1e-3):0.09909293991692047
step:533 - train/loss:0.6885654926300049 - train/lr(1e-3):0.09908329435069496
step:534 - train/loss:0.6265413165092468 - train/lr(1e-3):0.09907359824490344
step:535 - train/loss:0.611213207244873 - train/lr(1e-3):0.09906385160952977
step:536 - train/loss:0.6998212933540344 - train/lr(1e-3):0.09905405445460971
step:537 - train/loss:0.6521153450012207 - train/lr(1e-3):0.09904420679023113
step:538 - train/loss:0.6288141012191772 - train/lr(1e-3):0.0990343086265338
step:539 - train/loss:0.6476404666900635 - train/lr(1e-3):0.09902435997370962
step:540 - train/loss:0.7685200572013855 - train/lr(1e-3):0.0990143608420024
step:541 - train/loss:0.8372142314910889 - train/lr(1e-3):0.09900431124170792
step:542 - train/loss:0.6690019369125366 - train/lr(1e-3):0.09899421118317399
step:543 - train/loss:0.692686140537262 - train/lr(1e-3):0.09898406067680027
step:544 - train/loss:0.5874755382537842 - train/lr(1e-3):0.09897385973303845
step:545 - train/loss:0.6540213823318481 - train/lr(1e-3):0.09896360836239215
step:546 - train/loss:0.6723078489303589 - train/lr(1e-3):0.09895330657541689
step:547 - train/loss:0.7870590686798096 - train/lr(1e-3):0.09894295438272008
step:548 - train/loss:0.7534517645835876 - train/lr(1e-3):0.09893255179496106
step:549 - train/loss:0.7250561118125916 - train/lr(1e-3):0.09892209882285108
step:550 - train/loss:0.6397073864936829 - train/lr(1e-3):0.09891159547715321
step:551 - train/loss:0.724107563495636 - train/lr(1e-3):0.09890104176868247
step:552 - train/loss:0.5413075685501099 - train/lr(1e-3):0.09889043770830566
step:553 - train/loss:0.596680760383606 - train/lr(1e-3):0.09887978330694146
step:554 - train/loss:0.6823000907897949 - train/lr(1e-3):0.09886907857556038
step:555 - train/loss:0.5538885593414307 - train/lr(1e-3):0.09885832352518473
step:556 - train/loss:0.6970622539520264 - train/lr(1e-3):0.09884751816688872
step:557 - train/loss:0.6425342559814453 - train/lr(1e-3):0.09883666251179826
step:558 - train/loss:0.6790161728858948 - train/lr(1e-3):0.09882575657109106
step:559 - train/loss:0.777188777923584 - train/lr(1e-3):0.09881480035599667
step:560 - train/loss:0.8079261779785156 - train/lr(1e-3):0.09880379387779636
step:561 - train/loss:0.811556339263916 - train/lr(1e-3):0.09879273714782316
step:562 - train/loss:0.7382184267044067 - train/lr(1e-3):0.09878163017746185
step:563 - train/loss:0.6439933180809021 - train/lr(1e-3):0.09877047297814895
step:564 - train/loss:0.6526784896850586 - train/lr(1e-3):0.09875926556137266
step:565 - train/loss:0.6923835277557373 - train/lr(1e-3):0.09874800793867292
step:566 - train/loss:0.7990236282348633 - train/lr(1e-3):0.09873670012164135
step:567 - train/loss:0.654076874256134 - train/lr(1e-3):0.0987253421219213
step:568 - train/loss:0.705895185470581 - train/lr(1e-3):0.09871393395120774
step:569 - train/loss:0.580291211605072 - train/lr(1e-3):0.0987024756212473
step:570 - train/loss:0.5477411150932312 - train/lr(1e-3):0.09869096714383829
step:571 - train/loss:0.6687597632408142 - train/lr(1e-3):0.09867940853083063
step:572 - train/loss:0.6811304688453674 - train/lr(1e-3):0.09866779979412584
step:573 - train/loss:0.7927591800689697 - train/lr(1e-3):0.09865614094567712
step:574 - train/loss:0.5693029165267944 - train/lr(1e-3):0.09864443199748922
step:575 - train/loss:0.7268218994140625 - train/lr(1e-3):0.0986326729616185
step:576 - train/loss:0.5786144137382507 - train/lr(1e-3):0.09862086385017284
step:577 - train/loss:0.6567959785461426 - train/lr(1e-3):0.09860900467531174
step:578 - train/loss:0.5415313243865967 - train/lr(1e-3):0.09859709544924623
step:579 - train/loss:0.6961079239845276 - train/lr(1e-3):0.09858513618423889
step:580 - train/loss:0.6696596145629883 - train/lr(1e-3):0.0985731268926038
step:581 - train/loss:0.6763941049575806 - train/lr(1e-3):0.09856106758670655
step:582 - train/loss:0.6156967282295227 - train/lr(1e-3):0.09854895827896425
step:583 - train/loss:0.939942479133606 - train/lr(1e-3):0.09853679898184546
step:584 - train/loss:0.5674863457679749 - train/lr(1e-3):0.09852458970787026
step:585 - train/loss:0.6839457750320435 - train/lr(1e-3):0.09851233046961018
step:586 - train/loss:0.6944714784622192 - train/lr(1e-3):0.09850002127968814
step:587 - train/loss:0.7088192701339722 - train/lr(1e-3):0.09848766215077857
step:588 - train/loss:0.7045722007751465 - train/lr(1e-3):0.0984752530956073
step:589 - train/loss:0.5841191411018372 - train/lr(1e-3):0.0984627941269515
step:590 - train/loss:0.6303730010986328 - train/lr(1e-3):0.09845028525763982
step:591 - train/loss:0.7306221127510071 - train/lr(1e-3):0.09843772650055227
step:592 - train/loss:0.5930665135383606 - train/lr(1e-3):0.09842511786862018
step:593 - train/loss:0.7829675674438477 - train/lr(1e-3):0.09841245937482633
step:594 - train/loss:0.6458845734596252 - train/lr(1e-3):0.09839975103220475
step:595 - train/loss:0.6932540535926819 - train/lr(1e-3):0.09838699285384082
step:596 - train/loss:0.7303743958473206 - train/lr(1e-3):0.09837418485287126
step:597 - train/loss:0.5955097675323486 - train/lr(1e-3):0.09836132704248408
step:598 - train/loss:0.6587039232254028 - train/lr(1e-3):0.09834841943591859
step:599 - train/loss:0.7477298378944397 - train/lr(1e-3):0.09833546204646532
step:600 - train/loss:0.7233782410621643 - train/lr(1e-3):0.09832245488746612
step:601 - train/loss:0.6814113259315491 - train/lr(1e-3):0.09830939797231406
step:602 - train/loss:0.6277410387992859 - train/lr(1e-3):0.09829629131445342
step:603 - train/loss:0.8198626041412354 - train/lr(1e-3):0.09828313492737976
step:604 - train/loss:0.6954875588417053 - train/lr(1e-3):0.09826992882463982
step:605 - train/loss:0.6412926912307739 - train/lr(1e-3):0.09825667301983147
step:606 - train/loss:0.5364124178886414 - train/lr(1e-3):0.09824336752660386
step:607 - train/loss:0.6403521299362183 - train/lr(1e-3):0.09823001235865722
step:608 - train/loss:0.6829378008842468 - train/lr(1e-3):0.09821660752974293
step:609 - train/loss:0.5559167861938477 - train/lr(1e-3):0.09820315305366359
step:610 - train/loss:0.7115414142608643 - train/lr(1e-3):0.09818964894427282
step:611 - train/loss:0.6607450246810913 - train/lr(1e-3):0.09817609521547543
step:612 - train/loss:0.6869133114814758 - train/lr(1e-3):0.09816249188122723
step:613 - train/loss:0.5843276977539062 - train/lr(1e-3):0.0981488389555352
step:614 - train/loss:0.6674192547798157 - train/lr(1e-3):0.09813513645245729
step:615 - train/loss:0.7220384478569031 - train/lr(1e-3):0.09812138438610261
step:616 - train/loss:0.6626393795013428 - train/lr(1e-3):0.0981075827706312
step:617 - train/loss:0.6230685114860535 - train/lr(1e-3):0.09809373162025416
step:618 - train/loss:0.6469907760620117 - train/lr(1e-3):0.09807983094923362
step:619 - train/loss:0.663388729095459 - train/lr(1e-3):0.09806588077188265
step:620 - train/loss:0.6391580700874329 - train/lr(1e-3):0.09805188110256534
step:621 - train/loss:0.654257595539093 - train/lr(1e-3):0.09803783195569671
step:622 - train/loss:0.7087959051132202 - train/lr(1e-3):0.09802373334574276
step:623 - train/loss:0.7345340251922607 - train/lr(1e-3):0.09800958528722035
step:624 - train/loss:0.665874719619751 - train/lr(1e-3):0.09799538779469734
step:625 - train/loss:0.6237503290176392 - train/lr(1e-3):0.09798114088279244
step:626 - train/loss:0.7854738235473633 - train/lr(1e-3):0.09796684456617526
step:627 - train/loss:0.5792627930641174 - train/lr(1e-3):0.0979524988595663
step:628 - train/loss:0.5824840068817139 - train/lr(1e-3):0.09793810377773686
step:629 - train/loss:0.6795606017112732 - train/lr(1e-3):0.09792365933550916
step:630 - train/loss:0.5924475789070129 - train/lr(1e-3):0.09790916554775614
step:631 - train/loss:0.4867568612098694 - train/lr(1e-3):0.09789462242940167
step:632 - train/loss:0.7242681980133057 - train/lr(1e-3):0.0978800299954203
step:633 - train/loss:0.7142260074615479 - train/lr(1e-3):0.09786538826083746
step:634 - train/loss:0.6800693869590759 - train/lr(1e-3):0.09785069724072926
step:635 - train/loss:0.7016501426696777 - train/lr(1e-3):0.09783595695022262
step:636 - train/loss:0.6706173419952393 - train/lr(1e-3):0.09782116740449516
step:637 - train/loss:0.5083918571472168 - train/lr(1e-3):0.0978063286187752
step:638 - train/loss:0.5978424549102783 - train/lr(1e-3):0.09779144060834181
step:639 - train/loss:0.6581012010574341 - train/lr(1e-3):0.0977765033885247
step:640 - train/loss:0.6646863222122192 - train/lr(1e-3):0.0977615169747043
step:641 - train/loss:0.7144041061401367 - train/lr(1e-3):0.09774648138231162
step:642 - train/loss:0.7360296249389648 - train/lr(1e-3):0.09773139662682839
step:643 - train/loss:0.5487608313560486 - train/lr(1e-3):0.09771626272378689
step:644 - train/loss:0.7318642139434814 - train/lr(1e-3):0.09770107968877004
step:645 - train/loss:0.6455366611480713 - train/lr(1e-3):0.09768584753741134
step:646 - train/loss:0.6298506259918213 - train/lr(1e-3):0.09767056628539492
step:647 - train/loss:0.7541463375091553 - train/lr(1e-3):0.09765523594845535
step:648 - train/loss:0.7293851971626282 - train/lr(1e-3):0.09763985654237786
step:649 - train/loss:0.6582015752792358 - train/lr(1e-3):0.09762442808299812
step:650 - train/loss:0.6350520849227905 - train/lr(1e-3):0.09760895058620235
step:651 - train/loss:0.773482620716095 - train/lr(1e-3):0.09759342406792726
step:652 - train/loss:0.6624094247817993 - train/lr(1e-3):0.09757784854416006
step:653 - train/loss:0.5875952243804932 - train/lr(1e-3):0.09756222403093832
step:654 - train/loss:0.5342369079589844 - train/lr(1e-3):0.0975465505443502
step:655 - train/loss:0.7062860131263733 - train/lr(1e-3):0.09753082810053416
step:656 - train/loss:0.5521289706230164 - train/lr(1e-3):0.09751505671567913
step:657 - train/loss:0.7433585524559021 - train/lr(1e-3):0.09749923640602443
step:658 - train/loss:0.8394837379455566 - train/lr(1e-3):0.09748336718785974
step:659 - train/loss:0.6737716197967529 - train/lr(1e-3):0.0974674490775251
step:660 - train/loss:0.583104133605957 - train/lr(1e-3):0.09745148209141093
step:661 - train/loss:0.6745254993438721 - train/lr(1e-3):0.09743546624595792
step:662 - train/loss:0.5604563355445862 - train/lr(1e-3):0.09741940155765712
step:663 - train/loss:0.6337618827819824 - train/lr(1e-3):0.09740328804304982
step:664 - train/loss:0.7533935904502869 - train/lr(1e-3):0.09738712571872764
step:665 - train/loss:0.7091156840324402 - train/lr(1e-3):0.09737091460133242
step:666 - train/loss:0.6775851845741272 - train/lr(1e-3):0.09735465470755622
step:667 - train/loss:0.6847459673881531 - train/lr(1e-3):0.0973383460541414
step:668 - train/loss:0.627595067024231 - train/lr(1e-3):0.09732198865788047
step:669 - train/loss:0.712133526802063 - train/lr(1e-3):0.09730558253561614
step:670 - train/loss:0.6136574745178223 - train/lr(1e-3):0.09728912770424128
step:671 - train/loss:0.6190211772918701 - train/lr(1e-3):0.09727262418069893
step:672 - train/loss:0.5213801264762878 - train/lr(1e-3):0.09725607198198227
step:673 - train/loss:0.6668096780776978 - train/lr(1e-3):0.09723947112513459
step:674 - train/loss:0.7534184455871582 - train/lr(1e-3):0.09722282162724927
step:675 - train/loss:0.7852627635002136 - train/lr(1e-3):0.09720612350546982
step:676 - train/loss:0.6777971982955933 - train/lr(1e-3):0.09718937677698976
step:677 - train/loss:0.7094232439994812 - train/lr(1e-3):0.09717258145905269
step:678 - train/loss:0.6200898885726929 - train/lr(1e-3):0.09715573756895224
step:679 - train/loss:0.6954988241195679 - train/lr(1e-3):0.09713884512403204
step:680 - train/loss:0.5471312999725342 - train/lr(1e-3):0.09712190414168573
step:681 - train/loss:0.6147164702415466 - train/lr(1e-3):0.09710491463935692
step:682 - train/loss:0.7006162405014038 - train/lr(1e-3):0.09708787663453917
step:683 - train/loss:0.7753186225891113 - train/lr(1e-3):0.097070790144776
step:684 - train/loss:0.6241940855979919 - train/lr(1e-3):0.09705365518766085
step:685 - train/loss:0.6368627548217773 - train/lr(1e-3):0.09703647178083705
step:686 - train/loss:0.7076902389526367 - train/lr(1e-3):0.09701923994199785
step:687 - train/loss:0.5929663181304932 - train/lr(1e-3):0.09700195968888632
step:688 - train/loss:0.7868587374687195 - train/lr(1e-3):0.09698463103929542
step:689 - train/loss:0.6253544688224792 - train/lr(1e-3):0.09696725401106794
step:690 - train/loss:0.5908660292625427 - train/lr(1e-3):0.09694982862209645
step:691 - train/loss:0.6608537435531616 - train/lr(1e-3):0.09693235489032337
step:692 - train/loss:0.6165006756782532 - train/lr(1e-3):0.09691483283374085
step:693 - train/loss:0.7025383114814758 - train/lr(1e-3):0.09689726247039081
step:694 - train/loss:0.5673348903656006 - train/lr(1e-3):0.09687964381836492
step:695 - train/loss:0.7126188278198242 - train/lr(1e-3):0.09686197689580456
step:696 - train/loss:0.6539419889450073 - train/lr(1e-3):0.09684426172090085
step:697 - train/loss:0.6393743753433228 - train/lr(1e-3):0.09682649831189452
step:698 - train/loss:0.734430193901062 - train/lr(1e-3):0.09680868668707603
step:699 - train/loss:0.7702394723892212 - train/lr(1e-3):0.09679082686478549
step:700 - train/loss:0.6701579093933105 - train/lr(1e-3):0.09677291886341256
step:701 - train/loss:0.7120066285133362 - train/lr(1e-3):0.09675496270139661
step:702 - train/loss:0.7983516454696655 - train/lr(1e-3):0.0967369583972265
step:703 - train/loss:0.7046040296554565 - train/lr(1e-3):0.09671890596944076
step:704 - train/loss:0.7209428548812866 - train/lr(1e-3):0.0967008054366274
step:705 - train/loss:0.6405309438705444 - train/lr(1e-3):0.09668265681742398
step:706 - train/loss:0.6154901385307312 - train/lr(1e-3):0.0966644601305176
step:707 - train/loss:0.6080378293991089 - train/lr(1e-3):0.0966462153946448
step:708 - train/loss:0.6144481897354126 - train/lr(1e-3):0.09662792262859166
step:709 - train/loss:0.6706193089485168 - train/lr(1e-3):0.09660958185119364
step:710 - train/loss:0.771032989025116 - train/lr(1e-3):0.09659119308133571
step:711 - train/loss:0.5346183776855469 - train/lr(1e-3):0.09657275633795223
step:712 - train/loss:0.6733496189117432 - train/lr(1e-3):0.0965542716400269
step:713 - train/loss:0.6443562507629395 - train/lr(1e-3):0.09653573900659293
step:714 - train/loss:0.6603400707244873 - train/lr(1e-3):0.09651715845673271
step:715 - train/loss:0.5923276543617249 - train/lr(1e-3):0.09649853000957813
step:716 - train/loss:0.7652950882911682 - train/lr(1e-3):0.09647985368431032
step:717 - train/loss:0.571617066860199 - train/lr(1e-3):0.09646112950015971
step:718 - train/loss:0.6544187068939209 - train/lr(1e-3):0.09644235747640602
step:719 - train/loss:0.744513750076294 - train/lr(1e-3):0.09642353763237824
step:720 - train/loss:0.5614680051803589 - train/lr(1e-3):0.09640466998745456
step:721 - train/loss:0.7972082495689392 - train/lr(1e-3):0.09638575456106244
step:722 - train/loss:0.7101794481277466 - train/lr(1e-3):0.09636679137267852
step:723 - train/loss:0.70074862241745 - train/lr(1e-3):0.0963477804418286
step:724 - train/loss:0.649024248123169 - train/lr(1e-3):0.09632872178808766
step:725 - train/loss:0.565822958946228 - train/lr(1e-3):0.09630961543107981
step:726 - train/loss:0.5019350647926331 - train/lr(1e-3):0.09629046139047828
step:727 - train/loss:0.6159630417823792 - train/lr(1e-3):0.09627125968600542
step:728 - train/loss:0.7801087498664856 - train/lr(1e-3):0.09625201033743261
step:729 - train/loss:0.572027862071991 - train/lr(1e-3):0.09623271336458032
step:730 - train/loss:0.6823732256889343 - train/lr(1e-3):0.09621336878731807
step:731 - train/loss:0.6860539317131042 - train/lr(1e-3):0.09619397662556435
step:732 - train/loss:0.7483227252960205 - train/lr(1e-3):0.09617453689928669
step:733 - train/loss:0.6981525421142578 - train/lr(1e-3):0.09615504962850159
step:734 - train/loss:0.45445483922958374 - train/lr(1e-3):0.09613551483327448
step:735 - train/loss:0.6932544112205505 - train/lr(1e-3):0.09611593253371976
step:736 - train/loss:0.70893394947052 - train/lr(1e-3):0.09609630275000072
step:737 - train/loss:0.678168535232544 - train/lr(1e-3):0.09607662550232954
step:738 - train/loss:0.7039185762405396 - train/lr(1e-3):0.09605690081096725
step:739 - train/loss:0.613633394241333 - train/lr(1e-3):0.09603712869622383
step:740 - train/loss:0.5945780277252197 - train/lr(1e-3):0.09601730917845797
step:741 - train/loss:0.7516719102859497 - train/lr(1e-3):0.09599744227807724
step:742 - train/loss:0.6355528235435486 - train/lr(1e-3):0.09597752801553798
step:743 - train/loss:0.6351783871650696 - train/lr(1e-3):0.09595756641134529
step:744 - train/loss:0.7051318883895874 - train/lr(1e-3):0.095937557486053
step:745 - train/loss:0.6865664124488831 - train/lr(1e-3):0.09591750126026373
step:746 - train/loss:0.588408887386322 - train/lr(1e-3):0.09589739775462873
step:747 - train/loss:0.7331829071044922 - train/lr(1e-3):0.095877246989848
step:748 - train/loss:0.6671813726425171 - train/lr(1e-3):0.09585704898667013
step:749 - train/loss:0.5490720272064209 - train/lr(1e-3):0.0958368037658924
step:750 - train/loss:0.6626229286193848 - train/lr(1e-3):0.09581651134836068
step:751 - train/loss:0.6417645812034607 - train/lr(1e-3):0.0957961717549695
step:752 - train/loss:0.5389918088912964 - train/lr(1e-3):0.09577578500666187
step:753 - train/loss:0.7784914970397949 - train/lr(1e-3):0.0957553511244294
step:754 - train/loss:0.6752814650535583 - train/lr(1e-3):0.09573487012931224
step:755 - train/loss:0.5423996448516846 - train/lr(1e-3):0.09571434204239906
step:756 - train/loss:0.7243510484695435 - train/lr(1e-3):0.09569376688482702
step:757 - train/loss:0.5363500118255615 - train/lr(1e-3):0.09567314467778165
step:758 - train/loss:0.7530627250671387 - train/lr(1e-3):0.0956524754424971
step:759 - train/loss:0.5322393178939819 - train/lr(1e-3):0.09563175920025578
step:760 - train/loss:0.6122554540634155 - train/lr(1e-3):0.0956109959723886
step:761 - train/loss:0.6364077925682068 - train/lr(1e-3):0.09559018578027483
step:762 - train/loss:0.7118833065032959 - train/lr(1e-3):0.09556932864534207
step:763 - train/loss:0.6366313695907593 - train/lr(1e-3):0.09554842458906627
step:764 - train/loss:0.6740038394927979 - train/lr(1e-3):0.09552747363297172
step:765 - train/loss:0.5835016369819641 - train/lr(1e-3):0.09550647579863096
step:766 - train/loss:0.8189888000488281 - train/lr(1e-3):0.09548543110766482
step:767 - train/loss:0.6498318910598755 - train/lr(1e-3):0.09546433958174239
step:768 - train/loss:0.7091214656829834 - train/lr(1e-3):0.09544320124258092
step:769 - train/loss:0.660078763961792 - train/lr(1e-3):0.09542201611194598
step:770 - train/loss:0.5932815074920654 - train/lr(1e-3):0.09540078421165121
step:771 - train/loss:0.6937101483345032 - train/lr(1e-3):0.09537950556355844
step:772 - train/loss:0.6960617303848267 - train/lr(1e-3):0.09535818018957767
step:773 - train/loss:0.715919017791748 - train/lr(1e-3):0.09533680811166696
step:774 - train/loss:0.7116113901138306 - train/lr(1e-3):0.09531538935183251
step:775 - train/loss:0.6036888957023621 - train/lr(1e-3):0.09529392393212853
step:776 - train/loss:0.609377384185791 - train/lr(1e-3):0.09527241187465733
step:777 - train/loss:0.739691972732544 - train/lr(1e-3):0.0952508532015692
step:778 - train/loss:0.636904776096344 - train/lr(1e-3):0.09522924793506249
step:779 - train/loss:0.6436254382133484 - train/lr(1e-3):0.09520759609738344
step:780 - train/loss:0.7228618860244751 - train/lr(1e-3):0.09518589771082626
step:781 - train/loss:0.7173054218292236 - train/lr(1e-3):0.09516415279773317
step:782 - train/loss:0.6349309682846069 - train/lr(1e-3):0.09514236138049421
step:783 - train/loss:0.7012524008750916 - train/lr(1e-3):0.09512052348154736
step:784 - train/loss:0.5163718461990356 - train/lr(1e-3):0.09509863912337842
step:785 - train/loss:0.6539686322212219 - train/lr(1e-3):0.09507670832852103
step:786 - train/loss:0.6349813938140869 - train/lr(1e-3):0.09505473111955667
step:787 - train/loss:0.5600008964538574 - train/lr(1e-3):0.09503270751911462
step:788 - train/loss:0.527229905128479 - train/lr(1e-3):0.09501063754987188
step:789 - train/loss:0.5974104404449463 - train/lr(1e-3):0.09498852123455322
step:790 - train/loss:0.7239136695861816 - train/lr(1e-3):0.09496635859593117
step:791 - train/loss:0.5724207162857056 - train/lr(1e-3):0.09494414965682586
step:792 - train/loss:0.8426385521888733 - train/lr(1e-3):0.09492189444010521
step:793 - train/loss:0.6180611848831177 - train/lr(1e-3):0.09489959296868472
step:794 - train/loss:0.6929261684417725 - train/lr(1e-3):0.09487724526552753
step:795 - train/loss:0.6713379621505737 - train/lr(1e-3):0.09485485135364435
step:796 - train/loss:0.7000517845153809 - train/lr(1e-3):0.09483241125609358
step:797 - train/loss:0.7344751358032227 - train/lr(1e-3):0.09480992499598105
step:798 - train/loss:0.5549077987670898 - train/lr(1e-3):0.09478739259646017
step:799 - train/loss:0.6147582530975342 - train/lr(1e-3):0.0947648140807319
step:800 - train/loss:0.6984647512435913 - train/lr(1e-3):0.09474218947204459
step:801 - train/loss:0.8037355542182922 - train/lr(1e-3):0.09471951879369415
step:802 - train/loss:0.5118662714958191 - train/lr(1e-3):0.0946968020690239
step:803 - train/loss:0.5951778888702393 - train/lr(1e-3):0.09467403932142451
step:804 - train/loss:0.7498178482055664 - train/lr(1e-3):0.09465123057433412
step:805 - train/loss:0.6157141923904419 - train/lr(1e-3):0.09462837585123818
step:806 - train/loss:0.6381621956825256 - train/lr(1e-3):0.09460547517566949
step:807 - train/loss:0.6549865007400513 - train/lr(1e-3):0.09458252857120819
step:808 - train/loss:0.7176334857940674 - train/lr(1e-3):0.09455953606148172
step:809 - train/loss:0.693773627281189 - train/lr(1e-3):0.0945364976701647
step:810 - train/loss:0.7082052230834961 - train/lr(1e-3):0.09451341342097912
step:811 - train/loss:0.6697967052459717 - train/lr(1e-3):0.09449028333769408
step:812 - train/loss:0.6246139407157898 - train/lr(1e-3):0.09446710744412594
step:813 - train/loss:0.7664223313331604 - train/lr(1e-3):0.09444388576413823
step:814 - train/loss:0.7869547009468079 - train/lr(1e-3):0.09442061832164154
step:815 - train/loss:0.6570906639099121 - train/lr(1e-3):0.09439730514059372
step:816 - train/loss:0.772247314453125 - train/lr(1e-3):0.09437394624499958
step:817 - train/loss:0.5802148580551147 - train/lr(1e-3):0.09435054165891109
step:818 - train/loss:0.7743819355964661 - train/lr(1e-3):0.09432709140642723
step:819 - train/loss:0.49172747135162354 - train/lr(1e-3):0.09430359551169398
step:820 - train/loss:0.620209276676178 - train/lr(1e-3):0.0942800539989044
step:821 - train/loss:0.6280938982963562 - train/lr(1e-3):0.09425646689229843
step:822 - train/loss:0.7000219821929932 - train/lr(1e-3):0.09423283421616298
step:823 - train/loss:0.5371730327606201 - train/lr(1e-3):0.09420915599483191
step:824 - train/loss:0.5040490627288818 - train/lr(1e-3):0.09418543225268597
step:825 - train/loss:0.6596660017967224 - train/lr(1e-3):0.09416166301415274
step:826 - train/loss:0.6424487233161926 - train/lr(1e-3):0.09413784830370671
step:827 - train/loss:0.5464332103729248 - train/lr(1e-3):0.09411398814586916
step:828 - train/loss:0.4853563904762268 - train/lr(1e-3):0.09409008256520814
step:829 - train/loss:0.5881845951080322 - train/lr(1e-3):0.09406613158633848
step:830 - train/loss:0.6640372276306152 - train/lr(1e-3):0.09404213523392183
step:831 - train/loss:0.6849584579467773 - train/lr(1e-3):0.09401809353266644
step:832 - train/loss:0.6843430995941162 - train/lr(1e-3):0.09399400650732735
step:833 - train/loss:0.7806353569030762 - train/lr(1e-3):0.09396987418270622
step:834 - train/loss:0.5666631460189819 - train/lr(1e-3):0.09394569658365136
step:835 - train/loss:0.7154934406280518 - train/lr(1e-3):0.0939214737350577
step:836 - train/loss:0.49379611015319824 - train/lr(1e-3):0.09389720566186681
step:837 - train/loss:0.6123735308647156 - train/lr(1e-3):0.09387289238906674
step:838 - train/loss:0.6112664341926575 - train/lr(1e-3):0.0938485339416921
step:839 - train/loss:0.6618636846542358 - train/lr(1e-3):0.0938241303448241
step:840 - train/loss:0.4791182279586792 - train/lr(1e-3):0.09379968162359034
step:841 - train/loss:0.6968206167221069 - train/lr(1e-3):0.09377518780316492
step:842 - train/loss:0.773347020149231 - train/lr(1e-3):0.0937506489087684
step:843 - train/loss:0.7605711221694946 - train/lr(1e-3):0.0937260649656677
step:844 - train/loss:0.6217732429504395 - train/lr(1e-3):0.09370143599917614
step:845 - train/loss:0.5246378779411316 - train/lr(1e-3):0.0936767620346535
step:846 - train/loss:0.5755649209022522 - train/lr(1e-3):0.0936520430975057
step:847 - train/loss:0.610270619392395 - train/lr(1e-3):0.09362727921318513
step:848 - train/loss:0.5862125754356384 - train/lr(1e-3):0.09360247040719039
step:849 - train/loss:0.8659074306488037 - train/lr(1e-3):0.09357761670506635
step:850 - train/loss:0.713957667350769 - train/lr(1e-3):0.0935527181324041
step:851 - train/loss:0.7631648182868958 - train/lr(1e-3):0.09352777471484096
step:852 - train/loss:0.7436798810958862 - train/lr(1e-3):0.09350278647806037
step:853 - train/loss:0.6981631517410278 - train/lr(1e-3):0.093477753447792
step:854 - train/loss:0.5943024158477783 - train/lr(1e-3):0.09345267564981152
step:855 - train/loss:0.646418035030365 - train/lr(1e-3):0.09342755310994086
step:856 - train/loss:0.715481698513031 - train/lr(1e-3):0.09340238585404788
step:857 - train/loss:0.5852733254432678 - train/lr(1e-3):0.09337717390804652
step:858 - train/loss:0.675389289855957 - train/lr(1e-3):0.09335191729789678
step:859 - train/loss:0.7223360538482666 - train/lr(1e-3):0.09332661604960461
step:860 - train/loss:0.6438873410224915 - train/lr(1e-3):0.09330127018922194
Saving checkpoint to: /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_860
[2025-08-23 19:17:23,676][/home/Competition2025/P07/shareP07/share_env/deps/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved model to /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_860/model_world_size_24_rank_0.pt
[2025-08-23 19:17:30,163][/home/Competition2025/P07/shareP07/share_env/deps/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved optim to /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_860/optim_world_size_24_rank_0.pt
[2025-08-23 19:17:30,167][/home/Competition2025/P07/shareP07/share_env/deps/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved extra_state to /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_860/extra_state_world_size_24_rank_0.pt
[2025-08-23 19:17:30,582][/home/Competition2025/P07/shareP07/share_env/deps/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved model config and tokenizer class to /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_860/huggingface
[2025-08-23 19:19:23,727][/home/Competition2025/P07/shareP07/share_env/deps/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved hf_model to /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_860/huggingface
Saved dataloader state to: /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_860/data.pt
Updated checkpoint tracker: /home/Competition2025/P07/shareP07/share_model/step3_sft/latest_checkpointed_iteration.txt
step:861 - train/loss:0.7174177169799805 - train/lr(1e-3):0.09327587974284661
step:862 - train/loss:0.6054880023002625 - train/lr(1e-3):0.09325044473662239
step:863 - train/loss:0.7686585187911987 - train/lr(1e-3):0.09322496519673892
step:864 - train/loss:0.6358054876327515 - train/lr(1e-3):0.09319944114943171
step:865 - train/loss:0.5767531394958496 - train/lr(1e-3):0.09317387262098212
step:866 - train/loss:0.7599651217460632 - train/lr(1e-3):0.09314825963771724
step:867 - train/loss:0.7656457424163818 - train/lr(1e-3):0.09312260222600997
step:868 - train/loss:0.5854421854019165 - train/lr(1e-3):0.09309690041227899
step:869 - train/loss:0.5604745745658875 - train/lr(1e-3):0.09307115422298867
step:870 - train/loss:0.6194372773170471 - train/lr(1e-3):0.09304536368464905
step:871 - train/loss:0.81264728307724 - train/lr(1e-3):0.09301952882381588
step:872 - train/loss:0.6179099082946777 - train/lr(1e-3):0.0929936496670905
step:873 - train/loss:0.49569225311279297 - train/lr(1e-3):0.09296772624111993
step:874 - train/loss:0.7194223403930664 - train/lr(1e-3):0.09294175857259668
step:875 - train/loss:0.7085583806037903 - train/lr(1e-3):0.0929157466882589
step:876 - train/loss:0.6222041249275208 - train/lr(1e-3):0.0928896906148902
step:877 - train/loss:0.6730747818946838 - train/lr(1e-3):0.09286359037931975
step:878 - train/loss:0.5330909490585327 - train/lr(1e-3):0.09283744600842216
step:879 - train/loss:0.6984739303588867 - train/lr(1e-3):0.09281125752911747
step:880 - train/loss:0.6456760168075562 - train/lr(1e-3):0.09278502496837115
step:881 - train/loss:0.8064504265785217 - train/lr(1e-3):0.09275874835319409
step:882 - train/loss:0.6637314558029175 - train/lr(1e-3):0.09273242771064252
step:883 - train/loss:0.5755388140678406 - train/lr(1e-3):0.09270606306781796
step:884 - train/loss:0.721929669380188 - train/lr(1e-3):0.09267965445186734
step:885 - train/loss:0.603817880153656 - train/lr(1e-3):0.09265320188998273
step:886 - train/loss:0.6657720804214478 - train/lr(1e-3):0.09262670540940157
step:887 - train/loss:0.7854145169258118 - train/lr(1e-3):0.09260016503740646
step:888 - train/loss:0.6895164847373962 - train/lr(1e-3):0.09257358080132523
step:889 - train/loss:0.5534230470657349 - train/lr(1e-3):0.09254695272853082
step:890 - train/loss:0.6896032094955444 - train/lr(1e-3):0.09252028084644137
step:891 - train/loss:0.6248077154159546 - train/lr(1e-3):0.0924935651825201
step:892 - train/loss:0.7151422500610352 - train/lr(1e-3):0.0924668057642753
step:893 - train/loss:0.6461552977561951 - train/lr(1e-3):0.09244000261926029
step:894 - train/loss:0.6728380918502808 - train/lr(1e-3):0.09241315577507353
step:895 - train/loss:0.6520820260047913 - train/lr(1e-3):0.09238626525935831
step:896 - train/loss:0.7356278896331787 - train/lr(1e-3):0.09235933109980302
step:897 - train/loss:0.5660286545753479 - train/lr(1e-3):0.09233235332414093
step:898 - train/loss:0.6447868943214417 - train/lr(1e-3):0.09230533196015024
step:899 - train/loss:0.8266183137893677 - train/lr(1e-3):0.09227826703565399
step:900 - train/loss:0.47081422805786133 - train/lr(1e-3):0.09225115857852015
step:901 - train/loss:0.5791399478912354 - train/lr(1e-3):0.09222400661666139
step:902 - train/loss:0.6704541444778442 - train/lr(1e-3):0.09219681117803535
step:903 - train/loss:0.7153997421264648 - train/lr(1e-3):0.09216957229064429
step:904 - train/loss:0.604703426361084 - train/lr(1e-3):0.09214228998253528
step:905 - train/loss:0.5453149080276489 - train/lr(1e-3):0.09211496428180004
step:906 - train/loss:0.6548187136650085 - train/lr(1e-3):0.09208759521657503
step:907 - train/loss:0.7899372577667236 - train/lr(1e-3):0.09206018281504134
step:908 - train/loss:0.6870123147964478 - train/lr(1e-3):0.0920327271054247
step:909 - train/loss:0.5749881267547607 - train/lr(1e-3):0.09200522811599539
step:910 - train/loss:0.7849022150039673 - train/lr(1e-3):0.09197768587506829
step:911 - train/loss:0.5873099565505981 - train/lr(1e-3):0.09195010041100275
step:912 - train/loss:0.7162933945655823 - train/lr(1e-3):0.09192247175220276
step:913 - train/loss:0.6271519660949707 - train/lr(1e-3):0.09189479992711667
step:914 - train/loss:0.6980676651000977 - train/lr(1e-3):0.0918670849642373
step:915 - train/loss:0.6115494966506958 - train/lr(1e-3):0.09183932689210193
step:916 - train/loss:0.711499810218811 - train/lr(1e-3):0.09181152573929216
step:917 - train/loss:0.6756141781806946 - train/lr(1e-3):0.09178368153443399
step:918 - train/loss:0.7157982587814331 - train/lr(1e-3):0.09175579430619776
step:919 - train/loss:0.5397931337356567 - train/lr(1e-3):0.0917278640832981
step:920 - train/loss:0.6544075012207031 - train/lr(1e-3):0.0916998908944939
step:921 - train/loss:0.7532276511192322 - train/lr(1e-3):0.09167187476858829
step:922 - train/loss:0.6968300342559814 - train/lr(1e-3):0.09164381573442863
step:923 - train/loss:0.6066014766693115 - train/lr(1e-3):0.09161571382090643
step:924 - train/loss:0.6996456384658813 - train/lr(1e-3):0.09158756905695739
step:925 - train/loss:0.5610926151275635 - train/lr(1e-3):0.0915593814715613
step:926 - train/loss:0.6045244336128235 - train/lr(1e-3):0.09153115109374206
step:927 - train/loss:0.7815371751785278 - train/lr(1e-3):0.09150287795256763
step:928 - train/loss:0.6195057034492493 - train/lr(1e-3):0.09147456207714998
step:929 - train/loss:0.5706757307052612 - train/lr(1e-3):0.0914462034966451
step:930 - train/loss:0.8187752962112427 - train/lr(1e-3):0.09141780224025299
step:931 - train/loss:0.627183735370636 - train/lr(1e-3):0.09138935833721751
step:932 - train/loss:0.7295182943344116 - train/lr(1e-3):0.0913608718168265
step:933 - train/loss:0.6095672249794006 - train/lr(1e-3):0.09133234270841166
step:934 - train/loss:0.7178975939750671 - train/lr(1e-3):0.09130377104134851
step:935 - train/loss:0.72625732421875 - train/lr(1e-3):0.09127515684505647
step:936 - train/loss:0.7079169750213623 - train/lr(1e-3):0.09124650014899867
step:937 - train/loss:0.7279842495918274 - train/lr(1e-3):0.09121780098268202
step:938 - train/loss:0.6053266525268555 - train/lr(1e-3):0.09118905937565722
step:939 - train/loss:0.6282786130905151 - train/lr(1e-3):0.0911602753575186
step:940 - train/loss:0.6567636132240295 - train/lr(1e-3):0.09113144895790416
step:941 - train/loss:0.6255308389663696 - train/lr(1e-3):0.09110258020649559
step:942 - train/loss:0.607372522354126 - train/lr(1e-3):0.09107366913301812
step:943 - train/loss:0.7607181072235107 - train/lr(1e-3):0.09104471576724064
step:944 - train/loss:0.6589142680168152 - train/lr(1e-3):0.09101572013897555
step:945 - train/loss:0.6375533938407898 - train/lr(1e-3):0.09098668227807873
step:946 - train/loss:0.7047193050384521 - train/lr(1e-3):0.09095760221444961
step:947 - train/loss:0.6190246343612671 - train/lr(1e-3):0.09092847997803097
step:948 - train/loss:0.6792099475860596 - train/lr(1e-3):0.09089931559880916
step:949 - train/loss:0.591498851776123 - train/lr(1e-3):0.09087010910681387
step:950 - train/loss:0.6903436183929443 - train/lr(1e-3):0.09084086053211804
step:951 - train/loss:0.4963068962097168 - train/lr(1e-3):0.09081156990483807
step:952 - train/loss:0.6562912464141846 - train/lr(1e-3):0.09078223725513365
step:953 - train/loss:0.6699705123901367 - train/lr(1e-3):0.09075286261320768
step:954 - train/loss:0.6424006223678589 - train/lr(1e-3):0.09072344600930636
step:955 - train/loss:0.5754996538162231 - train/lr(1e-3):0.09069398747371904
step:956 - train/loss:0.6384932994842529 - train/lr(1e-3):0.09066448703677828
step:957 - train/loss:0.5839482545852661 - train/lr(1e-3):0.09063494472885977
step:958 - train/loss:0.8509585857391357 - train/lr(1e-3):0.09060536058038235
step:959 - train/loss:0.7482327222824097 - train/lr(1e-3):0.09057573462180786
step:960 - train/loss:0.6836115121841431 - train/lr(1e-3):0.0905460668836413
step:961 - train/loss:0.6292895674705505 - train/lr(1e-3):0.09051635739643057
step:962 - train/loss:0.658339262008667 - train/lr(1e-3):0.09048660619076669
step:963 - train/loss:0.5814722180366516 - train/lr(1e-3):0.09045681329728351
step:964 - train/loss:0.695336103439331 - train/lr(1e-3):0.09042697874665791
step:965 - train/loss:0.7003235816955566 - train/lr(1e-3):0.09039710256960956
step:966 - train/loss:0.6869356036186218 - train/lr(1e-3):0.09036718479690108
step:967 - train/loss:0.7348005175590515 - train/lr(1e-3):0.09033722545933787
step:968 - train/loss:0.6593108773231506 - train/lr(1e-3):0.09030722458776815
step:969 - train/loss:0.7609184384346008 - train/lr(1e-3):0.0902771822130829
step:970 - train/loss:0.5675768256187439 - train/lr(1e-3):0.09024709836621582
step:971 - train/loss:0.624531090259552 - train/lr(1e-3):0.09021697307814333
step:972 - train/loss:0.6288983821868896 - train/lr(1e-3):0.09018680637988456
step:973 - train/loss:0.6238314509391785 - train/lr(1e-3):0.09015659830250118
step:974 - train/loss:0.6136313080787659 - train/lr(1e-3):0.09012634887709754
step:975 - train/loss:0.5493947267532349 - train/lr(1e-3):0.09009605813482056
step:976 - train/loss:0.6907616257667542 - train/lr(1e-3):0.09006572610685969
step:977 - train/loss:0.602211594581604 - train/lr(1e-3):0.09003535282444687
step:978 - train/loss:0.6845769882202148 - train/lr(1e-3):0.09000493831885653
step:979 - train/loss:0.6599238514900208 - train/lr(1e-3):0.0899744826214056
step:980 - train/loss:0.40397781133651733 - train/lr(1e-3):0.08994398576345336
step:981 - train/loss:0.6246010065078735 - train/lr(1e-3):0.08991344777640148
step:982 - train/loss:0.6535639762878418 - train/lr(1e-3):0.089882868691694
step:983 - train/loss:0.6096392869949341 - train/lr(1e-3):0.08985224854081726
step:984 - train/loss:0.5918416976928711 - train/lr(1e-3):0.0898215873552999
step:985 - train/loss:0.6104286909103394 - train/lr(1e-3):0.08979088516671282
step:986 - train/loss:0.530483603477478 - train/lr(1e-3):0.08976014200666908
step:987 - train/loss:0.636918306350708 - train/lr(1e-3):0.08972935790682401
step:988 - train/loss:0.5907668471336365 - train/lr(1e-3):0.08969853289887506
step:989 - train/loss:0.7329868078231812 - train/lr(1e-3):0.08966766701456177
step:990 - train/loss:0.7319891452789307 - train/lr(1e-3):0.08963676028566578
step:991 - train/loss:0.5577337741851807 - train/lr(1e-3):0.08960581274401086
step:992 - train/loss:0.6399767994880676 - train/lr(1e-3):0.08957482442146272
step:993 - train/loss:0.5442240238189697 - train/lr(1e-3):0.08954379534992905
step:994 - train/loss:0.6798115968704224 - train/lr(1e-3):0.08951272556135959
step:995 - train/loss:0.6312505006790161 - train/lr(1e-3):0.08948161508774594
step:996 - train/loss:0.5022007822990417 - train/lr(1e-3):0.08945046396112158
step:997 - train/loss:0.6565555334091187 - train/lr(1e-3):0.08941927221356188
step:998 - train/loss:0.5285974144935608 - train/lr(1e-3):0.08938803987718402
step:999 - train/loss:0.6056857109069824 - train/lr(1e-3):0.08935676698414702
step:1000 - train/loss:0.6327410936355591 - train/lr(1e-3):0.08932545356665157
step:1001 - train/loss:0.5965138673782349 - train/lr(1e-3):0.08929409965694016
step:1002 - train/loss:0.6100978851318359 - train/lr(1e-3):0.08926270528729696
step:1003 - train/loss:0.5196300745010376 - train/lr(1e-3):0.08923127049004778
step:1004 - train/loss:0.6674797534942627 - train/lr(1e-3):0.08919979529756007
step:1005 - train/loss:0.4561801850795746 - train/lr(1e-3):0.0891682797422429
step:1006 - train/loss:0.5218038558959961 - train/lr(1e-3):0.08913672385654682
step:1007 - train/loss:0.7070046663284302 - train/lr(1e-3):0.08910512767296398
step:1008 - train/loss:0.5559626221656799 - train/lr(1e-3):0.08907349122402801
step:1009 - train/loss:0.6785593032836914 - train/lr(1e-3):0.089041814542314
step:1010 - train/loss:0.5729418396949768 - train/lr(1e-3):0.08901009766043846
step:1011 - train/loss:0.7256778478622437 - train/lr(1e-3):0.08897834061105929
step:1012 - train/loss:0.6145366430282593 - train/lr(1e-3):0.08894654342687573
step:1013 - train/loss:0.6509310007095337 - train/lr(1e-3):0.08891470614062841
step:1014 - train/loss:0.589813768863678 - train/lr(1e-3):0.08888282878509915
step:1015 - train/loss:0.6948839426040649 - train/lr(1e-3):0.08885091139311115
step:1016 - train/loss:0.6570003628730774 - train/lr(1e-3):0.08881895399752873
step:1017 - train/loss:0.7883206009864807 - train/lr(1e-3):0.08878695663125745
step:1018 - train/loss:0.6225935816764832 - train/lr(1e-3):0.08875491932724403
step:1019 - train/loss:0.5857959985733032 - train/lr(1e-3):0.0887228421184763
step:1020 - train/loss:0.6931006908416748 - train/lr(1e-3):0.08869072503798316
step:1021 - train/loss:0.47622138261795044 - train/lr(1e-3):0.0886585681188346
step:1022 - train/loss:0.6440914869308472 - train/lr(1e-3):0.08862637139414163
step:1023 - train/loss:0.6917376518249512 - train/lr(1e-3):0.08859413489705621
step:1024 - train/loss:0.6046051979064941 - train/lr(1e-3):0.08856185866077129
step:1025 - train/loss:0.529263973236084 - train/lr(1e-3):0.08852954271852069
step:1026 - train/loss:0.6934177875518799 - train/lr(1e-3):0.0884971871035792
step:1027 - train/loss:0.6555948257446289 - train/lr(1e-3):0.08846479184926237
step:1028 - train/loss:0.7044071555137634 - train/lr(1e-3):0.0884323569889266
step:1029 - train/loss:0.6038730144500732 - train/lr(1e-3):0.08839988255596909
step:1030 - train/loss:0.6069178581237793 - train/lr(1e-3):0.08836736858382777
step:1031 - train/loss:0.7524421215057373 - train/lr(1e-3):0.08833481510598128
step:1032 - train/loss:0.696022093296051 - train/lr(1e-3):0.0883022221559489
step:1033 - train/loss:0.6813356876373291 - train/lr(1e-3):0.08826958976729064
step:1034 - train/loss:0.6478187441825867 - train/lr(1e-3):0.08823691797360708
step:1035 - train/loss:0.6670246124267578 - train/lr(1e-3):0.08820420680853934
step:1036 - train/loss:0.6139810681343079 - train/lr(1e-3):0.0881714563057691
step:1037 - train/loss:0.5450049638748169 - train/lr(1e-3):0.08813866649901857
step:1038 - train/loss:0.6235408782958984 - train/lr(1e-3):0.08810583742205039
step:1039 - train/loss:0.43056637048721313 - train/lr(1e-3):0.08807296910866767
step:1040 - train/loss:0.6675577759742737 - train/lr(1e-3):0.0880400615927139
step:1041 - train/loss:0.654991865158081 - train/lr(1e-3):0.08800711490807296
step:1042 - train/loss:0.6538889408111572 - train/lr(1e-3):0.08797412908866901
step:1043 - train/loss:0.632813572883606 - train/lr(1e-3):0.08794110416846657
step:1044 - train/loss:0.6548988223075867 - train/lr(1e-3):0.08790804018147039
step:1045 - train/loss:0.5417889356613159 - train/lr(1e-3):0.08787493716172541
step:1046 - train/loss:0.7028173208236694 - train/lr(1e-3):0.08784179514331682
step:1047 - train/loss:0.5868125557899475 - train/lr(1e-3):0.08780861416036993
step:1048 - train/loss:0.6255603432655334 - train/lr(1e-3):0.08777539424705023
step:1049 - train/loss:0.6142248511314392 - train/lr(1e-3):0.08774213543756318
step:1050 - train/loss:0.7496110200881958 - train/lr(1e-3):0.0877088377661544
step:1051 - train/loss:0.7832049131393433 - train/lr(1e-3):0.08767550126710949
step:1052 - train/loss:0.605262279510498 - train/lr(1e-3):0.08764212597475397
step:1053 - train/loss:0.657400906085968 - train/lr(1e-3):0.0876087119234534
step:1054 - train/loss:0.6451062560081482 - train/lr(1e-3):0.08757525914761322
step:1055 - train/loss:0.6013402938842773 - train/lr(1e-3):0.0875417676816787
step:1056 - train/loss:0.5802894234657288 - train/lr(1e-3):0.08750823756013498
step:1057 - train/loss:0.7076171636581421 - train/lr(1e-3):0.08747466881750701
step:1058 - train/loss:0.6314983367919922 - train/lr(1e-3):0.08744106148835949
step:1059 - train/loss:0.8104676604270935 - train/lr(1e-3):0.08740741560729687
step:1060 - train/loss:0.4552640914916992 - train/lr(1e-3):0.08737373120896325
step:1061 - train/loss:0.5747443437576294 - train/lr(1e-3):0.08734000832804245
step:1062 - train/loss:0.5510340929031372 - train/lr(1e-3):0.08730624699925792
step:1063 - train/loss:0.5682111382484436 - train/lr(1e-3):0.0872724472573726
step:1064 - train/loss:0.6154414415359497 - train/lr(1e-3):0.0872386091371891
step:1065 - train/loss:0.7392215728759766 - train/lr(1e-3):0.08720473267354947
step:1066 - train/loss:0.5955572724342346 - train/lr(1e-3):0.0871708179013353
step:1067 - train/loss:0.7396606802940369 - train/lr(1e-3):0.08713686485546754
step:1068 - train/loss:0.6923425197601318 - train/lr(1e-3):0.08710287357090665
step:1069 - train/loss:0.6898338794708252 - train/lr(1e-3):0.0870688440826524
step:1070 - train/loss:0.7297054529190063 - train/lr(1e-3):0.0870347764257439
step:1071 - train/loss:0.6562424898147583 - train/lr(1e-3):0.0870006706352596
step:1072 - train/loss:0.6370067596435547 - train/lr(1e-3):0.08696652674631718
step:1073 - train/loss:0.6216257214546204 - train/lr(1e-3):0.08693234479407352
step:1074 - train/loss:0.4701763987541199 - train/lr(1e-3):0.08689812481372478
step:1075 - train/loss:0.5718789100646973 - train/lr(1e-3):0.0868638668405062
step:1076 - train/loss:0.6358019113540649 - train/lr(1e-3):0.08682957090969219
step:1077 - train/loss:0.5902051329612732 - train/lr(1e-3):0.08679523705659618
step:1078 - train/loss:0.6542379856109619 - train/lr(1e-3):0.08676086531657073
step:1079 - train/loss:0.6713671088218689 - train/lr(1e-3):0.08672645572500735
step:1080 - train/loss:0.5723594427108765 - train/lr(1e-3):0.08669200831733656
step:1081 - train/loss:0.6100794076919556 - train/lr(1e-3):0.08665752312902775
step:1082 - train/loss:0.5973038077354431 - train/lr(1e-3):0.08662300019558931
step:1083 - train/loss:0.535075306892395 - train/lr(1e-3):0.08658843955256844
step:1084 - train/loss:0.6154695153236389 - train/lr(1e-3):0.08655384123555117
step:1085 - train/loss:0.6411948204040527 - train/lr(1e-3):0.08651920528016233
step:1086 - train/loss:0.6978819370269775 - train/lr(1e-3):0.08648453172206551
step:1087 - train/loss:0.6581226587295532 - train/lr(1e-3):0.086449820596963
step:1088 - train/loss:0.7148399353027344 - train/lr(1e-3):0.08641507194059579
step:1089 - train/loss:0.5236018896102905 - train/lr(1e-3):0.08638028578874354
step:1090 - train/loss:0.66144198179245 - train/lr(1e-3):0.0863454621772244
step:1091 - train/loss:0.655677318572998 - train/lr(1e-3):0.08631060114189525
step:1092 - train/loss:0.5661962032318115 - train/lr(1e-3):0.08627570271865141
step:1093 - train/loss:0.6361898183822632 - train/lr(1e-3):0.08624076694342674
step:1094 - train/loss:0.5102409720420837 - train/lr(1e-3):0.0862057938521935
step:1095 - train/loss:0.656383752822876 - train/lr(1e-3):0.08617078348096241
step:1096 - train/loss:0.6276553869247437 - train/lr(1e-3):0.08613573586578262
step:1097 - train/loss:0.5338758230209351 - train/lr(1e-3):0.08610065104274156
step:1098 - train/loss:0.7794520854949951 - train/lr(1e-3):0.086065529047965
step:1099 - train/loss:0.6721030473709106 - train/lr(1e-3):0.08603036991761698
step:1100 - train/loss:0.7052421569824219 - train/lr(1e-3):0.0859951736878998
step:1101 - train/loss:0.5576916933059692 - train/lr(1e-3):0.08595994039505392
step:1102 - train/loss:0.572672963142395 - train/lr(1e-3):0.08592467007535798
step:1103 - train/loss:0.5438209176063538 - train/lr(1e-3):0.08588936276512878
step:1104 - train/loss:0.7331425547599792 - train/lr(1e-3):0.08585401850072114
step:1105 - train/loss:0.6467676758766174 - train/lr(1e-3):0.08581863731852797
step:1106 - train/loss:0.6502756476402283 - train/lr(1e-3):0.08578321925498024
step:1107 - train/loss:0.6951752305030823 - train/lr(1e-3):0.08574776434654677
step:1108 - train/loss:0.6602061986923218 - train/lr(1e-3):0.08571227262973444
step:1109 - train/loss:0.5552427172660828 - train/lr(1e-3):0.08567674414108799
step:1110 - train/loss:0.728729248046875 - train/lr(1e-3):0.08564117891719
step:1111 - train/loss:0.7220150232315063 - train/lr(1e-3):0.08560557699466088
step:1112 - train/loss:0.649203360080719 - train/lr(1e-3):0.0855699384101589
step:1113 - train/loss:0.49364691972732544 - train/lr(1e-3):0.08553426320037995
step:1114 - train/loss:0.5668836236000061 - train/lr(1e-3):0.08549855140205774
step:1115 - train/loss:0.6538881063461304 - train/lr(1e-3):0.08546280305196359
step:1116 - train/loss:0.6600310802459717 - train/lr(1e-3):0.08542701818690651
step:1117 - train/loss:0.628410279750824 - train/lr(1e-3):0.08539119684373306
step:1118 - train/loss:0.6249369978904724 - train/lr(1e-3):0.08535533905932738
step:1119 - train/loss:0.6539860367774963 - train/lr(1e-3):0.08531944487061115
step:1120 - train/loss:0.6561208367347717 - train/lr(1e-3):0.08528351431454351
step:1121 - train/loss:0.5778936147689819 - train/lr(1e-3):0.08524754742812105
step:1122 - train/loss:0.7247123718261719 - train/lr(1e-3):0.08521154424837778
step:1123 - train/loss:0.6666901707649231 - train/lr(1e-3):0.08517550481238506
step:1124 - train/loss:0.46957725286483765 - train/lr(1e-3):0.08513942915725159
step:1125 - train/loss:0.6453256607055664 - train/lr(1e-3):0.0851033173201234
step:1126 - train/loss:0.639999508857727 - train/lr(1e-3):0.08506716933818372
step:1127 - train/loss:0.6395939588546753 - train/lr(1e-3):0.08503098524865302
step:1128 - train/loss:0.567471444606781 - train/lr(1e-3):0.08499476508878893
step:1129 - train/loss:0.6683306694030762 - train/lr(1e-3):0.08495850889588628
step:1130 - train/loss:0.6595190763473511 - train/lr(1e-3):0.08492221670727694
step:1131 - train/loss:0.9019789695739746 - train/lr(1e-3):0.08488588856032989
step:1132 - train/loss:0.6263700723648071 - train/lr(1e-3):0.08484952449245108
step:1133 - train/loss:0.5373383164405823 - train/lr(1e-3):0.08481312454108347
step:1134 - train/loss:0.6688712239265442 - train/lr(1e-3):0.08477668874370703
step:1135 - train/loss:0.6134556531906128 - train/lr(1e-3):0.08474021713783854
step:1136 - train/loss:0.7060071229934692 - train/lr(1e-3):0.0847037097610317
step:1137 - train/loss:0.5393162965774536 - train/lr(1e-3):0.08466716665087705
step:1138 - train/loss:0.6388980746269226 - train/lr(1e-3):0.08463058784500191
step:1139 - train/loss:0.6828712224960327 - train/lr(1e-3):0.08459397338107034
step:1140 - train/loss:0.6729121208190918 - train/lr(1e-3):0.08455732329678317
step:1141 - train/loss:0.6162453889846802 - train/lr(1e-3):0.08452063762987784
step:1142 - train/loss:0.6083275079727173 - train/lr(1e-3):0.08448391641812844
step:1143 - train/loss:0.5813030004501343 - train/lr(1e-3):0.08444715969934573
step:1144 - train/loss:0.5924255847930908 - train/lr(1e-3):0.08441036751137697
step:1145 - train/loss:0.7043613791465759 - train/lr(1e-3):0.0843735398921059
step:1146 - train/loss:0.6267858743667603 - train/lr(1e-3):0.08433667687945284
step:1147 - train/loss:0.5891733169555664 - train/lr(1e-3):0.08429977851137449
step:1148 - train/loss:0.6310541033744812 - train/lr(1e-3):0.08426284482586395
step:1149 - train/loss:0.6914761662483215 - train/lr(1e-3):0.08422587586095077
step:1150 - train/loss:0.7103872299194336 - train/lr(1e-3):0.0841888716547007
step:1151 - train/loss:0.7821551561355591 - train/lr(1e-3):0.08415183224521583
step:1152 - train/loss:0.675636351108551 - train/lr(1e-3):0.08411475767063456
step:1153 - train/loss:0.6747008562088013 - train/lr(1e-3):0.08407764796913139
step:1154 - train/loss:0.6247759461402893 - train/lr(1e-3):0.08404050317891712
step:1155 - train/loss:0.588256299495697 - train/lr(1e-3):0.08400332333823853
step:1156 - train/loss:0.6202793717384338 - train/lr(1e-3):0.08396610848537858
step:1157 - train/loss:0.6222388744354248 - train/lr(1e-3):0.08392885865865628
step:1158 - train/loss:0.5918529033660889 - train/lr(1e-3):0.08389157389642664
step:1159 - train/loss:0.5926651954650879 - train/lr(1e-3):0.08385425423708062
step:1160 - train/loss:0.6783691644668579 - train/lr(1e-3):0.08381689971904514
step:1161 - train/loss:0.5411194562911987 - train/lr(1e-3):0.08377951038078302
step:1162 - train/loss:0.5556715130805969 - train/lr(1e-3):0.0837420862607929
step:1163 - train/loss:0.6740785241127014 - train/lr(1e-3):0.08370462739760923
step:1164 - train/loss:0.7768354415893555 - train/lr(1e-3):0.08366713382980229
step:1165 - train/loss:0.6380798816680908 - train/lr(1e-3):0.08362960559597805
step:1166 - train/loss:0.6038423180580139 - train/lr(1e-3):0.08359204273477819
step:1167 - train/loss:0.5573652982711792 - train/lr(1e-3):0.08355444528488001
step:1168 - train/loss:0.5839898586273193 - train/lr(1e-3):0.0835168132849965
step:1169 - train/loss:0.646970272064209 - train/lr(1e-3):0.08347914677387613
step:1170 - train/loss:0.6380883455276489 - train/lr(1e-3):0.08344144579030298
step:1171 - train/loss:0.6838258504867554 - train/lr(1e-3):0.0834037103730966
step:1172 - train/loss:0.6595373749732971 - train/lr(1e-3):0.08336594056111198
step:1173 - train/loss:0.5250197052955627 - train/lr(1e-3):0.08332813639323956
step:1174 - train/loss:0.6195062398910522 - train/lr(1e-3):0.0832902979084051
step:1175 - train/loss:0.6969148516654968 - train/lr(1e-3):0.08325242514556977
step:1176 - train/loss:0.6486757397651672 - train/lr(1e-3):0.08321451814372997
step:1177 - train/loss:0.7106565833091736 - train/lr(1e-3):0.08317657694191738
step:1178 - train/loss:0.6065953373908997 - train/lr(1e-3):0.08313860157919892
step:1179 - train/loss:0.6353982090950012 - train/lr(1e-3):0.08310059209467661
step:1180 - train/loss:0.6707667112350464 - train/lr(1e-3):0.0830625485274877
step:1181 - train/loss:0.6362087726593018 - train/lr(1e-3):0.08302447091680451
step:1182 - train/loss:0.6081074476242065 - train/lr(1e-3):0.08298635930183429
step:1183 - train/loss:0.6633874773979187 - train/lr(1e-3):0.08294821372181949
step:1184 - train/loss:0.5410684943199158 - train/lr(1e-3):0.0829100342160374
step:1185 - train/loss:0.5905038714408875 - train/lr(1e-3):0.08287182082380033
step:1186 - train/loss:0.604180097579956 - train/lr(1e-3):0.08283357358445541
step:1187 - train/loss:0.6993194222450256 - train/lr(1e-3):0.08279529253738467
step:1188 - train/loss:0.5649407505989075 - train/lr(1e-3):0.0827569777220049
step:1189 - train/loss:0.6102939248085022 - train/lr(1e-3):0.08271862917776773
step:1190 - train/loss:0.583658754825592 - train/lr(1e-3):0.08268024694415947
step:1191 - train/loss:0.6955236792564392 - train/lr(1e-3):0.08264183106070111
step:1192 - train/loss:0.5938725471496582 - train/lr(1e-3):0.08260338156694837
step:1193 - train/loss:0.6943245530128479 - train/lr(1e-3):0.08256489850249144
step:1194 - train/loss:0.6865177154541016 - train/lr(1e-3):0.08252638190695519
step:1195 - train/loss:0.8664361834526062 - train/lr(1e-3):0.082487831819999
step:1196 - train/loss:0.5649169683456421 - train/lr(1e-3):0.08244924828131668
step:1197 - train/loss:0.5358975529670715 - train/lr(1e-3):0.08241063133063653
step:1198 - train/loss:0.5936362147331238 - train/lr(1e-3):0.08237198100772125
step:1199 - train/loss:0.713036298751831 - train/lr(1e-3):0.0823332973523679
step:1200 - train/loss:0.5925530791282654 - train/lr(1e-3):0.08229458040440782
step:1201 - train/loss:0.5911329984664917 - train/lr(1e-3):0.0822558302037067
step:1202 - train/loss:0.6422000527381897 - train/lr(1e-3):0.08221704679016444
step:1203 - train/loss:0.5975667834281921 - train/lr(1e-3):0.0821782302037151
step:1204 - train/loss:0.49043452739715576 - train/lr(1e-3):0.08213938048432697
step:1205 - train/loss:0.6440648436546326 - train/lr(1e-3):0.08210049767200239
step:1206 - train/loss:0.6619642376899719 - train/lr(1e-3):0.08206158180677782
step:1207 - train/loss:0.6779507994651794 - train/lr(1e-3):0.08202263292872372
step:1208 - train/loss:0.7022473812103271 - train/lr(1e-3):0.08198365107794457
step:1209 - train/loss:0.7254807353019714 - train/lr(1e-3):0.08194463629457878
step:1210 - train/loss:0.6744569540023804 - train/lr(1e-3):0.08190558861879868
step:1211 - train/loss:0.6339120864868164 - train/lr(1e-3):0.08186650809081046
step:1212 - train/loss:0.6121549010276794 - train/lr(1e-3):0.08182739475085417
step:1213 - train/loss:0.594374418258667 - train/lr(1e-3):0.08178824863920359
step:1214 - train/loss:0.6657316088676453 - train/lr(1e-3):0.08174906979616628
step:1215 - train/loss:0.5760139226913452 - train/lr(1e-3):0.0817098582620835
step:1216 - train/loss:0.5168795585632324 - train/lr(1e-3):0.08167061407733016
step:1217 - train/loss:0.5104528665542603 - train/lr(1e-3):0.08163133728231482
step:1218 - train/loss:0.594565749168396 - train/lr(1e-3):0.08159202791747958
step:1219 - train/loss:0.5217463374137878 - train/lr(1e-3):0.08155268602330006
step:1220 - train/loss:0.6118909120559692 - train/lr(1e-3):0.08151331164028544
step:1221 - train/loss:0.6813961267471313 - train/lr(1e-3):0.08147390480897831
step:1222 - train/loss:0.6757158041000366 - train/lr(1e-3):0.08143446556995466
step:1223 - train/loss:0.633144736289978 - train/lr(1e-3):0.08139499396382391
step:1224 - train/loss:0.6186795830726624 - train/lr(1e-3):0.08135549003122872
step:1225 - train/loss:0.593833327293396 - train/lr(1e-3):0.0813159538128451
step:1226 - train/loss:0.6315183639526367 - train/lr(1e-3):0.08127638534938227
step:1227 - train/loss:0.6160596609115601 - train/lr(1e-3):0.08123678468158269
step:1228 - train/loss:0.6309322118759155 - train/lr(1e-3):0.08119715185022194
step:1229 - train/loss:0.6067656874656677 - train/lr(1e-3):0.08115748689610874
step:1230 - train/loss:0.7573861479759216 - train/lr(1e-3):0.08111778986008486
step:1231 - train/loss:0.6153291463851929 - train/lr(1e-3):0.08107806078302517
step:1232 - train/loss:0.46431323885917664 - train/lr(1e-3):0.08103829970583742
step:1233 - train/loss:0.6523149013519287 - train/lr(1e-3):0.08099850666946241
step:1234 - train/loss:0.6554482579231262 - train/lr(1e-3):0.08095868171487383
step:1235 - train/loss:0.5738339424133301 - train/lr(1e-3):0.0809188248830782
step:1236 - train/loss:0.5854243636131287 - train/lr(1e-3):0.08087893621511487
step:1237 - train/loss:0.5740546584129333 - train/lr(1e-3):0.08083901575205599
step:1238 - train/loss:0.6034682393074036 - train/lr(1e-3):0.0807990635350064
step:1239 - train/loss:0.5875626802444458 - train/lr(1e-3):0.08075907960510374
step:1240 - train/loss:0.6051640510559082 - train/lr(1e-3):0.08071906400351822
step:1241 - train/loss:0.5982810258865356 - train/lr(1e-3):0.08067901677145266
step:1242 - train/loss:0.6292020082473755 - train/lr(1e-3):0.08063893795014247
step:1243 - train/loss:0.7016929984092712 - train/lr(1e-3):0.08059882758085561
step:1244 - train/loss:0.7250680923461914 - train/lr(1e-3):0.08055868570489247
step:1245 - train/loss:0.5594989061355591 - train/lr(1e-3):0.08051851236358593
step:1246 - train/loss:0.6625595092773438 - train/lr(1e-3):0.08047830759830125
step:1247 - train/loss:0.5525118112564087 - train/lr(1e-3):0.08043807145043604
step:1248 - train/loss:0.5724388957023621 - train/lr(1e-3):0.08039780396142023
step:1249 - train/loss:0.5946905612945557 - train/lr(1e-3):0.08035750517271603
step:1250 - train/loss:0.5811510682106018 - train/lr(1e-3):0.08031717512581785
step:1251 - train/loss:0.6122757196426392 - train/lr(1e-3):0.08027681386225231
step:1252 - train/loss:0.6147382855415344 - train/lr(1e-3):0.08023642142357822
step:1253 - train/loss:0.6756274700164795 - train/lr(1e-3):0.08019599785138634
step:1254 - train/loss:0.720540463924408 - train/lr(1e-3):0.08015554318729966
step:1255 - train/loss:0.62046879529953 - train/lr(1e-3):0.08011505747297311
step:1256 - train/loss:0.5947169065475464 - train/lr(1e-3):0.08007454075009351
step:1257 - train/loss:0.5167367458343506 - train/lr(1e-3):0.0800339930603798
step:1258 - train/loss:0.6647427082061768 - train/lr(1e-3):0.07999341444558263
step:1259 - train/loss:0.6040476560592651 - train/lr(1e-3):0.07995280494748457
step:1260 - train/loss:0.5639299154281616 - train/lr(1e-3):0.07991216460789996
step:1261 - train/loss:0.5699313282966614 - train/lr(1e-3):0.07987149346867495
step:1262 - train/loss:0.7189161777496338 - train/lr(1e-3):0.07983079157168736
step:1263 - train/loss:0.7821792364120483 - train/lr(1e-3):0.07979005895884665
step:1264 - train/loss:0.6761301755905151 - train/lr(1e-3):0.079749295672094
step:1265 - train/loss:0.6669542193412781 - train/lr(1e-3):0.07970850175340208
step:1266 - train/loss:0.7801434993743896 - train/lr(1e-3):0.07966767724477515
step:1267 - train/loss:0.5879988074302673 - train/lr(1e-3):0.07962682218824894
step:1268 - train/loss:0.7045903205871582 - train/lr(1e-3):0.07958593662589068
step:1269 - train/loss:0.6271035075187683 - train/lr(1e-3):0.07954502059979898
step:1270 - train/loss:0.75054931640625 - train/lr(1e-3):0.0795040741521038
step:1271 - train/loss:0.5571640729904175 - train/lr(1e-3):0.07946309732496647
step:1272 - train/loss:0.5987386107444763 - train/lr(1e-3):0.07942209016057954
step:1273 - train/loss:0.5825769901275635 - train/lr(1e-3):0.07938105270116685
step:1274 - train/loss:0.6268125176429749 - train/lr(1e-3):0.07933998498898343
step:1275 - train/loss:0.5870359539985657 - train/lr(1e-3):0.07929888706631544
step:1276 - train/loss:0.6466931104660034 - train/lr(1e-3):0.07925775897548014
step:1277 - train/loss:0.5369918942451477 - train/lr(1e-3):0.07921660075882586
step:1278 - train/loss:0.5735993385314941 - train/lr(1e-3):0.07917541245873198
step:1279 - train/loss:0.6388007402420044 - train/lr(1e-3):0.07913419411760882
step:1280 - train/loss:0.6648119688034058 - train/lr(1e-3):0.07909294577789766
step:1281 - train/loss:0.5160322189331055 - train/lr(1e-3):0.0790516674820706
step:1282 - train/loss:0.663225531578064 - train/lr(1e-3):0.07901035927263073
step:1283 - train/loss:0.4812448024749756 - train/lr(1e-3):0.07896902119211176
step:1284 - train/loss:0.6260961294174194 - train/lr(1e-3):0.07892765328307827
step:1285 - train/loss:0.6140611171722412 - train/lr(1e-3):0.07888625558812556
step:1286 - train/loss:0.6985901594161987 - train/lr(1e-3):0.07884482814987957
step:1287 - train/loss:0.6892942190170288 - train/lr(1e-3):0.07880337101099683
step:1288 - train/loss:0.5475451350212097 - train/lr(1e-3):0.0787618842141645
step:1289 - train/loss:0.6829222440719604 - train/lr(1e-3):0.07872036780210026
step:1290 - train/loss:0.6028620004653931 - train/lr(1e-3):0.0786788218175523
step:1291 - train/loss:0.6349107027053833 - train/lr(1e-3):0.07863724630329927
step:1292 - train/loss:0.6549608111381531 - train/lr(1e-3):0.07859564130215016
step:1293 - train/loss:0.7085936069488525 - train/lr(1e-3):0.07855400685694439
step:1294 - train/loss:0.5693970322608948 - train/lr(1e-3):0.07851234301055167
step:1295 - train/loss:0.609161376953125 - train/lr(1e-3):0.078470649805872
step:1296 - train/loss:0.5763509273529053 - train/lr(1e-3):0.07842892728583557
step:1297 - train/loss:0.5973602533340454 - train/lr(1e-3):0.07838717549340281
step:1298 - train/loss:0.6206076145172119 - train/lr(1e-3):0.07834539447156424
step:1299 - train/loss:0.611894965171814 - train/lr(1e-3):0.07830358426334051
step:1300 - train/loss:0.5666464567184448 - train/lr(1e-3):0.07826174491178231
step:1301 - train/loss:0.5886372327804565 - train/lr(1e-3):0.07821987645997036
step:1302 - train/loss:0.47988492250442505 - train/lr(1e-3):0.07817797895101529
step:1303 - train/loss:0.5243496894836426 - train/lr(1e-3):0.07813605242805767
step:1304 - train/loss:0.5276857614517212 - train/lr(1e-3):0.07809409693426803
step:1305 - train/loss:0.7059385776519775 - train/lr(1e-3):0.07805211251284659
step:1306 - train/loss:0.5680629014968872 - train/lr(1e-3):0.07801009920702345
step:1307 - train/loss:0.686209499835968 - train/lr(1e-3):0.07796805706005842
step:1308 - train/loss:0.5900319218635559 - train/lr(1e-3):0.07792598611524103
step:1309 - train/loss:0.49852457642555237 - train/lr(1e-3):0.07788388641589039
step:1310 - train/loss:0.606092095375061 - train/lr(1e-3):0.07784175800535534
step:1311 - train/loss:0.5875886082649231 - train/lr(1e-3):0.0777996009270142
step:1312 - train/loss:0.6634916067123413 - train/lr(1e-3):0.07775741522427478
step:1313 - train/loss:0.5840010643005371 - train/lr(1e-3):0.07771520094057442
step:1314 - train/loss:0.6807342171669006 - train/lr(1e-3):0.07767295811937994
step:1315 - train/loss:0.7463834285736084 - train/lr(1e-3):0.07763068680418737
step:1316 - train/loss:0.5210012793540955 - train/lr(1e-3):0.0775883870385223
step:1317 - train/loss:0.554929792881012 - train/lr(1e-3):0.07754605886593945
step:1318 - train/loss:0.598780632019043 - train/lr(1e-3):0.07750370233002282
step:1319 - train/loss:0.5424046516418457 - train/lr(1e-3):0.0774613174743857
step:1320 - train/loss:0.6551607847213745 - train/lr(1e-3):0.07741890434267043
step:1321 - train/loss:0.5565130114555359 - train/lr(1e-3):0.07737646297854853
step:1322 - train/loss:0.643955409526825 - train/lr(1e-3):0.07733399342572056
step:1323 - train/loss:0.6670966148376465 - train/lr(1e-3):0.07729149572791615
step:1324 - train/loss:0.7065771818161011 - train/lr(1e-3):0.07724896992889385
step:1325 - train/loss:0.6785387992858887 - train/lr(1e-3):0.07720641607244119
step:1326 - train/loss:0.46614980697631836 - train/lr(1e-3):0.07716383420237458
step:1327 - train/loss:0.6815848350524902 - train/lr(1e-3):0.07712122436253924
step:1328 - train/loss:0.6425078511238098 - train/lr(1e-3):0.07707858659680923
step:1329 - train/loss:0.573731005191803 - train/lr(1e-3):0.07703592094908736
step:1330 - train/loss:0.5656968355178833 - train/lr(1e-3):0.07699322746330516
step:1331 - train/loss:0.5639417767524719 - train/lr(1e-3):0.07695050618342276
step:1332 - train/loss:0.7804884910583496 - train/lr(1e-3):0.07690775715342898
step:1333 - train/loss:0.6752161383628845 - train/lr(1e-3):0.0768649804173412
step:1334 - train/loss:0.584026038646698 - train/lr(1e-3):0.0768221760192053
step:1335 - train/loss:0.6987314820289612 - train/lr(1e-3):0.07677934400309565
step:1336 - train/loss:0.6888264417648315 - train/lr(1e-3):0.07673648441311508
step:1337 - train/loss:0.6982159614562988 - train/lr(1e-3):0.0766935972933948
step:1338 - train/loss:0.5788303017616272 - train/lr(1e-3):0.07665068268809434
step:1339 - train/loss:0.6812214255332947 - train/lr(1e-3):0.0766077406414016
step:1340 - train/loss:0.5607683062553406 - train/lr(1e-3):0.07656477119753266
step:1341 - train/loss:0.5932301878929138 - train/lr(1e-3):0.07652177440073187
step:1342 - train/loss:0.6773404479026794 - train/lr(1e-3):0.07647875029527167
step:1343 - train/loss:0.6201215386390686 - train/lr(1e-3):0.07643569892545267
step:1344 - train/loss:0.6175343990325928 - train/lr(1e-3):0.07639262033560358
step:1345 - train/loss:0.4998154640197754 - train/lr(1e-3):0.07634951457008111
step:1346 - train/loss:0.5699542760848999 - train/lr(1e-3):0.0763063816732699
step:1347 - train/loss:0.5471305847167969 - train/lr(1e-3):0.07626322168958263
step:1348 - train/loss:0.5447295308113098 - train/lr(1e-3):0.07622003466345978
step:1349 - train/loss:0.4534294605255127 - train/lr(1e-3):0.0761768206393697
step:1350 - train/loss:0.47615939378738403 - train/lr(1e-3):0.07613357966180859
step:1351 - train/loss:0.6593960523605347 - train/lr(1e-3):0.0760903117753003
step:1352 - train/loss:0.5831939578056335 - train/lr(1e-3):0.07604701702439651
step:1353 - train/loss:0.5211539268493652 - train/lr(1e-3):0.07600369545367647
step:1354 - train/loss:0.6088339686393738 - train/lr(1e-3):0.07596034710774709
step:1355 - train/loss:0.5929297208786011 - train/lr(1e-3):0.07591697203124279
step:1356 - train/loss:0.54933762550354 - train/lr(1e-3):0.07587357026882562
step:1357 - train/loss:0.7435417175292969 - train/lr(1e-3):0.07583014186518502
step:1358 - train/loss:0.5727462768554688 - train/lr(1e-3):0.0757866868650379
step:1359 - train/loss:0.706473708152771 - train/lr(1e-3):0.0757432053131285
step:1360 - train/loss:0.7052526473999023 - train/lr(1e-3):0.0756996972542285
step:1361 - train/loss:0.6155667304992676 - train/lr(1e-3):0.07565616273313677
step:1362 - train/loss:0.5903567671775818 - train/lr(1e-3):0.0756126017946795
step:1363 - train/loss:0.5301105976104736 - train/lr(1e-3):0.07556901448371008
step:1364 - train/loss:0.6273862719535828 - train/lr(1e-3):0.07552540084510896
step:1365 - train/loss:0.5967161655426025 - train/lr(1e-3):0.07548176092378381
step:1366 - train/loss:0.606728196144104 - train/lr(1e-3):0.07543809476466934
step:1367 - train/loss:0.5037050843238831 - train/lr(1e-3):0.07539440241272724
step:1368 - train/loss:0.7224000692367554 - train/lr(1e-3):0.07535068391294618
step:1369 - train/loss:0.7212108373641968 - train/lr(1e-3):0.07530693931034176
step:1370 - train/loss:0.6518046855926514 - train/lr(1e-3):0.07526316864995647
step:1371 - train/loss:0.7746454477310181 - train/lr(1e-3):0.0752193719768596
step:1372 - train/loss:0.6737397909164429 - train/lr(1e-3):0.07517554933614728
step:1373 - train/loss:0.6654688119888306 - train/lr(1e-3):0.07513170077294232
step:1374 - train/loss:0.5728324055671692 - train/lr(1e-3):0.07508782633239425
step:1375 - train/loss:0.6696727275848389 - train/lr(1e-3):0.07504392605967922
step:1376 - train/loss:0.6195735931396484 - train/lr(1e-3):0.07500000000000001
step:1377 - train/loss:0.6359580755233765 - train/lr(1e-3):0.07495604819858592
step:1378 - train/loss:0.7526153922080994 - train/lr(1e-3):0.07491207070069282
step:1379 - train/loss:0.6137272715568542 - train/lr(1e-3):0.07486806755160297
step:1380 - train/loss:0.7854071855545044 - train/lr(1e-3):0.07482403879662505
step:1381 - train/loss:0.6823889017105103 - train/lr(1e-3):0.07477998448109414
step:1382 - train/loss:0.6260457038879395 - train/lr(1e-3):0.07473590465037164
step:1383 - train/loss:0.5602981448173523 - train/lr(1e-3):0.07469179934984514
step:1384 - train/loss:0.4762287735939026 - train/lr(1e-3):0.07464766862492855
step:1385 - train/loss:0.6699689030647278 - train/lr(1e-3):0.07460351252106198
step:1386 - train/loss:0.6282123923301697 - train/lr(1e-3):0.07455933108371154
step:1387 - train/loss:0.5910454988479614 - train/lr(1e-3):0.07451512435836953
step:1388 - train/loss:0.6998699307441711 - train/lr(1e-3):0.07447089239055428
step:1389 - train/loss:0.608938992023468 - train/lr(1e-3):0.07442663522581007
step:1390 - train/loss:0.5375783443450928 - train/lr(1e-3):0.07438235290970717
step:1391 - train/loss:0.528872549533844 - train/lr(1e-3):0.07433804548784173
step:1392 - train/loss:0.5208336710929871 - train/lr(1e-3):0.0742937130058357
step:1393 - train/loss:0.5084375739097595 - train/lr(1e-3):0.07424935550933692
step:1394 - train/loss:0.5900577306747437 - train/lr(1e-3):0.07420497304401895
step:1395 - train/loss:0.5574774742126465 - train/lr(1e-3):0.07416056565558103
step:1396 - train/loss:0.6612085103988647 - train/lr(1e-3):0.07411613338974811
step:1397 - train/loss:0.6591494083404541 - train/lr(1e-3):0.07407167629227072
step:1398 - train/loss:0.7481380701065063 - train/lr(1e-3):0.07402719440892498
step:1399 - train/loss:0.6431879997253418 - train/lr(1e-3):0.07398268778551251
step:1400 - train/loss:0.39444559812545776 - train/lr(1e-3):0.07393815646786046
step:1401 - train/loss:0.5936279296875 - train/lr(1e-3):0.07389360050182132
step:1402 - train/loss:0.6119681596755981 - train/lr(1e-3):0.07384901993327303
step:1403 - train/loss:0.6627932786941528 - train/lr(1e-3):0.07380441480811882
step:1404 - train/loss:0.7733556032180786 - train/lr(1e-3):0.07375978517228723
step:1405 - train/loss:0.5623693466186523 - train/lr(1e-3):0.07371513107173203
step:1406 - train/loss:0.5442406535148621 - train/lr(1e-3):0.07367045255243217
step:1407 - train/loss:0.5461268424987793 - train/lr(1e-3):0.07362574966039177
step:1408 - train/loss:0.576715886592865 - train/lr(1e-3):0.07358102244164003
step:1409 - train/loss:0.4569171369075775 - train/lr(1e-3):0.0735362709422312
step:1410 - train/loss:0.6921115517616272 - train/lr(1e-3):0.07349149520824452
step:1411 - train/loss:0.6135382652282715 - train/lr(1e-3):0.07344669528578418
step:1412 - train/loss:0.5932207107543945 - train/lr(1e-3):0.0734018712209793
step:1413 - train/loss:0.6117287874221802 - train/lr(1e-3):0.07335702305998389
step:1414 - train/loss:0.6490951180458069 - train/lr(1e-3):0.07331215084897665
step:1415 - train/loss:0.6599101424217224 - train/lr(1e-3):0.07326725463416117
step:1416 - train/loss:0.6096086502075195 - train/lr(1e-3):0.07322233446176571
step:1417 - train/loss:0.6770687103271484 - train/lr(1e-3):0.07317739037804318
step:1418 - train/loss:0.6005903482437134 - train/lr(1e-3):0.07313242242927115
step:1419 - train/loss:0.512444019317627 - train/lr(1e-3):0.07308743066175172
step:1420 - train/loss:0.6457026600837708 - train/lr(1e-3):0.07304241512181152
step:1421 - train/loss:0.6989474296569824 - train/lr(1e-3):0.0729973758558017
step:1422 - train/loss:0.7531185746192932 - train/lr(1e-3):0.07295231291009784
step:1423 - train/loss:0.5755497217178345 - train/lr(1e-3):0.07290722633109982
step:1424 - train/loss:0.6542338728904724 - train/lr(1e-3):0.07286211616523193
step:1425 - train/loss:0.624258816242218 - train/lr(1e-3):0.07281698245894275
step:1426 - train/loss:0.5518988370895386 - train/lr(1e-3):0.07277182525870506
step:1427 - train/loss:0.5979002714157104 - train/lr(1e-3):0.07272664461101581
step:1428 - train/loss:0.5795866250991821 - train/lr(1e-3):0.07268144056239621
step:1429 - train/loss:0.5881036520004272 - train/lr(1e-3):0.07263621315939142
step:1430 - train/loss:0.510640561580658 - train/lr(1e-3):0.07259096244857074
step:1431 - train/loss:0.4547916650772095 - train/lr(1e-3):0.07254568847652744
step:1432 - train/loss:0.665798544883728 - train/lr(1e-3):0.07250039128987873
step:1433 - train/loss:0.6875632405281067 - train/lr(1e-3):0.07245507093526574
step:1434 - train/loss:0.653439462184906 - train/lr(1e-3):0.07240972745935348
step:1435 - train/loss:0.7285065650939941 - train/lr(1e-3):0.0723643609088307
step:1436 - train/loss:0.6559353470802307 - train/lr(1e-3):0.07231897133040996
step:1437 - train/loss:0.5193078517913818 - train/lr(1e-3):0.07227355877082756
step:1438 - train/loss:0.6767844557762146 - train/lr(1e-3):0.07222812327684336
step:1439 - train/loss:0.6173993349075317 - train/lr(1e-3):0.07218266489524092
step:1440 - train/loss:0.6088621020317078 - train/lr(1e-3):0.07213718367282737
step:1441 - train/loss:0.7226392030715942 - train/lr(1e-3):0.0720916796564333
step:1442 - train/loss:0.6103299260139465 - train/lr(1e-3):0.07204615289291283
step:1443 - train/loss:0.6157958507537842 - train/lr(1e-3):0.07200060342914347
step:1444 - train/loss:0.5600523352622986 - train/lr(1e-3):0.07195503131202606
step:1445 - train/loss:0.5957557559013367 - train/lr(1e-3):0.07190943658848488
step:1446 - train/loss:0.6803918480873108 - train/lr(1e-3):0.0718638193054674
step:1447 - train/loss:0.594505786895752 - train/lr(1e-3):0.07181817950994433
step:1448 - train/loss:0.6181271076202393 - train/lr(1e-3):0.07177251724890955
step:1449 - train/loss:0.6647141575813293 - train/lr(1e-3):0.07172683256938016
step:1450 - train/loss:0.5279017686843872 - train/lr(1e-3):0.07168112551839623
step:1451 - train/loss:0.7087224125862122 - train/lr(1e-3):0.07163539614302088
step:1452 - train/loss:0.7586710453033447 - train/lr(1e-3):0.07158964449034033
step:1453 - train/loss:0.527385950088501 - train/lr(1e-3):0.07154387060746359
step:1454 - train/loss:0.5701543688774109 - train/lr(1e-3):0.07149807454152265
step:1455 - train/loss:0.5993015170097351 - train/lr(1e-3):0.07145225633967231
step:1456 - train/loss:0.5948795676231384 - train/lr(1e-3):0.0714064160490902
step:1457 - train/loss:0.6490167379379272 - train/lr(1e-3):0.0713605537169766
step:1458 - train/loss:0.5789932608604431 - train/lr(1e-3):0.07131466939055463
step:1459 - train/loss:0.574099600315094 - train/lr(1e-3):0.07126876311706991
step:1460 - train/loss:0.4711071252822876 - train/lr(1e-3):0.07122283494379075
step:1461 - train/loss:0.6042231321334839 - train/lr(1e-3):0.07117688491800801
step:1462 - train/loss:0.559261679649353 - train/lr(1e-3):0.07113091308703498
step:1463 - train/loss:0.6012771725654602 - train/lr(1e-3):0.07108491949820747
step:1464 - train/loss:0.5073412656784058 - train/lr(1e-3):0.07103890419888367
step:1465 - train/loss:0.5699163675308228 - train/lr(1e-3):0.07099286723644413
step:1466 - train/loss:0.5048819780349731 - train/lr(1e-3):0.07094680865829169
step:1467 - train/loss:0.7343769073486328 - train/lr(1e-3):0.07090072851185146
step:1468 - train/loss:0.5113389492034912 - train/lr(1e-3):0.07085462684457075
step:1469 - train/loss:0.6292675733566284 - train/lr(1e-3):0.07080850370391907
step:1470 - train/loss:0.6192069053649902 - train/lr(1e-3):0.07076235913738797
step:1471 - train/loss:0.6637417078018188 - train/lr(1e-3):0.07071619319249112
step:1472 - train/loss:0.5289913415908813 - train/lr(1e-3):0.07067000591676416
step:1473 - train/loss:0.5287915468215942 - train/lr(1e-3):0.07062379735776472
step:1474 - train/loss:0.5311058163642883 - train/lr(1e-3):0.07057756756307235
step:1475 - train/loss:0.6172826290130615 - train/lr(1e-3):0.07053131658028845
step:1476 - train/loss:0.5947043895721436 - train/lr(1e-3):0.07048504445703624
step:1477 - train/loss:0.5535070896148682 - train/lr(1e-3):0.0704387512409607
step:1478 - train/loss:0.616873025894165 - train/lr(1e-3):0.07039243697972856
step:1479 - train/loss:0.4773523509502411 - train/lr(1e-3):0.07034610172102818
step:1480 - train/loss:0.479769766330719 - train/lr(1e-3):0.07029974551256957
step:1481 - train/loss:0.6416819095611572 - train/lr(1e-3):0.07025336840208428
step:1482 - train/loss:0.5613481998443604 - train/lr(1e-3):0.0702069704373254
step:1483 - train/loss:0.611021101474762 - train/lr(1e-3):0.07016055166606752
step:1484 - train/loss:0.542883574962616 - train/lr(1e-3):0.07011411213610662
step:1485 - train/loss:0.5594606399536133 - train/lr(1e-3):0.07006765189526006
step:1486 - train/loss:0.5821918845176697 - train/lr(1e-3):0.07002117099136652
step:1487 - train/loss:0.5421017408370972 - train/lr(1e-3):0.06997466947228596
step:1488 - train/loss:0.690001368522644 - train/lr(1e-3):0.06992814738589957
step:1489 - train/loss:0.6176947951316833 - train/lr(1e-3):0.06988160478010975
step:1490 - train/loss:0.6804032921791077 - train/lr(1e-3):0.06983504170284
step:1491 - train/loss:0.6264739036560059 - train/lr(1e-3):0.06978845820203482
step:1492 - train/loss:0.5167756080627441 - train/lr(1e-3):0.0697418543256599
step:1493 - train/loss:0.6602852940559387 - train/lr(1e-3):0.06969523012170178
step:1494 - train/loss:0.610678493976593 - train/lr(1e-3):0.06964858563816799
step:1495 - train/loss:0.6784043312072754 - train/lr(1e-3):0.06960192092308692
step:1496 - train/loss:0.6225976943969727 - train/lr(1e-3):0.06955523602450779
step:1497 - train/loss:0.5743957161903381 - train/lr(1e-3):0.06950853099050065
step:1498 - train/loss:0.6900637745857239 - train/lr(1e-3):0.06946180586915622
step:1499 - train/loss:0.5958465933799744 - train/lr(1e-3):0.06941506070858591
step:1500 - train/loss:0.6295546293258667 - train/lr(1e-3):0.06936829555692181
step:1501 - train/loss:0.5459837317466736 - train/lr(1e-3):0.06932151046231654
step:1502 - train/loss:0.6640481948852539 - train/lr(1e-3):0.0692747054729433
step:1503 - train/loss:0.6451829671859741 - train/lr(1e-3):0.06922788063699575
step:1504 - train/loss:0.6055213212966919 - train/lr(1e-3):0.06918103600268799
step:1505 - train/loss:0.6567891240119934 - train/lr(1e-3):0.0691341716182545
step:1506 - train/loss:0.6373264789581299 - train/lr(1e-3):0.0690872875319501
step:1507 - train/loss:0.5988531708717346 - train/lr(1e-3):0.06904038379204991
step:1508 - train/loss:0.6884274482727051 - train/lr(1e-3):0.06899346044684927
step:1509 - train/loss:0.512213945388794 - train/lr(1e-3):0.06894651754466373
step:1510 - train/loss:0.5894765853881836 - train/lr(1e-3):0.06889955513382892
step:1511 - train/loss:0.6153584718704224 - train/lr(1e-3):0.06885257326270063
step:1512 - train/loss:0.46537458896636963 - train/lr(1e-3):0.06880557197965464
step:1513 - train/loss:0.6849722862243652 - train/lr(1e-3):0.06875855133308675
step:1514 - train/loss:0.5117855072021484 - train/lr(1e-3):0.06871151137141267
step:1515 - train/loss:0.5516524910926819 - train/lr(1e-3):0.068664452143068
step:1516 - train/loss:0.5975557565689087 - train/lr(1e-3):0.06861737369650818
step:1517 - train/loss:0.6482468247413635 - train/lr(1e-3):0.06857027608020848
step:1518 - train/loss:0.6905152797698975 - train/lr(1e-3):0.06852315934266384
step:1519 - train/loss:0.5886539816856384 - train/lr(1e-3):0.06847602353238895
step:1520 - train/loss:0.5745347738265991 - train/lr(1e-3):0.06842886869791809
step:1521 - train/loss:0.7240763306617737 - train/lr(1e-3):0.06838169488780517
step:1522 - train/loss:0.602449893951416 - train/lr(1e-3):0.06833450215062359
step:1523 - train/loss:0.6327507495880127 - train/lr(1e-3):0.0682872905349663
step:1524 - train/loss:0.651241660118103 - train/lr(1e-3):0.06824006008944561
step:1525 - train/loss:0.6055421829223633 - train/lr(1e-3):0.06819281086269331
step:1526 - train/loss:0.6056936979293823 - train/lr(1e-3):0.06814554290336047
step:1527 - train/loss:0.6883991956710815 - train/lr(1e-3):0.06809825626011745
step:1528 - train/loss:0.523131787776947 - train/lr(1e-3):0.06805095098165388
step:1529 - train/loss:0.6096747517585754 - train/lr(1e-3):0.06800362711667852
step:1530 - train/loss:0.6655812859535217 - train/lr(1e-3):0.06795628471391935
step:1531 - train/loss:0.5144325494766235 - train/lr(1e-3):0.0679089238221234
step:1532 - train/loss:0.4628947377204895 - train/lr(1e-3):0.06786154449005664
step:1533 - train/loss:0.666213870048523 - train/lr(1e-3):0.06781414676650423
step:1534 - train/loss:0.5140900015830994 - train/lr(1e-3):0.06776673070027008
step:1535 - train/loss:0.6729927659034729 - train/lr(1e-3):0.06771929634017708
step:1536 - train/loss:0.6732516884803772 - train/lr(1e-3):0.06767184373506697
step:1537 - train/loss:0.6029296517372131 - train/lr(1e-3):0.06762437293380023
step:1538 - train/loss:0.6407662630081177 - train/lr(1e-3):0.06757688398525605
step:1539 - train/loss:0.5032482147216797 - train/lr(1e-3):0.06752937693833241
step:1540 - train/loss:0.5068037509918213 - train/lr(1e-3):0.06748185184194583
step:1541 - train/loss:0.627435028553009 - train/lr(1e-3):0.06743430874503144
step:1542 - train/loss:0.6799749732017517 - train/lr(1e-3):0.06738674769654293
step:1543 - train/loss:0.46367573738098145 - train/lr(1e-3):0.06733916874545245
step:1544 - train/loss:0.6164248585700989 - train/lr(1e-3):0.06729157194075057
step:1545 - train/loss:0.6390839219093323 - train/lr(1e-3):0.0672439573314463
step:1546 - train/loss:0.6524574160575867 - train/lr(1e-3):0.06719632496656693
step:1547 - train/loss:0.5512797236442566 - train/lr(1e-3):0.06714867489515804
step:1548 - train/loss:0.5008768439292908 - train/lr(1e-3):0.06710100716628345
step:1549 - train/loss:0.6870325207710266 - train/lr(1e-3):0.06705332182902517
step:1550 - train/loss:0.6502202153205872 - train/lr(1e-3):0.06700561893248332
step:1551 - train/loss:0.6715880632400513 - train/lr(1e-3):0.06695789852577612
step:1552 - train/loss:0.627373218536377 - train/lr(1e-3):0.06691016065803983
step:1553 - train/loss:0.5798051357269287 - train/lr(1e-3):0.06686240537842865
step:1554 - train/loss:0.7021161913871765 - train/lr(1e-3):0.06681463273611474
step:1555 - train/loss:0.5857747793197632 - train/lr(1e-3):0.06676684278028812
step:1556 - train/loss:0.5888248682022095 - train/lr(1e-3):0.06671903556015664
step:1557 - train/loss:0.5185449123382568 - train/lr(1e-3):0.06667121112494595
step:1558 - train/loss:0.5552780628204346 - train/lr(1e-3):0.06662336952389938
step:1559 - train/loss:0.5655913352966309 - train/lr(1e-3):0.06657551080627801
step:1560 - train/loss:0.6858309507369995 - train/lr(1e-3):0.06652763502136043
step:1561 - train/loss:0.6801730990409851 - train/lr(1e-3):0.06647974221844292
step:1562 - train/loss:0.5617680549621582 - train/lr(1e-3):0.06643183244683923
step:1563 - train/loss:0.512264609336853 - train/lr(1e-3):0.06638390575588056
step:1564 - train/loss:0.6664467453956604 - train/lr(1e-3):0.06633596219491558
step:1565 - train/loss:0.6430712342262268 - train/lr(1e-3):0.06628800181331031
step:1566 - train/loss:0.5804139971733093 - train/lr(1e-3):0.06624002466044805
step:1567 - train/loss:0.6251956820487976 - train/lr(1e-3):0.06619203078572945
step:1568 - train/loss:0.5566365718841553 - train/lr(1e-3):0.06614402023857231
step:1569 - train/loss:0.7103738784790039 - train/lr(1e-3):0.06609599306841164
step:1570 - train/loss:0.4985696077346802 - train/lr(1e-3):0.06604794932469953
step:1571 - train/loss:0.5695181488990784 - train/lr(1e-3):0.06599988905690515
step:1572 - train/loss:0.5756139159202576 - train/lr(1e-3):0.06595181231451468
step:1573 - train/loss:0.49941664934158325 - train/lr(1e-3):0.0659037191470313
step:1574 - train/loss:0.5571727752685547 - train/lr(1e-3):0.06585560960397507
step:1575 - train/loss:0.5085030198097229 - train/lr(1e-3):0.06580748373488288
step:1576 - train/loss:0.545907735824585 - train/lr(1e-3):0.06575934158930849
step:1577 - train/loss:0.4899032711982727 - train/lr(1e-3):0.0657111832168224
step:1578 - train/loss:0.6538118720054626 - train/lr(1e-3):0.06566300866701179
step:1579 - train/loss:0.5971576571464539 - train/lr(1e-3):0.06561481798948053
step:1580 - train/loss:0.6746687889099121 - train/lr(1e-3):0.06556661123384909
step:1581 - train/loss:0.5920485258102417 - train/lr(1e-3):0.0655183884497545
step:1582 - train/loss:0.4358794093132019 - train/lr(1e-3):0.06547014968685025
step:1583 - train/loss:0.5261735916137695 - train/lr(1e-3):0.06542189499480636
step:1584 - train/loss:0.614787757396698 - train/lr(1e-3):0.06537362442330916
step:1585 - train/loss:0.5723873376846313 - train/lr(1e-3):0.06532533802206143
step:1586 - train/loss:0.6952593326568604 - train/lr(1e-3):0.06527703584078218
step:1587 - train/loss:0.5527967214584351 - train/lr(1e-3):0.0652287179292067
step:1588 - train/loss:0.6492481231689453 - train/lr(1e-3):0.06518038433708644
step:1589 - train/loss:0.6511502861976624 - train/lr(1e-3):0.06513203511418902
step:1590 - train/loss:0.581691324710846 - train/lr(1e-3):0.06508367031029819
step:1591 - train/loss:0.5838700532913208 - train/lr(1e-3):0.06503528997521366
step:1592 - train/loss:0.7333957552909851 - train/lr(1e-3):0.06498689415875121
step:1593 - train/loss:0.5913679003715515 - train/lr(1e-3):0.06493848291074256
step:1594 - train/loss:0.6057541370391846 - train/lr(1e-3):0.06489005628103522
step:1595 - train/loss:0.5717909336090088 - train/lr(1e-3):0.06484161431949266
step:1596 - train/loss:0.5640285015106201 - train/lr(1e-3):0.06479315707599408
step:1597 - train/loss:0.5921192169189453 - train/lr(1e-3):0.0647446846004344
step:1598 - train/loss:0.555232048034668 - train/lr(1e-3):0.06469619694272426
step:1599 - train/loss:0.6126931309700012 - train/lr(1e-3):0.06464769415278991
step:1600 - train/loss:0.5688390731811523 - train/lr(1e-3):0.0645991762805732
step:1601 - train/loss:0.4938276410102844 - train/lr(1e-3):0.06455064337603149
step:1602 - train/loss:0.5574649572372437 - train/lr(1e-3):0.06450209548913761
step:1603 - train/loss:0.5055145025253296 - train/lr(1e-3):0.06445353266987987
step:1604 - train/loss:0.6821654438972473 - train/lr(1e-3):0.06440495496826189
step:1605 - train/loss:0.46607694029808044 - train/lr(1e-3):0.06435636243430265
step:1606 - train/loss:0.6899315118789673 - train/lr(1e-3):0.06430775511803638
step:1607 - train/loss:0.5181825160980225 - train/lr(1e-3):0.06425913306951259
step:1608 - train/loss:0.5900133848190308 - train/lr(1e-3):0.06421049633879589
step:1609 - train/loss:0.6302347183227539 - train/lr(1e-3):0.064161844975966
step:1610 - train/loss:0.5957968235015869 - train/lr(1e-3):0.06411317903111778
step:1611 - train/loss:0.631373941898346 - train/lr(1e-3):0.06406449855436107
step:1612 - train/loss:0.5311979651451111 - train/lr(1e-3):0.06401580359582064
step:1613 - train/loss:0.5303776264190674 - train/lr(1e-3):0.0639670942056362
step:1614 - train/loss:0.522089421749115 - train/lr(1e-3):0.06391837043396234
step:1615 - train/loss:0.6140668392181396 - train/lr(1e-3):0.06386963233096843
step:1616 - train/loss:0.6624407172203064 - train/lr(1e-3):0.06382087994683859
step:1617 - train/loss:0.6828774809837341 - train/lr(1e-3):0.06377211333177166
step:1618 - train/loss:0.5437381267547607 - train/lr(1e-3):0.06372333253598113
step:1619 - train/loss:0.8293316960334778 - train/lr(1e-3):0.0636745376096951
step:1620 - train/loss:0.6858473420143127 - train/lr(1e-3):0.0636257286031562
step:1621 - train/loss:0.6499567031860352 - train/lr(1e-3):0.06357690556662161
step:1622 - train/loss:0.5004206895828247 - train/lr(1e-3):0.06352806855036287
step:1623 - train/loss:0.6306654214859009 - train/lr(1e-3):0.06347921760466599
step:1624 - train/loss:0.4773982763290405 - train/lr(1e-3):0.06343035277983128
step:1625 - train/loss:0.5550387501716614 - train/lr(1e-3):0.06338147412617331
step:1626 - train/loss:0.5053938627243042 - train/lr(1e-3):0.06333258169402106
step:1627 - train/loss:0.5178146362304688 - train/lr(1e-3):0.06328367553371743
step:1628 - train/loss:0.589030385017395 - train/lr(1e-3):0.06323475569561968
step:1629 - train/loss:0.5101335048675537 - train/lr(1e-3):0.06318582223009904
step:1630 - train/loss:0.6299031972885132 - train/lr(1e-3):0.06313687518754081
step:1631 - train/loss:0.5728029608726501 - train/lr(1e-3):0.06308791461834426
step:1632 - train/loss:0.645807147026062 - train/lr(1e-3):0.06303894057292261
step:1633 - train/loss:0.5745749473571777 - train/lr(1e-3):0.0629899531017029
step:1634 - train/loss:0.5918877124786377 - train/lr(1e-3):0.06294095225512604
step:1635 - train/loss:0.5398678183555603 - train/lr(1e-3):0.06289193808364672
step:1636 - train/loss:0.5444843769073486 - train/lr(1e-3):0.0628429106377333
step:1637 - train/loss:0.6075255274772644 - train/lr(1e-3):0.0627938699678679
step:1638 - train/loss:0.6303476095199585 - train/lr(1e-3):0.06274481612454612
step:1639 - train/loss:0.5569658279418945 - train/lr(1e-3):0.06269574915827726
step:1640 - train/loss:0.4788767099380493 - train/lr(1e-3):0.06264666911958404
step:1641 - train/loss:0.5656997561454773 - train/lr(1e-3):0.0625975760590027
step:1642 - train/loss:0.5708433389663696 - train/lr(1e-3):0.06254847002708283
step:1643 - train/loss:0.5511465072631836 - train/lr(1e-3):0.06249935107438743
step:1644 - train/loss:0.6149808168411255 - train/lr(1e-3):0.062450219251492786
step:1645 - train/loss:0.5373661518096924 - train/lr(1e-3):0.06240107460898844
step:1646 - train/loss:0.6717726588249207 - train/lr(1e-3):0.06235191719747708
step:1647 - train/loss:0.48851704597473145 - train/lr(1e-3):0.06230274706757463
step:1648 - train/loss:0.49606603384017944 - train/lr(1e-3):0.06225356426991007
step:1649 - train/loss:0.6277052760124207 - train/lr(1e-3):0.062204368855125404
step:1650 - train/loss:0.5675097703933716 - train/lr(1e-3):0.06215516087387564
step:1651 - train/loss:0.5199432969093323 - train/lr(1e-3):0.06210594037682873
step:1652 - train/loss:0.6553679704666138 - train/lr(1e-3):0.06205670741466555
step:1653 - train/loss:0.611785888671875 - train/lr(1e-3):0.06200746203807972
step:1654 - train/loss:0.5573714971542358 - train/lr(1e-3):0.06195820429777776
step:1655 - train/loss:0.6726742386817932 - train/lr(1e-3):0.06190893424447879
step:1656 - train/loss:0.623259961605072 - train/lr(1e-3):0.06185965192891472
step:1657 - train/loss:0.5612950325012207 - train/lr(1e-3):0.06181035740183003
step:1658 - train/loss:0.7071390748023987 - train/lr(1e-3):0.061761050713981795
step:1659 - train/loss:0.646395742893219 - train/lr(1e-3):0.06171173191613959
step:1660 - train/loss:0.5799109935760498 - train/lr(1e-3):0.06166240105908546
step:1661 - train/loss:0.5334055423736572 - train/lr(1e-3):0.0616130581936139
step:1662 - train/loss:0.46851015090942383 - train/lr(1e-3):0.06156370337053175
step:1663 - train/loss:0.47996535897254944 - train/lr(1e-3):0.06151433664065815
step:1664 - train/loss:0.5991891026496887 - train/lr(1e-3):0.06146495805482451
step:1665 - train/loss:0.5948458313941956 - train/lr(1e-3):0.06141556766387445
step:1666 - train/loss:0.44840207695961 - train/lr(1e-3):0.06136616551866375
step:1667 - train/loss:0.4814755320549011 - train/lr(1e-3):0.061316751670060295
step:1668 - train/loss:0.5548555850982666 - train/lr(1e-3):0.06126732616894397
step:1669 - train/loss:0.6019085645675659 - train/lr(1e-3):0.06121788906620676
step:1670 - train/loss:0.5721442699432373 - train/lr(1e-3):0.061168440412752496
step:1671 - train/loss:0.5546873211860657 - train/lr(1e-3):0.06111898025949697
step:1672 - train/loss:0.5123147964477539 - train/lr(1e-3):0.061069508657367766
step:1673 - train/loss:0.6137588024139404 - train/lr(1e-3):0.06102002565730429
step:1674 - train/loss:0.7349302768707275 - train/lr(1e-3):0.060970531310257654
step:1675 - train/loss:0.5896601676940918 - train/lr(1e-3):0.06092102566719069
step:1676 - train/loss:0.6105650663375854 - train/lr(1e-3):0.060871508779077856
step:1677 - train/loss:0.5790928602218628 - train/lr(1e-3):0.06082198069690515
step:1678 - train/loss:0.5861308574676514 - train/lr(1e-3):0.060772441471670144
step:1679 - train/loss:0.5014201402664185 - train/lr(1e-3):0.060722891154381835
step:1680 - train/loss:0.7188230156898499 - train/lr(1e-3):0.06067332979606069
step:1681 - train/loss:0.5082000494003296 - train/lr(1e-3):0.06062375744773851
step:1682 - train/loss:0.6667864918708801 - train/lr(1e-3):0.060574174160458454
step:1683 - train/loss:0.5477298498153687 - train/lr(1e-3):0.060524579985274884
step:1684 - train/loss:0.5959718823432922 - train/lr(1e-3):0.06047497497325341
step:1685 - train/loss:0.631942629814148 - train/lr(1e-3):0.060425359175470796
step:1686 - train/loss:0.5446823835372925 - train/lr(1e-3):0.06037573264301492
step:1687 - train/loss:0.46398407220840454 - train/lr(1e-3):0.06032609542698467
step:1688 - train/loss:0.593817949295044 - train/lr(1e-3):0.06027644757849004
step:1689 - train/loss:0.713394284248352 - train/lr(1e-3):0.06022678914865183
step:1690 - train/loss:0.5327290296554565 - train/lr(1e-3):0.060177120188601815
step:1691 - train/loss:0.6139445304870605 - train/lr(1e-3):0.06012744074948264
step:1692 - train/loss:0.5599365234375 - train/lr(1e-3):0.06007775088244769
step:1693 - train/loss:0.6283595561981201 - train/lr(1e-3):0.06002805063866108
step:1694 - train/loss:0.7227662205696106 - train/lr(1e-3):0.05997834006929765
step:1695 - train/loss:0.5581825971603394 - train/lr(1e-3):0.05992861922554282
step:1696 - train/loss:0.663705587387085 - train/lr(1e-3):0.059878888158592665
step:1697 - train/loss:0.5907659530639648 - train/lr(1e-3):0.05982914691965371
step:1698 - train/loss:0.6464618444442749 - train/lr(1e-3):0.05977939555994301
step:1699 - train/loss:0.5718342065811157 - train/lr(1e-3):0.05972963413068799
step:1700 - train/loss:0.5282511711120605 - train/lr(1e-3):0.05967986268312651
step:1701 - train/loss:0.529068648815155 - train/lr(1e-3):0.05963008126850666
step:1702 - train/loss:0.5470805168151855 - train/lr(1e-3):0.059580289938086874
step:1703 - train/loss:0.5439798831939697 - train/lr(1e-3):0.05953048874313575
step:1704 - train/loss:0.6079040765762329 - train/lr(1e-3):0.05948067773493204
step:1705 - train/loss:0.47968512773513794 - train/lr(1e-3):0.05943085696476465
step:1706 - train/loss:0.6955581903457642 - train/lr(1e-3):0.05938102648393247
step:1707 - train/loss:0.550984263420105 - train/lr(1e-3):0.05933118634374443
step:1708 - train/loss:0.6106907725334167 - train/lr(1e-3):0.05928133659551939
step:1709 - train/loss:0.5174410343170166 - train/lr(1e-3):0.05923147729058612
step:1710 - train/loss:0.6266653537750244 - train/lr(1e-3):0.05918160848028324
step:1711 - train/loss:0.5904145240783691 - train/lr(1e-3):0.05913173021595909
step:1712 - train/loss:0.5265432596206665 - train/lr(1e-3):0.05908184254897182
step:1713 - train/loss:0.6451787352561951 - train/lr(1e-3):0.059031945530689245
step:1714 - train/loss:0.5514665842056274 - train/lr(1e-3):0.05898203921248877
step:1715 - train/loss:0.6375654339790344 - train/lr(1e-3):0.05893212364575743
step:1716 - train/loss:0.5792224407196045 - train/lr(1e-3):0.05888219888189176
step:1717 - train/loss:0.5136211514472961 - train/lr(1e-3):0.05883226497229773
step:1718 - train/loss:0.5687434077262878 - train/lr(1e-3):0.05878232196839076
step:1719 - train/loss:0.5769296884536743 - train/lr(1e-3):0.058732369921595674
step:1720 - train/loss:0.5212748050689697 - train/lr(1e-3):0.05868240888334653
Saving checkpoint to: /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_1720
Checkpoint manager remove previous save local path: /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_860
[2025-08-23 21:50:18,003][/home/Competition2025/P07/shareP07/share_env/deps/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved model to /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_1720/model_world_size_24_rank_0.pt
[2025-08-23 21:50:25,047][/home/Competition2025/P07/shareP07/share_env/deps/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved optim to /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_1720/optim_world_size_24_rank_0.pt
[2025-08-23 21:50:25,049][/home/Competition2025/P07/shareP07/share_env/deps/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved extra_state to /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_1720/extra_state_world_size_24_rank_0.pt
[2025-08-23 21:50:25,483][/home/Competition2025/P07/shareP07/share_env/deps/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved model config and tokenizer class to /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_1720/huggingface
[2025-08-23 21:52:18,903][/home/Competition2025/P07/shareP07/share_env/deps/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved hf_model to /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_1720/huggingface
Saved dataloader state to: /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_1720/data.pt
Updated checkpoint tracker: /home/Competition2025/P07/shareP07/share_model/step3_sft/latest_checkpointed_iteration.txt
step:1721 - train/loss:0.6022412776947021 - train/lr(1e-3):0.05863243890508668
step:1722 - train/loss:0.5571638345718384 - train/lr(1e-3):0.05858246003826869
step:1723 - train/loss:0.5172487497329712 - train/lr(1e-3):0.05853247233435428
step:1724 - train/loss:0.5115312337875366 - train/lr(1e-3):0.05848247584481424
step:1725 - train/loss:0.5629060864448547 - train/lr(1e-3):0.058432470621128434
step:1726 - train/loss:0.5156160593032837 - train/lr(1e-3):0.058382456714785716
step:1727 - train/loss:0.6544135808944702 - train/lr(1e-3):0.05833243417728387
step:1728 - train/loss:0.628994882106781 - train/lr(1e-3):0.058282403060129565
step:1729 - train/loss:0.4987024664878845 - train/lr(1e-3):0.058232363414838326
step:1730 - train/loss:0.5687477588653564 - train/lr(1e-3):0.058182315292934404
step:1731 - train/loss:0.6005886793136597 - train/lr(1e-3):0.05813225874595087
step:1732 - train/loss:0.6652461290359497 - train/lr(1e-3):0.05808219382542941
step:1733 - train/loss:0.49012452363967896 - train/lr(1e-3):0.05803212058292033
step:1734 - train/loss:0.6107600927352905 - train/lr(1e-3):0.05798203906998249
step:1735 - train/loss:0.5547720789909363 - train/lr(1e-3):0.05793194933818333
step:1736 - train/loss:0.5256243944168091 - train/lr(1e-3):0.05788185143909868
step:1737 - train/loss:0.5116625428199768 - train/lr(1e-3):0.057831745424312846
step:1738 - train/loss:0.621931791305542 - train/lr(1e-3):0.05778163134541845
step:1739 - train/loss:0.6393753886222839 - train/lr(1e-3):0.05773150925401641
step:1740 - train/loss:0.6525033116340637 - train/lr(1e-3):0.05768137920171593
step:1741 - train/loss:0.5988021492958069 - train/lr(1e-3):0.05763124124013437
step:1742 - train/loss:0.5246235132217407 - train/lr(1e-3):0.057581095420897246
step:1743 - train/loss:0.5303626656532288 - train/lr(1e-3):0.05753094179563822
step:1744 - train/loss:0.5905961394309998 - train/lr(1e-3):0.057480780415998904
step:1745 - train/loss:0.5518561005592346 - train/lr(1e-3):0.057430611333628936
step:1746 - train/loss:0.595641553401947 - train/lr(1e-3):0.05738043460018592
step:1747 - train/loss:0.5309205651283264 - train/lr(1e-3):0.05733025026733526
step:1748 - train/loss:0.6348141431808472 - train/lr(1e-3):0.05728005838675026
step:1749 - train/loss:0.559912919998169 - train/lr(1e-3):0.057229859010111926
step:1750 - train/loss:0.5593538284301758 - train/lr(1e-3):0.05717965218910907
step:1751 - train/loss:0.579409122467041 - train/lr(1e-3):0.05712943797543808
step:1752 - train/loss:0.537723958492279 - train/lr(1e-3):0.05707921642080299
step:1753 - train/loss:0.48830699920654297 - train/lr(1e-3):0.057028987576915435
step:1754 - train/loss:0.5628410577774048 - train/lr(1e-3):0.0569787514954945
step:1755 - train/loss:0.4590601325035095 - train/lr(1e-3):0.05692850822826674
step:1756 - train/loss:0.5936954617500305 - train/lr(1e-3):0.056878257826966094
step:1757 - train/loss:0.5969487428665161 - train/lr(1e-3):0.0568280003433339
step:1758 - train/loss:0.582192063331604 - train/lr(1e-3):0.05677773582911869
step:1759 - train/loss:0.6025675535202026 - train/lr(1e-3):0.056727464336076366
step:1760 - train/loss:0.5476900935173035 - train/lr(1e-3):0.0566771859159699
step:1761 - train/loss:0.6582174301147461 - train/lr(1e-3):0.05662690062056946
step:1762 - train/loss:0.5717620849609375 - train/lr(1e-3):0.056576608501652276
step:1763 - train/loss:0.6175376772880554 - train/lr(1e-3):0.05652630961100259
step:1764 - train/loss:0.6656867265701294 - train/lr(1e-3):0.056476004000411625
step:1765 - train/loss:0.5038026571273804 - train/lr(1e-3):0.056425691721677565
step:1766 - train/loss:0.6430233716964722 - train/lr(1e-3):0.056375372826605395
step:1767 - train/loss:0.46405118703842163 - train/lr(1e-3):0.05632504736700694
step:1768 - train/loss:0.6137585043907166 - train/lr(1e-3):0.0562747153947008
step:1769 - train/loss:0.66921067237854 - train/lr(1e-3):0.05622437696151227
step:1770 - train/loss:0.49425119161605835 - train/lr(1e-3):0.056174032119273264
step:1771 - train/loss:0.6461854577064514 - train/lr(1e-3):0.05612368091982235
step:1772 - train/loss:0.6249338984489441 - train/lr(1e-3):0.056073323415004636
step:1773 - train/loss:0.467088520526886 - train/lr(1e-3):0.05602295965667163
step:1774 - train/loss:0.6047179102897644 - train/lr(1e-3):0.055972589696681445
step:1775 - train/loss:0.5615150928497314 - train/lr(1e-3):0.05592221358689843
step:1776 - train/loss:0.5987203121185303 - train/lr(1e-3):0.05587183137919332
step:1777 - train/loss:0.5838750600814819 - train/lr(1e-3):0.055821443125443175
step:1778 - train/loss:0.4308520555496216 - train/lr(1e-3):0.055771048877531204
step:1779 - train/loss:0.6096262335777283 - train/lr(1e-3):0.05572064868734682
step:1780 - train/loss:0.6097298860549927 - train/lr(1e-3):0.05567024260678558
step:1781 - train/loss:0.5865130424499512 - train/lr(1e-3):0.05561983068774907
step:1782 - train/loss:0.5320359468460083 - train/lr(1e-3):0.055569412982144885
step:1783 - train/loss:0.5581849813461304 - train/lr(1e-3):0.05551898954188662
step:1784 - train/loss:0.6595450639724731 - train/lr(1e-3):0.05546856041889373
step:1785 - train/loss:0.5569806098937988 - train/lr(1e-3):0.05541812566509155
step:1786 - train/loss:0.6131623983383179 - train/lr(1e-3):0.055367685332411175
step:1787 - train/loss:0.710496723651886 - train/lr(1e-3):0.05531723947278952
step:1788 - train/loss:0.4946240782737732 - train/lr(1e-3):0.05526678813816911
step:1789 - train/loss:0.6885620355606079 - train/lr(1e-3):0.05521633138049814
step:1790 - train/loss:0.5622667074203491 - train/lr(1e-3):0.05516586925173041
step:1791 - train/loss:0.6087731122970581 - train/lr(1e-3):0.05511540180382521
step:1792 - train/loss:0.5943930149078369 - train/lr(1e-3):0.055064929088747314
step:1793 - train/loss:0.6319975852966309 - train/lr(1e-3):0.055014451158466975
step:1794 - train/loss:0.6864739060401917 - train/lr(1e-3):0.05496396806495974
step:1795 - train/loss:0.6468446254730225 - train/lr(1e-3):0.05491347986020652
step:1796 - train/loss:0.6103042364120483 - train/lr(1e-3):0.05486298659619345
step:1797 - train/loss:0.5339202284812927 - train/lr(1e-3):0.05481248832491194
step:1798 - train/loss:0.41566115617752075 - train/lr(1e-3):0.054761985098358466
step:1799 - train/loss:0.6018222570419312 - train/lr(1e-3):0.05471147696853469
step:1800 - train/loss:0.6343649625778198 - train/lr(1e-3):0.054660963987447304
step:1801 - train/loss:0.5725686550140381 - train/lr(1e-3):0.054610446207107914
step:1802 - train/loss:0.5208224058151245 - train/lr(1e-3):0.054559923679533176
step:1803 - train/loss:0.5434156060218811 - train/lr(1e-3):0.0545093964567446
step:1804 - train/loss:0.5498843789100647 - train/lr(1e-3):0.05445886459076848
step:1805 - train/loss:0.5518325567245483 - train/lr(1e-3):0.05440832813363599
step:1806 - train/loss:0.46022850275039673 - train/lr(1e-3):0.054357787137382915
step:1807 - train/loss:0.44180387258529663 - train/lr(1e-3):0.0543072416540498
step:1808 - train/loss:0.5203184485435486 - train/lr(1e-3):0.05425669173568179
step:1809 - train/loss:0.6598832607269287 - train/lr(1e-3):0.054206137434328575
step:1810 - train/loss:0.5500485897064209 - train/lr(1e-3):0.05415557880204436
step:1811 - train/loss:0.5448423624038696 - train/lr(1e-3):0.054105015890887856
step:1812 - train/loss:0.5492093563079834 - train/lr(1e-3):0.054054448752922125
step:1813 - train/loss:0.5073611736297607 - train/lr(1e-3):0.0540038774402146
step:1814 - train/loss:0.6339088678359985 - train/lr(1e-3):0.053953302004837
step:1815 - train/loss:0.6814321279525757 - train/lr(1e-3):0.05390272249886534
step:1816 - train/loss:0.7052123546600342 - train/lr(1e-3):0.05385213897437975
step:1817 - train/loss:0.5235260725021362 - train/lr(1e-3):0.05380155148346456
step:1818 - train/loss:0.5378803014755249 - train/lr(1e-3):0.05375096007820817
step:1819 - train/loss:0.48903191089630127 - train/lr(1e-3):0.05370036481070297
step:1820 - train/loss:0.47474926710128784 - train/lr(1e-3):0.053649765733045376
step:1821 - train/loss:0.6031826138496399 - train/lr(1e-3):0.053599162897335725
step:1822 - train/loss:0.5796387791633606 - train/lr(1e-3):0.05354855635567818
step:1823 - train/loss:0.46522054076194763 - train/lr(1e-3):0.05349794616018077
step:1824 - train/loss:0.515924870967865 - train/lr(1e-3):0.05344733236295525
step:1825 - train/loss:0.5739721655845642 - train/lr(1e-3):0.053396715016117105
step:1826 - train/loss:0.5183110237121582 - train/lr(1e-3):0.05334609417178546
step:1827 - train/loss:0.5232234001159668 - train/lr(1e-3):0.053295469882083064
step:1828 - train/loss:0.4631664752960205 - train/lr(1e-3):0.0532448421991362
step:1829 - train/loss:0.5299897193908691 - train/lr(1e-3):0.05319421117507462
step:1830 - train/loss:0.5752779841423035 - train/lr(1e-3):0.053143576862031555
step:1831 - train/loss:0.4825808107852936 - train/lr(1e-3):0.053092939312143594
step:1832 - train/loss:0.6546069383621216 - train/lr(1e-3):0.053042298577550696
step:1833 - train/loss:0.6292152404785156 - train/lr(1e-3):0.05299165471039607
step:1834 - train/loss:0.6407644748687744 - train/lr(1e-3):0.052941007762826155
step:1835 - train/loss:0.5804076790809631 - train/lr(1e-3):0.05289035778699053
step:1836 - train/loss:0.8014764189720154 - train/lr(1e-3):0.05283970483504198
step:1837 - train/loss:0.6239749789237976 - train/lr(1e-3):0.052789048959136255
step:1838 - train/loss:0.5253104567527771 - train/lr(1e-3):0.05273839021143218
step:1839 - train/loss:0.5869712233543396 - train/lr(1e-3):0.052687728644091526
step:1840 - train/loss:0.5611031651496887 - train/lr(1e-3):0.05263706430927895
step:1841 - train/loss:0.4432376027107239 - train/lr(1e-3):0.05258639725916195
step:1842 - train/loss:0.6636154651641846 - train/lr(1e-3):0.05253572754591085
step:1843 - train/loss:0.7155724167823792 - train/lr(1e-3):0.05248505522169871
step:1844 - train/loss:0.6213009357452393 - train/lr(1e-3):0.052434380338701264
step:1845 - train/loss:0.5545631647109985 - train/lr(1e-3):0.052383702949096875
step:1846 - train/loss:0.6037856340408325 - train/lr(1e-3):0.05233302310506653
step:1847 - train/loss:0.48888200521469116 - train/lr(1e-3):0.0522823408587937
step:1848 - train/loss:0.438228964805603 - train/lr(1e-3):0.05223165626246432
step:1849 - train/loss:0.616161584854126 - train/lr(1e-3):0.05218096936826681
step:1850 - train/loss:0.5874024033546448 - train/lr(1e-3):0.05213028022839188
step:1851 - train/loss:0.6068904995918274 - train/lr(1e-3):0.05207958889503259
step:1852 - train/loss:0.5325132012367249 - train/lr(1e-3):0.05202889542038428
step:1853 - train/loss:0.6093363761901855 - train/lr(1e-3):0.05197819985664444
step:1854 - train/loss:0.44288599491119385 - train/lr(1e-3):0.05192750225601275
step:1855 - train/loss:0.4713551104068756 - train/lr(1e-3):0.05187680267069098
step:1856 - train/loss:0.5569374561309814 - train/lr(1e-3):0.051826101152882956
step:1857 - train/loss:0.7055086493492126 - train/lr(1e-3):0.051775397754794436
step:1858 - train/loss:0.5787429809570312 - train/lr(1e-3):0.05172469252863321
step:1859 - train/loss:0.5668342113494873 - train/lr(1e-3):0.05167398552660886
step:1860 - train/loss:0.5334818363189697 - train/lr(1e-3):0.05162327680093284
step:1861 - train/loss:0.4218137562274933 - train/lr(1e-3):0.051572566403818396
step:1862 - train/loss:0.5273737907409668 - train/lr(1e-3):0.05152185438748045
step:1863 - train/loss:0.49183499813079834 - train/lr(1e-3):0.051471140804135604
step:1864 - train/loss:0.6156054139137268 - train/lr(1e-3):0.05142042570600212
step:1865 - train/loss:0.5318864583969116 - train/lr(1e-3):0.05136970914529975
step:1866 - train/loss:0.4400181174278259 - train/lr(1e-3):0.051318991174249776
step:1867 - train/loss:0.6018975973129272 - train/lr(1e-3):0.051268271845074986
step:1868 - train/loss:0.7679834365844727 - train/lr(1e-3):0.05121755120999949
step:1869 - train/loss:0.5956899523735046 - train/lr(1e-3):0.051166829321248754
step:1870 - train/loss:0.5177040696144104 - train/lr(1e-3):0.051116106231049604
step:1871 - train/loss:0.5666958093643188 - train/lr(1e-3):0.051065381991630014
step:1872 - train/loss:0.6463979482650757 - train/lr(1e-3):0.0510146566552192
step:1873 - train/loss:0.4798923134803772 - train/lr(1e-3):0.05096393027404748
step:1874 - train/loss:0.4430629014968872 - train/lr(1e-3):0.05091320290034625
step:1875 - train/loss:0.5170986652374268 - train/lr(1e-3):0.05086247458634795
step:1876 - train/loss:0.6459065079689026 - train/lr(1e-3):0.050811745384285956
step:1877 - train/loss:0.5602028369903564 - train/lr(1e-3):0.050761015346394586
step:1878 - train/loss:0.4667232930660248 - train/lr(1e-3):0.05071028452490901
step:1879 - train/loss:0.45265108346939087 - train/lr(1e-3):0.0506595529720652
step:1880 - train/loss:0.5282778739929199 - train/lr(1e-3):0.05060882074009988
step:1881 - train/loss:0.5972089767456055 - train/lr(1e-3):0.05055808788125048
step:1882 - train/loss:0.4970286786556244 - train/lr(1e-3):0.050507354447755066
step:1883 - train/loss:0.6326708793640137 - train/lr(1e-3):0.05045662049185229
step:1884 - train/loss:0.594252347946167 - train/lr(1e-3):0.05040588606578139
step:1885 - train/loss:0.5488981604576111 - train/lr(1e-3):0.050355151221782024
step:1886 - train/loss:0.6593692302703857 - train/lr(1e-3):0.05030441601209431
step:1887 - train/loss:0.6190692782402039 - train/lr(1e-3):0.05025368048895876
step:1888 - train/loss:0.5922461748123169 - train/lr(1e-3):0.05020294470461615
step:1889 - train/loss:0.532987117767334 - train/lr(1e-3):0.0501522087113076
step:1890 - train/loss:0.6804763078689575 - train/lr(1e-3):0.050101472561274424
step:1891 - train/loss:0.4644474387168884 - train/lr(1e-3):0.05005073630675802
step:1892 - train/loss:0.5967770218849182 - train/lr(1e-3):0.05
step:1893 - train/loss:0.6473749279975891 - train/lr(1e-3):0.049949263693241985
step:1894 - train/loss:0.547203779220581 - train/lr(1e-3):0.0498985274387256
step:1895 - train/loss:0.6680879592895508 - train/lr(1e-3):0.049847791288692406
step:1896 - train/loss:0.5552083253860474 - train/lr(1e-3):0.04979705529538385
step:1897 - train/loss:0.5813056230545044 - train/lr(1e-3):0.04974631951104127
step:1898 - train/loss:0.589031994342804 - train/lr(1e-3):0.049695583987905696
step:1899 - train/loss:0.5377619862556458 - train/lr(1e-3):0.049644848778217975
step:1900 - train/loss:0.6170732975006104 - train/lr(1e-3):0.04959411393421862
step:1901 - train/loss:0.5572085380554199 - train/lr(1e-3):0.04954337950814772
step:1902 - train/loss:0.5127958059310913 - train/lr(1e-3):0.04949264555224494
step:1903 - train/loss:0.5653839111328125 - train/lr(1e-3):0.049441912118749536
step:1904 - train/loss:0.5652170777320862 - train/lr(1e-3):0.04939117925990012
step:1905 - train/loss:0.524205207824707 - train/lr(1e-3):0.049340447027934796
step:1906 - train/loss:0.530120313167572 - train/lr(1e-3):0.049289715475091
step:1907 - train/loss:0.5176635980606079 - train/lr(1e-3):0.04923898465360542
step:1908 - train/loss:0.6257575154304504 - train/lr(1e-3):0.04918825461571405
step:1909 - train/loss:0.5689921379089355 - train/lr(1e-3):0.04913752541365207
step:1910 - train/loss:0.5150920152664185 - train/lr(1e-3):0.04908679709965376
step:1911 - train/loss:0.4946313202381134 - train/lr(1e-3):0.04903606972595254
step:1912 - train/loss:0.5176321268081665 - train/lr(1e-3):0.048985343344780816
step:1913 - train/loss:0.567987322807312 - train/lr(1e-3):0.04893461800837
step:1914 - train/loss:0.5108946561813354 - train/lr(1e-3):0.0488838937689504
step:1915 - train/loss:0.526124119758606 - train/lr(1e-3):0.048833170678751245
step:1916 - train/loss:0.48393237590789795 - train/lr(1e-3):0.04878244879000052
step:1917 - train/loss:0.4959128201007843 - train/lr(1e-3):0.04873172815492502
step:1918 - train/loss:0.5580992102622986 - train/lr(1e-3):0.04868100882575023
step:1919 - train/loss:0.6307522654533386 - train/lr(1e-3):0.04863029085470026
step:1920 - train/loss:0.5318865776062012 - train/lr(1e-3):0.04857957429399788
step:1921 - train/loss:0.4365357756614685 - train/lr(1e-3):0.0485288591958644
step:1922 - train/loss:0.6486765146255493 - train/lr(1e-3):0.04847814561251955
step:1923 - train/loss:0.5183697938919067 - train/lr(1e-3):0.04842743359618161
step:1924 - train/loss:0.5533573627471924 - train/lr(1e-3):0.048376723199067176
step:1925 - train/loss:0.52305668592453 - train/lr(1e-3):0.04832601447339115
step:1926 - train/loss:0.5943049192428589 - train/lr(1e-3):0.04827530747136682
step:1927 - train/loss:0.5756702423095703 - train/lr(1e-3):0.04822460224520557
step:1928 - train/loss:0.5919240713119507 - train/lr(1e-3):0.04817389884711705
step:1929 - train/loss:0.5476666688919067 - train/lr(1e-3):0.04812319732930903
step:1930 - train/loss:0.505878210067749 - train/lr(1e-3):0.048072497743987266
step:1931 - train/loss:0.6555471420288086 - train/lr(1e-3):0.04802180014335557
step:1932 - train/loss:0.6122751235961914 - train/lr(1e-3):0.047971104579615745
step:1933 - train/loss:0.5650734901428223 - train/lr(1e-3):0.04792041110496742
step:1934 - train/loss:0.4657664895057678 - train/lr(1e-3):0.04786971977160813
step:1935 - train/loss:0.5042410492897034 - train/lr(1e-3):0.04781903063173321
step:1936 - train/loss:0.5295107960700989 - train/lr(1e-3):0.04776834373753569
step:1937 - train/loss:0.6511818170547485 - train/lr(1e-3):0.047717659141206306
step:1938 - train/loss:0.5308256149291992 - train/lr(1e-3):0.04766697689493349
step:1939 - train/loss:0.5548463463783264 - train/lr(1e-3):0.04761629705090313
step:1940 - train/loss:0.4419228434562683 - train/lr(1e-3):0.047565619661298755
step:1941 - train/loss:0.5728359222412109 - train/lr(1e-3):0.04751494477830132
step:1942 - train/loss:0.5852347016334534 - train/lr(1e-3):0.04746427245408917
step:1943 - train/loss:0.7011093497276306 - train/lr(1e-3):0.04741360274083806
step:1944 - train/loss:0.5276433229446411 - train/lr(1e-3):0.04736293569072108
step:1945 - train/loss:0.604284405708313 - train/lr(1e-3):0.04731227135590848
step:1946 - train/loss:0.5328425168991089 - train/lr(1e-3):0.04726160978856782
step:1947 - train/loss:0.5074791312217712 - train/lr(1e-3):0.04721095104086376
step:1948 - train/loss:0.5448664426803589 - train/lr(1e-3):0.04716029516495804
step:1949 - train/loss:0.5519965887069702 - train/lr(1e-3):0.047109642213009464
step:1950 - train/loss:0.5935475826263428 - train/lr(1e-3):0.04705899223717387
step:1951 - train/loss:0.6264352798461914 - train/lr(1e-3):0.047008345289603945
step:1952 - train/loss:0.4603916108608246 - train/lr(1e-3):0.04695770142244931
step:1953 - train/loss:0.5801801085472107 - train/lr(1e-3):0.04690706068785642
step:1954 - train/loss:0.5508809089660645 - train/lr(1e-3):0.046856423137968464
step:1955 - train/loss:0.530241072177887 - train/lr(1e-3):0.046805788824925386
step:1956 - train/loss:0.7013550996780396 - train/lr(1e-3):0.046755157800863825
step:1957 - train/loss:0.603065013885498 - train/lr(1e-3):0.04670453011791695
step:1958 - train/loss:0.5616065263748169 - train/lr(1e-3):0.046653905828214534
step:1959 - train/loss:0.6014145612716675 - train/lr(1e-3):0.046603284983882914
step:1960 - train/loss:0.5851720571517944 - train/lr(1e-3):0.04655266763704476
step:1961 - train/loss:0.5306658744812012 - train/lr(1e-3):0.04650205383981923
step:1962 - train/loss:0.6283290386199951 - train/lr(1e-3):0.04645144364432183
step:1963 - train/loss:0.49371138215065 - train/lr(1e-3):0.04640083710266429
step:1964 - train/loss:0.48213696479797363 - train/lr(1e-3):0.04635023426695463
step:1965 - train/loss:0.6262847185134888 - train/lr(1e-3):0.04629963518929705
step:1966 - train/loss:0.5358268022537231 - train/lr(1e-3):0.04624903992179185
step:1967 - train/loss:0.533690869808197 - train/lr(1e-3):0.04619844851653545
step:1968 - train/loss:0.4901755452156067 - train/lr(1e-3):0.04614786102562026
step:1969 - train/loss:0.6411462426185608 - train/lr(1e-3):0.046097277501134674
step:1970 - train/loss:0.7099994421005249 - train/lr(1e-3):0.046046697995163005
step:1971 - train/loss:0.5221425890922546 - train/lr(1e-3):0.04599612255978543
step:1972 - train/loss:0.5659375190734863 - train/lr(1e-3):0.04594555124707789
step:1973 - train/loss:0.5312066078186035 - train/lr(1e-3):0.04589498410911215
step:1974 - train/loss:0.47205185890197754 - train/lr(1e-3):0.04584442119795565
step:1975 - train/loss:0.5102793574333191 - train/lr(1e-3):0.045793862565671445
step:1976 - train/loss:0.4969032406806946 - train/lr(1e-3):0.04574330826431821
step:1977 - train/loss:0.5878573060035706 - train/lr(1e-3):0.045692758345950206
step:1978 - train/loss:0.4899475872516632 - train/lr(1e-3):0.04564221286261709
step:1979 - train/loss:0.6345201134681702 - train/lr(1e-3):0.04559167186636403
step:1980 - train/loss:0.5852380394935608 - train/lr(1e-3):0.04554113540923153
step:1981 - train/loss:0.5571070909500122 - train/lr(1e-3):0.04549060354325542
step:1982 - train/loss:0.5254045724868774 - train/lr(1e-3):0.04544007632046682
step:1983 - train/loss:0.4694754481315613 - train/lr(1e-3):0.0453895537928921
step:1984 - train/loss:0.5330520272254944 - train/lr(1e-3):0.045339036012552715
step:1985 - train/loss:0.436988890171051 - train/lr(1e-3):0.045288523031465314
step:1986 - train/loss:0.6557872295379639 - train/lr(1e-3):0.045238014901641546
step:1987 - train/loss:0.5254492163658142 - train/lr(1e-3):0.045187511675088075
step:1988 - train/loss:0.551329493522644 - train/lr(1e-3):0.04513701340380655
step:1989 - train/loss:0.5003557205200195 - train/lr(1e-3):0.045086520139793494
step:1990 - train/loss:0.5259920954704285 - train/lr(1e-3):0.045036031935040265
step:1991 - train/loss:0.5305482149124146 - train/lr(1e-3):0.04498554884153304
step:1992 - train/loss:0.6366435289382935 - train/lr(1e-3):0.04493507091125269
step:1993 - train/loss:0.5339456796646118 - train/lr(1e-3):0.0448845981961748
step:1994 - train/loss:0.3910147547721863 - train/lr(1e-3):0.04483413074826962
step:1995 - train/loss:0.5659238696098328 - train/lr(1e-3):0.044783668619501865
step:1996 - train/loss:0.6127614974975586 - train/lr(1e-3):0.0447332118618309
step:1997 - train/loss:0.5701451301574707 - train/lr(1e-3):0.044682760527210506
step:1998 - train/loss:0.5238788723945618 - train/lr(1e-3):0.04463231466758883
step:1999 - train/loss:0.5924211144447327 - train/lr(1e-3):0.04458187433490846
step:2000 - train/loss:0.5008456707000732 - train/lr(1e-3):0.044531439581106294
step:2001 - train/loss:0.5294398069381714 - train/lr(1e-3):0.04448101045811339
step:2002 - train/loss:0.5144513249397278 - train/lr(1e-3):0.04443058701785512
step:2003 - train/loss:0.5217152833938599 - train/lr(1e-3):0.04438016931225096
step:2004 - train/loss:0.5662215948104858 - train/lr(1e-3):0.04432975739321443
step:2005 - train/loss:0.5009143948554993 - train/lr(1e-3):0.044279351312653176
step:2006 - train/loss:0.5786371231079102 - train/lr(1e-3):0.044228951122468815
step:2007 - train/loss:0.5112196207046509 - train/lr(1e-3):0.04417855687455683
step:2008 - train/loss:0.5777742862701416 - train/lr(1e-3):0.04412816862080668
step:2009 - train/loss:0.5490713715553284 - train/lr(1e-3):0.044077786413101595
step:2010 - train/loss:0.5200605392456055 - train/lr(1e-3):0.04402741030331857
step:2011 - train/loss:0.5760632157325745 - train/lr(1e-3):0.04397704034332836
step:2012 - train/loss:0.5716409683227539 - train/lr(1e-3):0.04392667658499539
step:2013 - train/loss:0.6559758186340332 - train/lr(1e-3):0.04387631908017765
step:2014 - train/loss:0.3810942471027374 - train/lr(1e-3):0.04382596788072674
step:2015 - train/loss:0.5774316191673279 - train/lr(1e-3):0.043775623038487754
step:2016 - train/loss:0.6341371536254883 - train/lr(1e-3):0.0437252846052992
step:2017 - train/loss:0.6125173568725586 - train/lr(1e-3):0.04367495263299305
step:2018 - train/loss:0.5549889802932739 - train/lr(1e-3):0.04362462717339461
step:2019 - train/loss:0.6413644552230835 - train/lr(1e-3):0.04357430827832245
step:2020 - train/loss:0.6087734699249268 - train/lr(1e-3):0.04352399599958837
step:2021 - train/loss:0.5479030013084412 - train/lr(1e-3):0.04347369038899744
step:2022 - train/loss:0.548200786113739 - train/lr(1e-3):0.04342339149834774
step:2023 - train/loss:0.6287685632705688 - train/lr(1e-3):0.04337309937943055
step:2024 - train/loss:0.5500209331512451 - train/lr(1e-3):0.04332281408403011
step:2025 - train/loss:0.6847038269042969 - train/lr(1e-3):0.043272535663923646
step:2026 - train/loss:0.6279501914978027 - train/lr(1e-3):0.043222264170881305
step:2027 - train/loss:0.44335395097732544 - train/lr(1e-3):0.043171999656666134
step:2028 - train/loss:0.5678125619888306 - train/lr(1e-3):0.04312174217303391
step:2029 - train/loss:0.49921494722366333 - train/lr(1e-3):0.04307149177173328
step:2030 - train/loss:0.5134639739990234 - train/lr(1e-3):0.043021248504505505
step:2031 - train/loss:0.5634137392044067 - train/lr(1e-3):0.04297101242308457
step:2032 - train/loss:0.5504109859466553 - train/lr(1e-3):0.04292078357919701
step:2033 - train/loss:0.4553842544555664 - train/lr(1e-3):0.042870562024561944
step:2034 - train/loss:0.6202750205993652 - train/lr(1e-3):0.04282034781089094
step:2035 - train/loss:0.535209059715271 - train/lr(1e-3):0.04277014098988808
step:2036 - train/loss:0.5737775564193726 - train/lr(1e-3):0.04271994161324977
step:2037 - train/loss:0.49362659454345703 - train/lr(1e-3):0.042669749732664755
step:2038 - train/loss:0.5741305947303772 - train/lr(1e-3):0.04261956539981408
step:2039 - train/loss:0.5707094669342041 - train/lr(1e-3):0.04256938866637106
step:2040 - train/loss:0.5594459772109985 - train/lr(1e-3):0.0425192195840011
step:2041 - train/loss:0.5601193904876709 - train/lr(1e-3):0.04246905820436179
step:2042 - train/loss:0.4903663992881775 - train/lr(1e-3):0.042418904579102766
step:2043 - train/loss:0.6015441417694092 - train/lr(1e-3):0.04236875875986565
step:2044 - train/loss:0.5341727137565613 - train/lr(1e-3):0.04231862079828407
step:2045 - train/loss:0.6064081192016602 - train/lr(1e-3):0.0422684907459836
step:2046 - train/loss:0.5892669558525085 - train/lr(1e-3):0.04221836865458156
step:2047 - train/loss:0.6482659578323364 - train/lr(1e-3):0.04216825457568715
step:2048 - train/loss:0.6230836510658264 - train/lr(1e-3):0.042118148560901326
step:2049 - train/loss:0.5496267080307007 - train/lr(1e-3):0.04206805066181669
step:2050 - train/loss:0.40181633830070496 - train/lr(1e-3):0.042017960930017514
step:2051 - train/loss:0.5126215815544128 - train/lr(1e-3):0.04196787941707969
step:2052 - train/loss:0.46073979139328003 - train/lr(1e-3):0.0419178061745706
step:2053 - train/loss:0.6442291736602783 - train/lr(1e-3):0.04186774125404912
step:2054 - train/loss:0.5024219751358032 - train/lr(1e-3):0.04181768470706561
step:2055 - train/loss:0.569466233253479 - train/lr(1e-3):0.04176763658516169
step:2056 - train/loss:0.6000574827194214 - train/lr(1e-3):0.04171759693987046
step:2057 - train/loss:0.516338586807251 - train/lr(1e-3):0.04166756582271614
step:2058 - train/loss:0.6137933731079102 - train/lr(1e-3):0.04161754328521429
step:2059 - train/loss:0.5505079030990601 - train/lr(1e-3):0.041567529378871586
step:2060 - train/loss:0.5734720230102539 - train/lr(1e-3):0.04151752415518577
step:2061 - train/loss:0.439876526594162 - train/lr(1e-3):0.04146752766564573
step:2062 - train/loss:0.6061263084411621 - train/lr(1e-3):0.04141753996173132
step:2063 - train/loss:0.6292731165885925 - train/lr(1e-3):0.04136756109491334
step:2064 - train/loss:0.5549473166465759 - train/lr(1e-3):0.041317591116653486
step:2065 - train/loss:0.48352286219596863 - train/lr(1e-3):0.04126763007840435
step:2066 - train/loss:0.4446875751018524 - train/lr(1e-3):0.04121767803160924
step:2067 - train/loss:0.5788801312446594 - train/lr(1e-3):0.041167735027702275
step:2068 - train/loss:0.49358928203582764 - train/lr(1e-3):0.04111780111810826
step:2069 - train/loss:0.463505357503891 - train/lr(1e-3):0.041067876354242576
step:2070 - train/loss:0.5251381397247314 - train/lr(1e-3):0.04101796078751122
step:2071 - train/loss:0.4797869622707367 - train/lr(1e-3):0.040968054469310775
step:2072 - train/loss:0.5203442573547363 - train/lr(1e-3):0.040918157451028184
step:2073 - train/loss:0.49689531326293945 - train/lr(1e-3):0.040868269784040914
step:2074 - train/loss:0.5226542949676514 - train/lr(1e-3):0.040818391519716786
step:2075 - train/loss:0.5427280068397522 - train/lr(1e-3):0.04076852270941389
step:2076 - train/loss:0.5170350074768066 - train/lr(1e-3):0.04071866340448062
step:2077 - train/loss:0.6261629462242126 - train/lr(1e-3):0.0406688136562556
step:2078 - train/loss:0.5425615310668945 - train/lr(1e-3):0.040618973516067546
step:2079 - train/loss:0.528244137763977 - train/lr(1e-3):0.04056914303523536
step:2080 - train/loss:0.594636857509613 - train/lr(1e-3):0.040519322265067964
step:2081 - train/loss:0.6508312821388245 - train/lr(1e-3):0.040469511256864266
step:2082 - train/loss:0.578326404094696 - train/lr(1e-3):0.04041971006191313
step:2083 - train/loss:0.5745604038238525 - train/lr(1e-3):0.04036991873149335
step:2084 - train/loss:0.6387758851051331 - train/lr(1e-3):0.04032013731687351
step:2085 - train/loss:0.5183361172676086 - train/lr(1e-3):0.040270365869312014
step:2086 - train/loss:0.5509766340255737 - train/lr(1e-3):0.040220604440057005
step:2087 - train/loss:0.6270447373390198 - train/lr(1e-3):0.0401708530803463
step:2088 - train/loss:0.4868236780166626 - train/lr(1e-3):0.04012111184140734
step:2089 - train/loss:0.5822315812110901 - train/lr(1e-3):0.04007138077445719
step:2090 - train/loss:0.5249198079109192 - train/lr(1e-3):0.04002165993070237
step:2091 - train/loss:0.4734957218170166 - train/lr(1e-3):0.03997194936133893
step:2092 - train/loss:0.6975741982460022 - train/lr(1e-3):0.039922249117552336
step:2093 - train/loss:0.40265634655952454 - train/lr(1e-3):0.039872559250517366
step:2094 - train/loss:0.43116772174835205 - train/lr(1e-3):0.039822879811398176
step:2095 - train/loss:0.493160218000412 - train/lr(1e-3):0.03977321085134819
step:2096 - train/loss:0.6643806099891663 - train/lr(1e-3):0.039723552421509975
step:2097 - train/loss:0.5682162642478943 - train/lr(1e-3):0.03967390457301532
step:2098 - train/loss:0.5023958683013916 - train/lr(1e-3):0.039624267356985106
step:2099 - train/loss:0.5685233473777771 - train/lr(1e-3):0.039574640824529224
step:2100 - train/loss:0.6468248963356018 - train/lr(1e-3):0.039525025026746596
step:2101 - train/loss:0.5536457300186157 - train/lr(1e-3):0.03947542001472514
step:2102 - train/loss:0.5217449069023132 - train/lr(1e-3):0.03942582583954155
step:2103 - train/loss:0.5370493531227112 - train/lr(1e-3):0.03937624255226149
step:2104 - train/loss:0.4902278184890747 - train/lr(1e-3):0.03932667020393933
step:2105 - train/loss:0.536857008934021 - train/lr(1e-3):0.03927710884561818
step:2106 - train/loss:0.6531577706336975 - train/lr(1e-3):0.03922755852832986
step:2107 - train/loss:0.5595235824584961 - train/lr(1e-3):0.039178019303094856
step:2108 - train/loss:0.5229432582855225 - train/lr(1e-3):0.03912849122092216
step:2109 - train/loss:0.5529196262359619 - train/lr(1e-3):0.0390789743328093
step:2110 - train/loss:0.5839295983314514 - train/lr(1e-3):0.03902946868974236
step:2111 - train/loss:0.648728609085083 - train/lr(1e-3):0.038979974342695727
step:2112 - train/loss:0.5124891996383667 - train/lr(1e-3):0.03893049134263224
step:2113 - train/loss:0.5059096813201904 - train/lr(1e-3):0.03888101974050304
step:2114 - train/loss:0.6076413989067078 - train/lr(1e-3):0.03883155958724751
step:2115 - train/loss:0.5882731676101685 - train/lr(1e-3):0.03878211093379323
step:2116 - train/loss:0.5511291027069092 - train/lr(1e-3):0.03873267383105603
step:2117 - train/loss:0.46800464391708374 - train/lr(1e-3):0.03868324832993972
step:2118 - train/loss:0.604824960231781 - train/lr(1e-3):0.03863383448133627
step:2119 - train/loss:0.5008164644241333 - train/lr(1e-3):0.03858443233612556
step:2120 - train/loss:0.4648798406124115 - train/lr(1e-3):0.038535041945175506
step:2121 - train/loss:0.553945004940033 - train/lr(1e-3):0.038485663359341886
step:2122 - train/loss:0.6642001271247864 - train/lr(1e-3):0.03843629662946827
step:2123 - train/loss:0.5305967330932617 - train/lr(1e-3):0.03838694180638611
step:2124 - train/loss:0.4604910612106323 - train/lr(1e-3):0.03833759894091456
step:2125 - train/loss:0.5401689410209656 - train/lr(1e-3):0.03828826808386043
step:2126 - train/loss:0.5113062858581543 - train/lr(1e-3):0.038238949286018224
step:2127 - train/loss:0.5352336168289185 - train/lr(1e-3):0.03818964259816999
step:2128 - train/loss:0.6547373533248901 - train/lr(1e-3):0.03814034807108529
step:2129 - train/loss:0.5280531644821167 - train/lr(1e-3):0.03809106575552121
step:2130 - train/loss:0.4717419147491455 - train/lr(1e-3):0.03804179570222227
step:2131 - train/loss:0.5927403569221497 - train/lr(1e-3):0.03799253796192028
step:2132 - train/loss:0.5123249292373657 - train/lr(1e-3):0.03794329258533446
step:2133 - train/loss:0.43377846479415894 - train/lr(1e-3):0.03789405962317128
step:2134 - train/loss:0.5065563917160034 - train/lr(1e-3):0.03784483912612438
step:2135 - train/loss:0.5419393181800842 - train/lr(1e-3):0.0377956311448746
step:2136 - train/loss:0.5052440166473389 - train/lr(1e-3):0.03774643573008995
step:2137 - train/loss:0.4262024164199829 - train/lr(1e-3):0.03769725293242538
step:2138 - train/loss:0.5017421841621399 - train/lr(1e-3):0.03764808280252292
step:2139 - train/loss:0.4996371865272522 - train/lr(1e-3):0.03759892539101158
step:2140 - train/loss:0.520481526851654 - train/lr(1e-3):0.03754978074850722
step:2141 - train/loss:0.614892303943634 - train/lr(1e-3):0.03750064892561257
step:2142 - train/loss:0.5506159067153931 - train/lr(1e-3):0.03745152997291718
step:2143 - train/loss:0.4532027840614319 - train/lr(1e-3):0.037402423940997326
step:2144 - train/loss:0.4937703013420105 - train/lr(1e-3):0.03735333088041596
step:2145 - train/loss:0.5596838593482971 - train/lr(1e-3):0.03730425084172276
step:2146 - train/loss:0.5610380172729492 - train/lr(1e-3):0.03725518387545388
step:2147 - train/loss:0.5818045735359192 - train/lr(1e-3):0.03720613003213212
step:2148 - train/loss:0.5901519656181335 - train/lr(1e-3):0.03715708936226669
step:2149 - train/loss:0.5532532334327698 - train/lr(1e-3):0.0371080619163533
step:2150 - train/loss:0.5133657455444336 - train/lr(1e-3):0.03705904774487396
step:2151 - train/loss:0.5362353324890137 - train/lr(1e-3):0.03701004689829712
step:2152 - train/loss:0.5796753168106079 - train/lr(1e-3):0.036961059427077406
step:2153 - train/loss:0.6689532995223999 - train/lr(1e-3):0.03691208538165573
step:2154 - train/loss:0.5908573865890503 - train/lr(1e-3):0.03686312481245921
step:2155 - train/loss:0.5261960625648499 - train/lr(1e-3):0.03681417776990097
step:2156 - train/loss:0.5515198707580566 - train/lr(1e-3):0.03676524430438032
step:2157 - train/loss:0.5478324294090271 - train/lr(1e-3):0.036716324466282584
step:2158 - train/loss:0.397067666053772 - train/lr(1e-3):0.03666741830597896
step:2159 - train/loss:0.5704651474952698 - train/lr(1e-3):0.03661852587382667
step:2160 - train/loss:0.5601586103439331 - train/lr(1e-3):0.03656964722016875
step:2161 - train/loss:0.558769941329956 - train/lr(1e-3):0.036520782395334024
step:2162 - train/loss:0.5789464712142944 - train/lr(1e-3):0.036471931449637125
step:2163 - train/loss:0.4088903069496155 - train/lr(1e-3):0.0364230944333784
step:2164 - train/loss:0.47809261083602905 - train/lr(1e-3):0.036374271396843794
step:2165 - train/loss:0.572553813457489 - train/lr(1e-3):0.03632546239030491
step:2166 - train/loss:0.562414288520813 - train/lr(1e-3):0.036276667464018884
step:2167 - train/loss:0.5435441136360168 - train/lr(1e-3):0.036227886668228355
step:2168 - train/loss:0.6075442433357239 - train/lr(1e-3):0.036179120053161415
step:2169 - train/loss:0.5771547555923462 - train/lr(1e-3):0.03613036766903159
step:2170 - train/loss:0.5303491353988647 - train/lr(1e-3):0.03608162956603767
step:2171 - train/loss:0.5197824835777283 - train/lr(1e-3):0.0360329057943638
step:2172 - train/loss:0.647373378276825 - train/lr(1e-3):0.03598419640417939
step:2173 - train/loss:0.6174532175064087 - train/lr(1e-3):0.03593550144563894
step:2174 - train/loss:0.6369882822036743 - train/lr(1e-3):0.0358868209688822
step:2175 - train/loss:0.49795305728912354 - train/lr(1e-3):0.03583815502403401
step:2176 - train/loss:0.4972110092639923 - train/lr(1e-3):0.03578950366120414
step:2177 - train/loss:0.5181872844696045 - train/lr(1e-3):0.03574086693048741
step:2178 - train/loss:0.6475673913955688 - train/lr(1e-3):0.03569224488196362
step:2179 - train/loss:0.6163294911384583 - train/lr(1e-3):0.03564363756569736
step:2180 - train/loss:0.5064873099327087 - train/lr(1e-3):0.035595045031738125
step:2181 - train/loss:0.4835383892059326 - train/lr(1e-3):0.035546467330120145
step:2182 - train/loss:0.573528528213501 - train/lr(1e-3):0.0354979045108624
step:2183 - train/loss:0.5586948394775391 - train/lr(1e-3):0.03544935662396854
step:2184 - train/loss:0.6214712858200073 - train/lr(1e-3):0.035400823719426815
step:2185 - train/loss:0.5261512994766235 - train/lr(1e-3):0.035352305847210094
step:2186 - train/loss:0.5876435041427612 - train/lr(1e-3):0.035303803057275755
step:2187 - train/loss:0.5021369457244873 - train/lr(1e-3):0.03525531539956562
step:2188 - train/loss:0.7073497176170349 - train/lr(1e-3):0.03520684292400593
step:2189 - train/loss:0.39401543140411377 - train/lr(1e-3):0.03515838568050736
step:2190 - train/loss:0.49291154742240906 - train/lr(1e-3):0.03510994371896479
step:2191 - train/loss:0.5142041444778442 - train/lr(1e-3):0.035061517089257456
step:2192 - train/loss:0.5336386561393738 - train/lr(1e-3):0.035013105841248796
step:2193 - train/loss:0.6027829647064209 - train/lr(1e-3):0.03496471002478636
step:2194 - train/loss:0.6512351632118225 - train/lr(1e-3):0.03491632968970183
step:2195 - train/loss:0.5975056290626526 - train/lr(1e-3):0.034867964885810995
step:2196 - train/loss:0.5505681037902832 - train/lr(1e-3):0.03481961566291358
step:2197 - train/loss:0.6061398983001709 - train/lr(1e-3):0.03477128207079331
step:2198 - train/loss:0.6570913195610046 - train/lr(1e-3):0.03472296415921783
step:2199 - train/loss:0.5786395072937012 - train/lr(1e-3):0.03467466197793858
step:2200 - train/loss:0.5850037336349487 - train/lr(1e-3):0.034626375576690835
step:2201 - train/loss:0.7050455808639526 - train/lr(1e-3):0.03457810500519368
step:2202 - train/loss:0.5989264249801636 - train/lr(1e-3):0.034529850313149764
step:2203 - train/loss:0.5854492783546448 - train/lr(1e-3):0.034481611550245525
step:2204 - train/loss:0.49492132663726807 - train/lr(1e-3):0.034433388766150916
step:2205 - train/loss:0.5924964547157288 - train/lr(1e-3):0.03438518201051949
step:2206 - train/loss:0.4627676010131836 - train/lr(1e-3):0.03433699133298822
step:2207 - train/loss:0.650477409362793 - train/lr(1e-3):0.03428881678317763
step:2208 - train/loss:0.6405052542686462 - train/lr(1e-3):0.034240658410691516
step:2209 - train/loss:0.5215091705322266 - train/lr(1e-3):0.03419251626511712
step:2210 - train/loss:0.5863438248634338 - train/lr(1e-3):0.03414439039602495
step:2211 - train/loss:0.5204177498817444 - train/lr(1e-3):0.0340962808529687
step:2212 - train/loss:0.5403855443000793 - train/lr(1e-3):0.034048187685485315
step:2213 - train/loss:0.52812260389328 - train/lr(1e-3):0.03400011094309487
step:2214 - train/loss:0.5628446340560913 - train/lr(1e-3):0.03395205067530049
step:2215 - train/loss:0.5293432474136353 - train/lr(1e-3):0.03390400693158837
step:2216 - train/loss:0.5416857004165649 - train/lr(1e-3):0.0338559797614277
step:2217 - train/loss:0.529487133026123 - train/lr(1e-3):0.03380796921427056
step:2218 - train/loss:0.5929962396621704 - train/lr(1e-3):0.03375997533955194
step:2219 - train/loss:0.47359079122543335 - train/lr(1e-3):0.033711998186689705
step:2220 - train/loss:0.4524551331996918 - train/lr(1e-3):0.033664037805084424
step:2221 - train/loss:0.5343614816665649 - train/lr(1e-3):0.033616094244119446
step:2222 - train/loss:0.5552458167076111 - train/lr(1e-3):0.033568167553160784
step:2223 - train/loss:0.564453661441803 - train/lr(1e-3):0.03352025778155709
step:2224 - train/loss:0.5879812240600586 - train/lr(1e-3):0.03347236497863957
step:2225 - train/loss:0.510834276676178 - train/lr(1e-3):0.03342448919372201
step:2226 - train/loss:0.6018013954162598 - train/lr(1e-3):0.03337663047610062
step:2227 - train/loss:0.4985814690589905 - train/lr(1e-3):0.03332878887505406
step:2228 - train/loss:0.41765913367271423 - train/lr(1e-3):0.03328096443984337
step:2229 - train/loss:0.4364200532436371 - train/lr(1e-3):0.0332331572197119
step:2230 - train/loss:0.5310595035552979 - train/lr(1e-3):0.03318536726388526
step:2231 - train/loss:0.6890062689781189 - train/lr(1e-3):0.033137594621571356
step:2232 - train/loss:0.5110108256340027 - train/lr(1e-3):0.03308983934196018
step:2233 - train/loss:0.4423244595527649 - train/lr(1e-3):0.03304210147422387
step:2234 - train/loss:0.553400456905365 - train/lr(1e-3):0.0329943810675167
step:2235 - train/loss:0.4679596424102783 - train/lr(1e-3):0.03294667817097484
step:2236 - train/loss:0.7153187990188599 - train/lr(1e-3):0.03289899283371657
step:2237 - train/loss:0.5790721774101257 - train/lr(1e-3):0.03285132510484198
step:2238 - train/loss:0.4754592776298523 - train/lr(1e-3):0.032803675033433094
step:2239 - train/loss:0.5918790102005005 - train/lr(1e-3):0.0327560426685537
step:2240 - train/loss:0.517655074596405 - train/lr(1e-3):0.032708428059249436
step:2241 - train/loss:0.4427921175956726 - train/lr(1e-3):0.032660831254547565
step:2242 - train/loss:0.5656731128692627 - train/lr(1e-3):0.03261325230345708
step:2243 - train/loss:0.47531163692474365 - train/lr(1e-3):0.03256569125496858
step:2244 - train/loss:0.5899463891983032 - train/lr(1e-3):0.032518148158054185
step:2245 - train/loss:0.4626469016075134 - train/lr(1e-3):0.032470623061667585
step:2246 - train/loss:0.5063085556030273 - train/lr(1e-3):0.032423116014743944
step:2247 - train/loss:0.5200692415237427 - train/lr(1e-3):0.032375627066199786
step:2248 - train/loss:0.48453575372695923 - train/lr(1e-3):0.03232815626493304
step:2249 - train/loss:0.5116986036300659 - train/lr(1e-3):0.03228070365982293
step:2250 - train/loss:0.4416876435279846 - train/lr(1e-3):0.03223326929972994
step:2251 - train/loss:0.5171123147010803 - train/lr(1e-3):0.032185853233495806
step:2252 - train/loss:0.5561760663986206 - train/lr(1e-3):0.03213845550994337
step:2253 - train/loss:0.5054293870925903 - train/lr(1e-3):0.03209107617787663
step:2254 - train/loss:0.565653383731842 - train/lr(1e-3):0.03204371528608065
step:2255 - train/loss:0.5422091484069824 - train/lr(1e-3):0.03199637288332148
step:2256 - train/loss:0.4999474287033081 - train/lr(1e-3):0.03194904901834612
step:2257 - train/loss:0.5796946287155151 - train/lr(1e-3):0.03190174373988256
step:2258 - train/loss:0.518677294254303 - train/lr(1e-3):0.03185445709663953
step:2259 - train/loss:0.5355663895606995 - train/lr(1e-3):0.031807189137306686
step:2260 - train/loss:0.4938240051269531 - train/lr(1e-3):0.0317599399105544
step:2261 - train/loss:0.560082733631134 - train/lr(1e-3):0.03171270946503373
step:2262 - train/loss:0.6038936972618103 - train/lr(1e-3):0.03166549784937642
step:2263 - train/loss:0.49074843525886536 - train/lr(1e-3):0.03161830511219486
step:2264 - train/loss:0.5485008955001831 - train/lr(1e-3):0.03157113130208191
step:2265 - train/loss:0.44287002086639404 - train/lr(1e-3):0.03152397646761106
step:2266 - train/loss:0.49883875250816345 - train/lr(1e-3):0.03147684065733618
step:2267 - train/loss:0.5959198474884033 - train/lr(1e-3):0.03142972391979153
step:2268 - train/loss:0.5889739990234375 - train/lr(1e-3):0.03138262630349182
step:2269 - train/loss:0.6689674854278564 - train/lr(1e-3):0.031335547856932024
step:2270 - train/loss:0.6126395463943481 - train/lr(1e-3):0.031288488628587345
step:2271 - train/loss:0.5313600301742554 - train/lr(1e-3):0.031241448666913262
step:2272 - train/loss:0.6265982985496521 - train/lr(1e-3):0.031194428020345378
step:2273 - train/loss:0.40506798028945923 - train/lr(1e-3):0.03114742673729938
step:2274 - train/loss:0.5124558806419373 - train/lr(1e-3):0.031100444866171077
step:2275 - train/loss:0.392537385225296 - train/lr(1e-3):0.03105348245533629
step:2276 - train/loss:0.5486881732940674 - train/lr(1e-3):0.031006539553150726
step:2277 - train/loss:0.44439828395843506 - train/lr(1e-3):0.03095961620795009
step:2278 - train/loss:0.5256021022796631 - train/lr(1e-3):0.03091271246804992
step:2279 - train/loss:0.5035558938980103 - train/lr(1e-3):0.03086582838174551
step:2280 - train/loss:0.6379642486572266 - train/lr(1e-3):0.03081896399731202
step:2281 - train/loss:0.526745080947876 - train/lr(1e-3):0.030772119363004266
step:2282 - train/loss:0.44886913895606995 - train/lr(1e-3):0.030725294527056718
step:2283 - train/loss:0.6508902311325073 - train/lr(1e-3):0.03067848953768346
step:2284 - train/loss:0.5525474548339844 - train/lr(1e-3):0.030631704443078216
step:2285 - train/loss:0.6180942058563232 - train/lr(1e-3):0.030584939291414096
step:2286 - train/loss:0.5405260324478149 - train/lr(1e-3):0.030538194130843785
step:2287 - train/loss:0.5086787939071655 - train/lr(1e-3):0.030491469009499353
step:2288 - train/loss:0.5826865434646606 - train/lr(1e-3):0.030444763975492208
step:2289 - train/loss:0.560437798500061 - train/lr(1e-3):0.03039807907691309
step:2290 - train/loss:0.49332645535469055 - train/lr(1e-3):0.03035141436183203
step:2291 - train/loss:0.45907264947891235 - train/lr(1e-3):0.030304769878298235
step:2292 - train/loss:0.6241254210472107 - train/lr(1e-3):0.030258145674340098
step:2293 - train/loss:0.5037205815315247 - train/lr(1e-3):0.03021154179796518
step:2294 - train/loss:0.583446741104126 - train/lr(1e-3):0.030164958297160028
step:2295 - train/loss:0.5190695524215698 - train/lr(1e-3):0.03011839521989024
step:2296 - train/loss:0.5391084551811218 - train/lr(1e-3):0.030071852614100426
step:2297 - train/loss:0.5267367362976074 - train/lr(1e-3):0.030025330527714045
step:2298 - train/loss:0.5945257544517517 - train/lr(1e-3):0.029978829008633495
step:2299 - train/loss:0.752729058265686 - train/lr(1e-3):0.02993234810473996
step:2300 - train/loss:0.4433002471923828 - train/lr(1e-3):0.02988588786389339
step:2301 - train/loss:0.6402585506439209 - train/lr(1e-3):0.029839448333932473
step:2302 - train/loss:0.48341798782348633 - train/lr(1e-3):0.029793029562674607
step:2303 - train/loss:0.48076480627059937 - train/lr(1e-3):0.029746631597915733
step:2304 - train/loss:0.5891521573066711 - train/lr(1e-3):0.029700254487430446
step:2305 - train/loss:0.41915595531463623 - train/lr(1e-3):0.029653898278971837
step:2306 - train/loss:0.608899712562561 - train/lr(1e-3):0.029607563020271448
step:2307 - train/loss:0.5526338219642639 - train/lr(1e-3):0.029561248759039295
step:2308 - train/loss:0.443888396024704 - train/lr(1e-3):0.029514955542963774
step:2309 - train/loss:0.5573749542236328 - train/lr(1e-3):0.029468683419711553
step:2310 - train/loss:0.5051594376564026 - train/lr(1e-3):0.02942243243692765
step:2311 - train/loss:0.5176118612289429 - train/lr(1e-3):0.029376202642235297
step:2312 - train/loss:0.567608118057251 - train/lr(1e-3):0.029329994083235857
step:2313 - train/loss:0.46096840500831604 - train/lr(1e-3):0.02928380680750891
step:2314 - train/loss:0.5774257183074951 - train/lr(1e-3):0.029237640862612036
step:2315 - train/loss:0.48298850655555725 - train/lr(1e-3):0.029191496296080935
step:2316 - train/loss:0.47296416759490967 - train/lr(1e-3):0.029145373155429262
step:2317 - train/loss:0.6776506304740906 - train/lr(1e-3):0.02909927148814855
step:2318 - train/loss:0.550865650177002 - train/lr(1e-3):0.029053191341708317
step:2319 - train/loss:0.4852408468723297 - train/lr(1e-3):0.029007132763555883
step:2320 - train/loss:0.5195688605308533 - train/lr(1e-3):0.02896109580111634
step:2321 - train/loss:0.6089281439781189 - train/lr(1e-3):0.02891508050179254
step:2322 - train/loss:0.5256470441818237 - train/lr(1e-3):0.02886908691296504
step:2323 - train/loss:0.5127584338188171 - train/lr(1e-3):0.028823115081992014
step:2324 - train/loss:0.5127555727958679 - train/lr(1e-3):0.028777165056209256
step:2325 - train/loss:0.42551785707473755 - train/lr(1e-3):0.0287312368829301
step:2326 - train/loss:0.49324142932891846 - train/lr(1e-3):0.028685330609445392
step:2327 - train/loss:0.53459233045578 - train/lr(1e-3):0.028639446283023385
step:2328 - train/loss:0.5652856826782227 - train/lr(1e-3):0.02859358395090983
step:2329 - train/loss:0.6022518873214722 - train/lr(1e-3):0.02854774366032769
step:2330 - train/loss:0.6772668361663818 - train/lr(1e-3):0.028501925458477354
step:2331 - train/loss:0.4386999011039734 - train/lr(1e-3):0.028456129392536438
step:2332 - train/loss:0.641416072845459 - train/lr(1e-3):0.02841035550965968
step:2333 - train/loss:0.4867558181285858 - train/lr(1e-3):0.02836460385697911
step:2334 - train/loss:0.5517407655715942 - train/lr(1e-3):0.028318874481603785
step:2335 - train/loss:0.5444785356521606 - train/lr(1e-3):0.02827316743061985
step:2336 - train/loss:0.4600810408592224 - train/lr(1e-3):0.028227482751090445
step:2337 - train/loss:0.5637651681900024 - train/lr(1e-3):0.02818182049005569
step:2338 - train/loss:0.6132725477218628 - train/lr(1e-3):0.028136180694532623
step:2339 - train/loss:0.4413456618785858 - train/lr(1e-3):0.028090563411515116
step:2340 - train/loss:0.5632510185241699 - train/lr(1e-3):0.028044968687973956
step:2341 - train/loss:0.5746909379959106 - train/lr(1e-3):0.027999396570856573
step:2342 - train/loss:0.4783337116241455 - train/lr(1e-3):0.027953847107087173
step:2343 - train/loss:0.5661436319351196 - train/lr(1e-3):0.027908320343566717
step:2344 - train/loss:0.46243685483932495 - train/lr(1e-3):0.027862816327172635
step:2345 - train/loss:0.5839315056800842 - train/lr(1e-3):0.02781733510475908
step:2346 - train/loss:0.48040375113487244 - train/lr(1e-3):0.027771876723156654
step:2347 - train/loss:0.6036999821662903 - train/lr(1e-3):0.027726441229172463
step:2348 - train/loss:0.5494887828826904 - train/lr(1e-3):0.027681028669590036
step:2349 - train/loss:0.5579479336738586 - train/lr(1e-3):0.027635639091169315
step:2350 - train/loss:0.3978809118270874 - train/lr(1e-3):0.02759027254064654
step:2351 - train/loss:0.44419950246810913 - train/lr(1e-3):0.02754492906473425
step:2352 - train/loss:0.5784320831298828 - train/lr(1e-3):0.027499608710121286
step:2353 - train/loss:0.47566524147987366 - train/lr(1e-3):0.027454311523472587
step:2354 - train/loss:0.5787612199783325 - train/lr(1e-3):0.027409037551429264
step:2355 - train/loss:0.4890134930610657 - train/lr(1e-3):0.027363786840608598
step:2356 - train/loss:0.578712522983551 - train/lr(1e-3):0.0273185594376038
step:2357 - train/loss:0.4215104877948761 - train/lr(1e-3):0.02727335538898418
step:2358 - train/loss:0.5707904100418091 - train/lr(1e-3):0.027228174741294957
step:2359 - train/loss:0.6527166366577148 - train/lr(1e-3):0.027183017541057265
step:2360 - train/loss:0.47197723388671875 - train/lr(1e-3):0.027137883834768072
step:2361 - train/loss:0.4966842532157898 - train/lr(1e-3):0.027092773668900196
step:2362 - train/loss:0.48703068494796753 - train/lr(1e-3):0.027047687089902187
step:2363 - train/loss:0.5060968995094299 - train/lr(1e-3):0.027002624144198305
step:2364 - train/loss:0.47373682260513306 - train/lr(1e-3):0.026957584878188497
step:2365 - train/loss:0.49308791756629944 - train/lr(1e-3):0.026912569338248316
step:2366 - train/loss:0.5352106690406799 - train/lr(1e-3):0.02686757757072886
step:2367 - train/loss:0.5388981103897095 - train/lr(1e-3):0.02682260962195684
step:2368 - train/loss:0.4307986795902252 - train/lr(1e-3):0.026777665538234293
step:2369 - train/loss:0.505440354347229 - train/lr(1e-3):0.026732745365838827
step:2370 - train/loss:0.5768399238586426 - train/lr(1e-3):0.026687849151023374
step:2371 - train/loss:0.4981725215911865 - train/lr(1e-3):0.026642976940016126
step:2372 - train/loss:0.4895426630973816 - train/lr(1e-3):0.026598128779020694
step:2373 - train/loss:0.5062319040298462 - train/lr(1e-3):0.026553304714215825
step:2374 - train/loss:0.5797657370567322 - train/lr(1e-3):0.026508504791755497
step:2375 - train/loss:0.5325421690940857 - train/lr(1e-3):0.02646372905776881
step:2376 - train/loss:0.5139901638031006 - train/lr(1e-3):0.026418977558359973
step:2377 - train/loss:0.5992839336395264 - train/lr(1e-3):0.02637425033960823
step:2378 - train/loss:0.4023548662662506 - train/lr(1e-3):0.026329547447567835
step:2379 - train/loss:0.5193246006965637 - train/lr(1e-3):0.026284868928267993
step:2380 - train/loss:0.44262272119522095 - train/lr(1e-3):0.026240214827712795
step:2381 - train/loss:0.5176048278808594 - train/lr(1e-3):0.0261955851918812
step:2382 - train/loss:0.6022524237632751 - train/lr(1e-3):0.026150980066726993
step:2383 - train/loss:0.4809085726737976 - train/lr(1e-3):0.026106399498178678
step:2384 - train/loss:0.5100668668746948 - train/lr(1e-3):0.026061843532139563
step:2385 - train/loss:0.5699374675750732 - train/lr(1e-3):0.026017312214487477
step:2386 - train/loss:0.6214959621429443 - train/lr(1e-3):0.025972805591075024
step:2387 - train/loss:0.5051344037055969 - train/lr(1e-3):0.025928323707729305
step:2388 - train/loss:0.5915547609329224 - train/lr(1e-3):0.025883866610251906
step:2389 - train/loss:0.5731227397918701 - train/lr(1e-3):0.025839434344418977
step:2390 - train/loss:0.5470830202102661 - train/lr(1e-3):0.025795026955981067
step:2391 - train/loss:0.5030636191368103 - train/lr(1e-3):0.02575064449066309
step:2392 - train/loss:0.4334687888622284 - train/lr(1e-3):0.025706286994164315
step:2393 - train/loss:0.589402437210083 - train/lr(1e-3):0.0256619545121583
step:2394 - train/loss:0.6245601177215576 - train/lr(1e-3):0.02561764709029284
step:2395 - train/loss:0.4887388348579407 - train/lr(1e-3):0.02557336477418992
step:2396 - train/loss:0.5360658764839172 - train/lr(1e-3):0.025529107609445732
step:2397 - train/loss:0.4821488857269287 - train/lr(1e-3):0.02548487564163049
step:2398 - train/loss:0.5612614750862122 - train/lr(1e-3):0.02544066891628847
step:2399 - train/loss:0.48072904348373413 - train/lr(1e-3):0.025396487478938055
step:2400 - train/loss:0.46159785985946655 - train/lr(1e-3):0.025352331375071438
step:2401 - train/loss:0.5949907302856445 - train/lr(1e-3):0.025308200650154867
step:2402 - train/loss:0.6502633094787598 - train/lr(1e-3):0.025264095349628382
step:2403 - train/loss:0.5197076797485352 - train/lr(1e-3):0.025220015518905858
step:2404 - train/loss:0.4581451416015625 - train/lr(1e-3):0.025175961203374952
step:2405 - train/loss:0.49382007122039795 - train/lr(1e-3):0.02513193244839704
step:2406 - train/loss:0.5529946088790894 - train/lr(1e-3):0.02508792929930718
step:2407 - train/loss:0.5670350790023804 - train/lr(1e-3):0.025043951801414055
step:2408 - train/loss:0.6163835525512695 - train/lr(1e-3):0.025000000000000012
step:2409 - train/loss:0.7173773646354675 - train/lr(1e-3):0.024956073940320806
step:2410 - train/loss:0.6093109250068665 - train/lr(1e-3):0.024912173667605758
step:2411 - train/loss:0.5620520114898682 - train/lr(1e-3):0.024868299227057696
step:2412 - train/loss:0.48514047265052795 - train/lr(1e-3):0.024824450663852717
step:2413 - train/loss:0.5101314783096313 - train/lr(1e-3):0.024780628023140388
step:2414 - train/loss:0.5413352847099304 - train/lr(1e-3):0.024736831350043537
step:2415 - train/loss:0.6099256873130798 - train/lr(1e-3):0.024693060689658246
step:2416 - train/loss:0.4513402581214905 - train/lr(1e-3):0.024649316087053837
step:2417 - train/loss:0.4212607145309448 - train/lr(1e-3):0.024605597587272775
step:2418 - train/loss:0.6791833639144897 - train/lr(1e-3):0.02456190523533067
step:2419 - train/loss:0.50032639503479 - train/lr(1e-3):0.024518239076216194
step:2420 - train/loss:0.5810452699661255 - train/lr(1e-3):0.024474599154891058
step:2421 - train/loss:0.49658477306365967 - train/lr(1e-3):0.024430985516289954
step:2422 - train/loss:0.47575700283050537 - train/lr(1e-3):0.02438739820532049
step:2423 - train/loss:0.4863150119781494 - train/lr(1e-3):0.024343837266863247
step:2424 - train/loss:0.5550686717033386 - train/lr(1e-3):0.024300302745771506
step:2425 - train/loss:0.5632896423339844 - train/lr(1e-3):0.024256794686871495
step:2426 - train/loss:0.4990178346633911 - train/lr(1e-3):0.024213313134962132
step:2427 - train/loss:0.3958163857460022 - train/lr(1e-3):0.024169858134814974
step:2428 - train/loss:0.530724287033081 - train/lr(1e-3):0.02412642973117437
step:2429 - train/loss:0.4889370799064636 - train/lr(1e-3):0.0240830279687572
step:2430 - train/loss:0.4718320369720459 - train/lr(1e-3):0.024039652892252926
step:2431 - train/loss:0.5256887078285217 - train/lr(1e-3):0.02399630454632353
step:2432 - train/loss:0.47932952642440796 - train/lr(1e-3):0.023952982975603495
step:2433 - train/loss:0.5867376327514648 - train/lr(1e-3):0.0239096882246997
step:2434 - train/loss:0.47760751843452454 - train/lr(1e-3):0.023866420338191408
step:2435 - train/loss:0.5161212682723999 - train/lr(1e-3):0.02382317936063031
step:2436 - train/loss:0.4796143174171448 - train/lr(1e-3):0.023779965336540237
step:2437 - train/loss:0.4514327049255371 - train/lr(1e-3):0.02373677831041737
step:2438 - train/loss:0.5042055249214172 - train/lr(1e-3):0.023693618326730104
step:2439 - train/loss:0.5302811861038208 - train/lr(1e-3):0.023650485429918898
step:2440 - train/loss:0.4916132092475891 - train/lr(1e-3):0.02360737966439641
step:2441 - train/loss:0.6689018607139587 - train/lr(1e-3):0.02356430107454733
step:2442 - train/loss:0.5867894887924194 - train/lr(1e-3):0.023521249704728346
step:2443 - train/loss:0.5265957117080688 - train/lr(1e-3):0.02347822559926817
step:2444 - train/loss:0.5117249488830566 - train/lr(1e-3):0.02343522880246734
step:2445 - train/loss:0.4709387421607971 - train/lr(1e-3):0.023392259358598403
step:2446 - train/loss:0.5561236143112183 - train/lr(1e-3):0.023349317311905655
step:2447 - train/loss:0.6603967547416687 - train/lr(1e-3):0.023306402706605212
step:2448 - train/loss:0.49919453263282776 - train/lr(1e-3):0.02326351558688493
step:2449 - train/loss:0.4575191140174866 - train/lr(1e-3):0.023220655996904368
step:2450 - train/loss:0.6279697418212891 - train/lr(1e-3):0.023177823980794727
step:2451 - train/loss:0.42492493987083435 - train/lr(1e-3):0.023135019582658803
step:2452 - train/loss:0.5476338863372803 - train/lr(1e-3):0.023092242846571034
step:2453 - train/loss:0.43578267097473145 - train/lr(1e-3):0.023049493816577244
step:2454 - train/loss:0.5356898307800293 - train/lr(1e-3):0.023006772536694853
step:2455 - train/loss:0.5489804148674011 - train/lr(1e-3):0.022964079050912654
step:2456 - train/loss:0.4424331784248352 - train/lr(1e-3):0.02292141340319077
step:2457 - train/loss:0.4657563865184784 - train/lr(1e-3):0.022878775637460776
step:2458 - train/loss:0.596749484539032 - train/lr(1e-3):0.022836165797625443
step:2459 - train/loss:0.5825402140617371 - train/lr(1e-3):0.02279358392755882
step:2460 - train/loss:0.5456610321998596 - train/lr(1e-3):0.02275103007110616
step:2461 - train/loss:0.510039746761322 - train/lr(1e-3):0.022708504272083867
step:2462 - train/loss:0.562291145324707 - train/lr(1e-3):0.022666006574279453
step:2463 - train/loss:0.461820513010025 - train/lr(1e-3):0.022623537021451482
step:2464 - train/loss:0.6113749742507935 - train/lr(1e-3):0.0225810956573296
step:2465 - train/loss:0.4773476719856262 - train/lr(1e-3):0.02253868252561433
step:2466 - train/loss:0.6269770860671997 - train/lr(1e-3):0.022496297669977173
step:2467 - train/loss:0.49737948179244995 - train/lr(1e-3):0.02245394113406058
step:2468 - train/loss:0.534447193145752 - train/lr(1e-3):0.0224116129614777
step:2469 - train/loss:0.5968011617660522 - train/lr(1e-3):0.02236931319581262
step:2470 - train/loss:0.5124027132987976 - train/lr(1e-3):0.02232704188062008
step:2471 - train/loss:0.45856964588165283 - train/lr(1e-3):0.022284799059425577
step:2472 - train/loss:0.4767530560493469 - train/lr(1e-3):0.02224258477572524
step:2473 - train/loss:0.562367856502533 - train/lr(1e-3):0.02220039907298583
step:2474 - train/loss:0.4552660882472992 - train/lr(1e-3):0.022158241994644664
step:2475 - train/loss:0.6399248838424683 - train/lr(1e-3):0.02211611358410961
step:2476 - train/loss:0.4617803692817688 - train/lr(1e-3):0.02207401388475899
step:2477 - train/loss:0.4997904300689697 - train/lr(1e-3):0.022031942939941592
step:2478 - train/loss:0.436290442943573 - train/lr(1e-3):0.02198990079297655
step:2479 - train/loss:0.5367914438247681 - train/lr(1e-3):0.02194788748715343
step:2480 - train/loss:0.4770354926586151 - train/lr(1e-3):0.021905903065731973
step:2481 - train/loss:0.5546083450317383 - train/lr(1e-3):0.021863947571942315
step:2482 - train/loss:0.5217535495758057 - train/lr(1e-3):0.02182202104898474
step:2483 - train/loss:0.4394720792770386 - train/lr(1e-3):0.021780123540029655
step:2484 - train/loss:0.5123481154441833 - train/lr(1e-3):0.0217382550882177
step:2485 - train/loss:0.5776435732841492 - train/lr(1e-3):0.021696415736659497
step:2486 - train/loss:0.47580546140670776 - train/lr(1e-3):0.02165460552843577
step:2487 - train/loss:0.41309165954589844 - train/lr(1e-3):0.021612824506597204
step:2488 - train/loss:0.6620516180992126 - train/lr(1e-3):0.021571072714164443
step:2489 - train/loss:0.475242555141449 - train/lr(1e-3):0.021529350194128022
step:2490 - train/loss:0.4817429184913635 - train/lr(1e-3):0.021487656989448323
step:2491 - train/loss:0.4268150329589844 - train/lr(1e-3):0.021445993143055626
step:2492 - train/loss:0.5624256730079651 - train/lr(1e-3):0.02140435869784986
step:2493 - train/loss:0.5443060398101807 - train/lr(1e-3):0.021362753696700737
step:2494 - train/loss:0.5149471163749695 - train/lr(1e-3):0.02132117818244771
step:2495 - train/loss:0.5978661775588989 - train/lr(1e-3):0.02127963219789974
step:2496 - train/loss:0.642780065536499 - train/lr(1e-3):0.021238115785835513
step:2497 - train/loss:0.5588625073432922 - train/lr(1e-3):0.021196628989003187
step:2498 - train/loss:0.5307321548461914 - train/lr(1e-3):0.02115517185012044
step:2499 - train/loss:0.4255480170249939 - train/lr(1e-3):0.021113744411874438
step:2500 - train/loss:0.5832187533378601 - train/lr(1e-3):0.021072346716921733
step:2501 - train/loss:0.4278629422187805 - train/lr(1e-3):0.02103097880788826
step:2502 - train/loss:0.5181323289871216 - train/lr(1e-3):0.020989640727369283
step:2503 - train/loss:0.5325632095336914 - train/lr(1e-3):0.020948332517929404
step:2504 - train/loss:0.5619708895683289 - train/lr(1e-3):0.02090705422210237
step:2505 - train/loss:0.5429742932319641 - train/lr(1e-3):0.020865805882391193
step:2506 - train/loss:0.566257119178772 - train/lr(1e-3):0.02082458754126804
step:2507 - train/loss:0.5569353103637695 - train/lr(1e-3):0.020783399241174137
step:2508 - train/loss:0.5911075472831726 - train/lr(1e-3):0.020742241024519888
step:2509 - train/loss:0.5670241117477417 - train/lr(1e-3):0.02070111293368457
step:2510 - train/loss:0.4179494082927704 - train/lr(1e-3):0.02066001501101657
step:2511 - train/loss:0.5102271437644958 - train/lr(1e-3):0.02061894729883317
step:2512 - train/loss:0.41528481245040894 - train/lr(1e-3):0.02057790983942047
step:2513 - train/loss:0.5759872198104858 - train/lr(1e-3):0.02053690267503355
step:2514 - train/loss:0.5241232514381409 - train/lr(1e-3):0.02049592584789621
step:2515 - train/loss:0.6534264087677002 - train/lr(1e-3):0.02045497940020103
step:2516 - train/loss:0.48474934697151184 - train/lr(1e-3):0.020414063374109327
step:2517 - train/loss:0.4836416244506836 - train/lr(1e-3):0.020373177811751072
step:2518 - train/loss:0.5170807242393494 - train/lr(1e-3):0.020332322755224876
step:2519 - train/loss:0.4623858332633972 - train/lr(1e-3):0.02029149824659793
step:2520 - train/loss:0.41247954964637756 - train/lr(1e-3):0.020250704327906023
step:2521 - train/loss:0.5242524147033691 - train/lr(1e-3):0.020209941041153357
step:2522 - train/loss:0.5452194213867188 - train/lr(1e-3):0.020169208428312647
step:2523 - train/loss:0.5255181789398193 - train/lr(1e-3):0.020128506531325065
step:2524 - train/loss:0.5682309865951538 - train/lr(1e-3):0.020087835392100035
step:2525 - train/loss:0.5096560716629028 - train/lr(1e-3):0.020047195052515444
step:2526 - train/loss:0.702824592590332 - train/lr(1e-3):0.020006585554417384
step:2527 - train/loss:0.480615496635437 - train/lr(1e-3):0.01996600693962021
step:2528 - train/loss:0.5514180660247803 - train/lr(1e-3):0.019925459249906484
step:2529 - train/loss:0.4843638241291046 - train/lr(1e-3):0.019884942527026925
step:2530 - train/loss:0.5091893076896667 - train/lr(1e-3):0.01984445681270035
step:2531 - train/loss:0.5584003925323486 - train/lr(1e-3):0.01980400214861367
step:2532 - train/loss:0.5179516673088074 - train/lr(1e-3):0.019763578576421817
step:2533 - train/loss:0.5337680578231812 - train/lr(1e-3):0.019723186137747695
step:2534 - train/loss:0.5844411849975586 - train/lr(1e-3):0.019682824874182155
step:2535 - train/loss:0.5443500280380249 - train/lr(1e-3):0.019642494827283998
step:2536 - train/loss:0.48952823877334595 - train/lr(1e-3):0.01960219603857977
step:2537 - train/loss:0.4973532557487488 - train/lr(1e-3):0.019561928549563967
step:2538 - train/loss:0.47976940870285034 - train/lr(1e-3):0.019521692401698775
step:2539 - train/loss:0.5105702877044678 - train/lr(1e-3):0.019481487636414076
step:2540 - train/loss:0.4716690182685852 - train/lr(1e-3):0.019441314295107537
step:2541 - train/loss:0.5598244667053223 - train/lr(1e-3):0.019401172419144404
step:2542 - train/loss:0.4255523681640625 - train/lr(1e-3):0.019361062049857537
step:2543 - train/loss:0.46429580450057983 - train/lr(1e-3):0.019320983228547358
step:2544 - train/loss:0.5410189628601074 - train/lr(1e-3):0.01928093599648179
step:2545 - train/loss:0.531661868095398 - train/lr(1e-3):0.019240920394896263
step:2546 - train/loss:0.6084415316581726 - train/lr(1e-3):0.019200936464993587
step:2547 - train/loss:0.5397565960884094 - train/lr(1e-3):0.019160984247944043
step:2548 - train/loss:0.4907732307910919 - train/lr(1e-3):0.019121063784885133
step:2549 - train/loss:0.48327529430389404 - train/lr(1e-3):0.0190811751169218
step:2550 - train/loss:0.49834495782852173 - train/lr(1e-3):0.019041318285126174
step:2551 - train/loss:0.49084198474884033 - train/lr(1e-3):0.019001493330537574
step:2552 - train/loss:0.6018213033676147 - train/lr(1e-3):0.018961700294162578
step:2553 - train/loss:0.510615885257721 - train/lr(1e-3):0.018921939216974843
step:2554 - train/loss:0.4459048807621002 - train/lr(1e-3):0.018882210139915135
step:2555 - train/loss:0.45787298679351807 - train/lr(1e-3):0.01884251310389127
step:2556 - train/loss:0.5287749171257019 - train/lr(1e-3):0.01880284814977807
step:2557 - train/loss:0.5670063495635986 - train/lr(1e-3):0.01876321531841732
step:2558 - train/loss:0.44903212785720825 - train/lr(1e-3):0.018723614650617722
step:2559 - train/loss:0.5324605703353882 - train/lr(1e-3):0.01868404618715492
step:2560 - train/loss:0.4866544008255005 - train/lr(1e-3):0.0186445099687713
step:2561 - train/loss:0.4779484272003174 - train/lr(1e-3):0.018605006036176097
step:2562 - train/loss:0.4800204038619995 - train/lr(1e-3):0.018565534430045348
step:2563 - train/loss:0.7939595580101013 - train/lr(1e-3):0.018526095191021698
step:2564 - train/loss:0.5461611747741699 - train/lr(1e-3):0.018486688359714565
step:2565 - train/loss:0.557770848274231 - train/lr(1e-3):0.018447313976699947
step:2566 - train/loss:0.48432040214538574 - train/lr(1e-3):0.01840797208252044
step:2567 - train/loss:0.4080240726470947 - train/lr(1e-3):0.018368662717685186
step:2568 - train/loss:0.5648216009140015 - train/lr(1e-3):0.01832938592266984
step:2569 - train/loss:0.5172536969184875 - train/lr(1e-3):0.018290141737916505
step:2570 - train/loss:0.4567325711250305 - train/lr(1e-3):0.018250930203833733
step:2571 - train/loss:0.5649847984313965 - train/lr(1e-3):0.018211751360796426
step:2572 - train/loss:0.46535181999206543 - train/lr(1e-3):0.018172605249145848
step:2573 - train/loss:0.41901683807373047 - train/lr(1e-3):0.018133491909189548
step:2574 - train/loss:0.5129371881484985 - train/lr(1e-3):0.01809441138120134
step:2575 - train/loss:0.4572720229625702 - train/lr(1e-3):0.018055363705421223
step:2576 - train/loss:0.5567045211791992 - train/lr(1e-3):0.018016348922055447
step:2577 - train/loss:0.5400639772415161 - train/lr(1e-3):0.017977367071276295
step:2578 - train/loss:0.49945563077926636 - train/lr(1e-3):0.017938418193222186
step:2579 - train/loss:0.6992632746696472 - train/lr(1e-3):0.017899502327997623
step:2580 - train/loss:0.5801119804382324 - train/lr(1e-3):0.017860619515673033
Saving checkpoint to: /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_2580
Checkpoint manager remove previous save local path: /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_1720
[2025-08-24 00:23:19,834][/home/Competition2025/P07/shareP07/share_env/deps/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved model to /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_2580/model_world_size_24_rank_0.pt
[2025-08-24 00:23:25,993][/home/Competition2025/P07/shareP07/share_env/deps/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved optim to /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_2580/optim_world_size_24_rank_0.pt
[2025-08-24 00:23:26,039][/home/Competition2025/P07/shareP07/share_env/deps/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved extra_state to /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_2580/extra_state_world_size_24_rank_0.pt
[2025-08-24 00:23:26,460][/home/Competition2025/P07/shareP07/share_env/deps/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved model config and tokenizer class to /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_2580/huggingface
[2025-08-24 00:25:20,715][/home/Competition2025/P07/shareP07/share_env/deps/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved hf_model to /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_2580/huggingface
Saved dataloader state to: /home/Competition2025/P07/shareP07/share_model/step3_sft/global_step_2580/data.pt
Updated checkpoint tracker: /home/Competition2025/P07/shareP07/share_model/step3_sft/latest_checkpointed_iteration.txt
step:2581 - train/loss:0.5940170884132385 - train/lr(1e-3):0.017821769796284897
step:2582 - train/loss:0.5973118543624878 - train/lr(1e-3):0.017782953209835573
step:2583 - train/loss:0.553708553314209 - train/lr(1e-3):0.01774416979629331
step:2584 - train/loss:0.6479507684707642 - train/lr(1e-3):0.017705419595592194
step:2585 - train/loss:0.589469313621521 - train/lr(1e-3):0.017666702647632128
step:2586 - train/loss:0.6413275003433228 - train/lr(1e-3):0.017628018992278765
step:2587 - train/loss:0.5297446846961975 - train/lr(1e-3):0.017589368669363486
step:2588 - train/loss:0.4694913625717163 - train/lr(1e-3):0.01755075171868334
step:2589 - train/loss:0.5071983933448792 - train/lr(1e-3):0.01751216818000102
step:2590 - train/loss:0.6162083745002747 - train/lr(1e-3):0.0174736180930448
step:2591 - train/loss:0.4664832055568695 - train/lr(1e-3):0.017435101497508584
step:2592 - train/loss:0.5247655510902405 - train/lr(1e-3):0.017396618433051646
step:2593 - train/loss:0.47127294540405273 - train/lr(1e-3):0.01735816893929888
step:2594 - train/loss:0.5622127056121826 - train/lr(1e-3):0.017319753055840555
step:2595 - train/loss:0.6249621510505676 - train/lr(1e-3):0.017281370822232276
step:2596 - train/loss:0.5339362621307373 - train/lr(1e-3):0.017243022277995106
step:2597 - train/loss:0.5267200469970703 - train/lr(1e-3):0.01720470746261535
step:2598 - train/loss:0.5014220476150513 - train/lr(1e-3):0.0171664264155446
step:2599 - train/loss:0.48587673902511597 - train/lr(1e-3):0.01712817917619968
step:2600 - train/loss:0.5248966813087463 - train/lr(1e-3):0.01708996578396261
step:2601 - train/loss:0.49715977907180786 - train/lr(1e-3):0.01705178627818053
step:2602 - train/loss:0.5551915168762207 - train/lr(1e-3):0.017013640698165713
step:2603 - train/loss:0.6325511336326599 - train/lr(1e-3):0.01697552908319553
step:2604 - train/loss:0.4979923367500305 - train/lr(1e-3):0.016937451472512282
step:2605 - train/loss:0.619725227355957 - train/lr(1e-3):0.016899407905323377
step:2606 - train/loss:0.602949857711792 - train/lr(1e-3):0.016861398420801105
step:2607 - train/loss:0.5229356288909912 - train/lr(1e-3):0.016823423058082616
step:2608 - train/loss:0.601080060005188 - train/lr(1e-3):0.01678548185627004
step:2609 - train/loss:0.5841081142425537 - train/lr(1e-3):0.016747574854430243
step:2610 - train/loss:0.6305402517318726 - train/lr(1e-3):0.01670970209159491
step:2611 - train/loss:0.5127418041229248 - train/lr(1e-3):0.016671863606760463
step:2612 - train/loss:0.38592371344566345 - train/lr(1e-3):0.016634059438888033
step:2613 - train/loss:0.47916179895401 - train/lr(1e-3):0.016596289626903415
step:2614 - train/loss:0.5099859237670898 - train/lr(1e-3):0.016558554209697016
step:2615 - train/loss:0.5302383899688721 - train/lr(1e-3):0.01652085322612389
step:2616 - train/loss:0.6107327938079834 - train/lr(1e-3):0.016483186715003522
step:2617 - train/loss:0.4939550757408142 - train/lr(1e-3):0.01644555471511998
step:2618 - train/loss:0.43344128131866455 - train/lr(1e-3):0.01640795726522183
step:2619 - train/loss:0.4871390759944916 - train/lr(1e-3):0.016370394404021944
step:2620 - train/loss:0.5201147794723511 - train/lr(1e-3):0.016332866170197708
step:2621 - train/loss:0.49069398641586304 - train/lr(1e-3):0.016295372602390768
step:2622 - train/loss:0.34826335310935974 - train/lr(1e-3):0.016257913739207114
step:2623 - train/loss:0.5809744596481323 - train/lr(1e-3):0.01622048961921699
step:2624 - train/loss:0.47745105624198914 - train/lr(1e-3):0.01618310028095486
step:2625 - train/loss:0.5973464250564575 - train/lr(1e-3):0.01614574576291939
step:2626 - train/loss:0.6155223250389099 - train/lr(1e-3):0.01610842610357337
step:2627 - train/loss:0.6041120290756226 - train/lr(1e-3):0.01607114134134373
step:2628 - train/loss:0.5176964998245239 - train/lr(1e-3):0.016033891514621434
step:2629 - train/loss:0.5040610432624817 - train/lr(1e-3):0.015996676661761477
step:2630 - train/loss:0.5084205269813538 - train/lr(1e-3):0.015959496821082903
step:2631 - train/loss:0.4857550859451294 - train/lr(1e-3):0.015922352030868593
step:2632 - train/loss:0.5448695421218872 - train/lr(1e-3):0.01588524232936545
step:2633 - train/loss:0.4604566693305969 - train/lr(1e-3):0.015848167754784186
step:2634 - train/loss:0.5176376104354858 - train/lr(1e-3):0.015811128345299318
step:2635 - train/loss:0.5439658761024475 - train/lr(1e-3):0.015774124139049262
step:2636 - train/loss:0.5412958860397339 - train/lr(1e-3):0.01573715517413604
step:2637 - train/loss:0.6386706829071045 - train/lr(1e-3):0.015700221488625522
step:2638 - train/loss:0.48614633083343506 - train/lr(1e-3):0.01566332312054717
step:2639 - train/loss:0.5594518780708313 - train/lr(1e-3):0.01562646010789411
step:2640 - train/loss:0.4452130198478699 - train/lr(1e-3):0.015589632488623053
step:2641 - train/loss:0.5065213441848755 - train/lr(1e-3):0.01555284030065427
step:2642 - train/loss:0.5677241086959839 - train/lr(1e-3):0.01551608358187156
step:2643 - train/loss:0.5851566791534424 - train/lr(1e-3):0.015479362370122169
step:2644 - train/loss:0.5128355026245117 - train/lr(1e-3):0.015442676703216852
step:2645 - train/loss:0.4789271056652069 - train/lr(1e-3):0.015406026618929671
step:2646 - train/loss:0.4547852873802185 - train/lr(1e-3):0.015369412154998097
step:2647 - train/loss:0.5601924657821655 - train/lr(1e-3):0.015332833349122972
step:2648 - train/loss:0.6810513734817505 - train/lr(1e-3):0.015296290238968304
step:2649 - train/loss:0.5452854037284851 - train/lr(1e-3):0.01525978286216147
step:2650 - train/loss:0.4991878271102905 - train/lr(1e-3):0.015223311256292976
step:2651 - train/loss:0.4475875496864319 - train/lr(1e-3):0.015186875458916522
step:2652 - train/loss:0.5447182655334473 - train/lr(1e-3):0.015150475507548933
step:2653 - train/loss:0.45496076345443726 - train/lr(1e-3):0.015114111439670121
step:2654 - train/loss:0.580259382724762 - train/lr(1e-3):0.015077783292723058
step:2655 - train/loss:0.4577546715736389 - train/lr(1e-3):0.015041491104113725
step:2656 - train/loss:0.46503397822380066 - train/lr(1e-3):0.01500523491121108
step:2657 - train/loss:0.49541738629341125 - train/lr(1e-3):0.01496901475134701
step:2658 - train/loss:0.5299023389816284 - train/lr(1e-3):0.014932830661816294
step:2659 - train/loss:0.5726610422134399 - train/lr(1e-3):0.014896682679876623
step:2660 - train/loss:0.5205549001693726 - train/lr(1e-3):0.014860570842748411
step:2661 - train/loss:0.49848175048828125 - train/lr(1e-3):0.014824495187614951
step:2662 - train/loss:0.5262198448181152 - train/lr(1e-3):0.01478845575162225
step:2663 - train/loss:0.5238619446754456 - train/lr(1e-3):0.01475245257187896
step:2664 - train/loss:0.5255917906761169 - train/lr(1e-3):0.014716485685456498
step:2665 - train/loss:0.4699133038520813 - train/lr(1e-3):0.014680555129388857
step:2666 - train/loss:0.433519184589386 - train/lr(1e-3):0.014644660940672627
step:2667 - train/loss:0.5598627328872681 - train/lr(1e-3):0.014608803156266958
step:2668 - train/loss:0.5323622822761536 - train/lr(1e-3):0.014572981813093506
step:2669 - train/loss:0.4310953617095947 - train/lr(1e-3):0.014537196948036424
step:2670 - train/loss:0.47904932498931885 - train/lr(1e-3):0.014501448597942264
step:2671 - train/loss:0.5228656530380249 - train/lr(1e-3):0.014465736799620066
step:2672 - train/loss:0.581310510635376 - train/lr(1e-3):0.014430061589841121
step:2673 - train/loss:0.5343761444091797 - train/lr(1e-3):0.014394423005339097
step:2674 - train/loss:0.46571075916290283 - train/lr(1e-3):0.014358821082810015
step:2675 - train/loss:0.6546289920806885 - train/lr(1e-3):0.014323255858912011
step:2676 - train/loss:0.5273536443710327 - train/lr(1e-3):0.014287727370265558
step:2677 - train/loss:0.4741423428058624 - train/lr(1e-3):0.014252235653453238
step:2678 - train/loss:0.4992981553077698 - train/lr(1e-3):0.014216780745019787
step:2679 - train/loss:0.5006827116012573 - train/lr(1e-3):0.014181362681472031
step:2680 - train/loss:0.5156667828559875 - train/lr(1e-3):0.014145981499278875
step:2681 - train/loss:0.5510075092315674 - train/lr(1e-3):0.014110637234871238
step:2682 - train/loss:0.5288084745407104 - train/lr(1e-3):0.014075329924642027
step:2683 - train/loss:0.5245842337608337 - train/lr(1e-3):0.014040059604946099
step:2684 - train/loss:0.6500714421272278 - train/lr(1e-3):0.014004826312100215
step:2685 - train/loss:0.597769558429718 - train/lr(1e-3):0.013969630082383012
step:2686 - train/loss:0.6588257551193237 - train/lr(1e-3):0.013934470952035018
step:2687 - train/loss:0.5853530168533325 - train/lr(1e-3):0.013899348957258447
step:2688 - train/loss:0.5092543959617615 - train/lr(1e-3):0.01386426413421738
step:2689 - train/loss:0.5235253572463989 - train/lr(1e-3):0.013829216519037603
step:2690 - train/loss:0.5810537338256836 - train/lr(1e-3):0.013794206147806522
step:2691 - train/loss:0.5637206435203552 - train/lr(1e-3):0.013759233056573278
step:2692 - train/loss:0.6133814454078674 - train/lr(1e-3):0.013724297281348592
step:2693 - train/loss:0.5180187225341797 - train/lr(1e-3):0.01368939885810475
step:2694 - train/loss:0.4026939868927002 - train/lr(1e-3):0.013654537822775602
step:2695 - train/loss:0.4629632234573364 - train/lr(1e-3):0.01361971421125649
step:2696 - train/loss:0.6064959764480591 - train/lr(1e-3):0.013584928059404205
step:2697 - train/loss:0.5188314914703369 - train/lr(1e-3):0.01355017940303699
step:2698 - train/loss:0.5002155303955078 - train/lr(1e-3):0.013515468277934496
step:2699 - train/loss:0.6264148950576782 - train/lr(1e-3):0.013480794719837659
step:2700 - train/loss:0.5460157990455627 - train/lr(1e-3):0.01344615876444884
step:2701 - train/loss:0.5582082271575928 - train/lr(1e-3):0.013411560447431576
step:2702 - train/loss:0.5262607932090759 - train/lr(1e-3):0.01337699980441069
step:2703 - train/loss:0.6114447116851807 - train/lr(1e-3):0.01334247687097227
step:2704 - train/loss:0.5383228063583374 - train/lr(1e-3):0.013307991682663462
step:2705 - train/loss:0.5367328524589539 - train/lr(1e-3):0.013273544274992655
step:2706 - train/loss:0.62583327293396 - train/lr(1e-3):0.013239134683429271
step:2707 - train/loss:0.4974469542503357 - train/lr(1e-3):0.01320476294340382
step:2708 - train/loss:0.5147156715393066 - train/lr(1e-3):0.013170429090307823
step:2709 - train/loss:0.4410895109176636 - train/lr(1e-3):0.013136133159493801
step:2710 - train/loss:0.5942833423614502 - train/lr(1e-3):0.01310187518627523
step:2711 - train/loss:0.5710710883140564 - train/lr(1e-3):0.013067655205926489
step:2712 - train/loss:0.41952401399612427 - train/lr(1e-3):0.013033473253682848
step:2713 - train/loss:0.5466799736022949 - train/lr(1e-3):0.012999329364740414
step:2714 - train/loss:0.4375237822532654 - train/lr(1e-3):0.01296522357425609
step:2715 - train/loss:0.549623429775238 - train/lr(1e-3):0.01293115591734762
step:2716 - train/loss:0.4799356460571289 - train/lr(1e-3):0.012897126429093355
step:2717 - train/loss:0.5400034189224243 - train/lr(1e-3):0.012863135144532462
step:2718 - train/loss:0.5501254796981812 - train/lr(1e-3):0.012829182098664732
step:2719 - train/loss:0.4890880584716797 - train/lr(1e-3):0.012795267326450532
step:2720 - train/loss:0.5791734457015991 - train/lr(1e-3):0.012761390862810907
step:2721 - train/loss:0.6008785963058472 - train/lr(1e-3):0.012727552742627407
step:2722 - train/loss:0.4349237382411957 - train/lr(1e-3):0.012693753000742098
step:2723 - train/loss:0.5110942721366882 - train/lr(1e-3):0.012659991671957551
step:2724 - train/loss:0.4425385296344757 - train/lr(1e-3):0.012626268791036767
step:2725 - train/loss:0.5645945072174072 - train/lr(1e-3):0.01259258439270316
step:2726 - train/loss:0.5352075695991516 - train/lr(1e-3):0.012558938511640512
step:2727 - train/loss:0.5116744041442871 - train/lr(1e-3):0.012525331182493011
step:2728 - train/loss:0.45215845108032227 - train/lr(1e-3):0.012491762439865035
step:2729 - train/loss:0.5393608808517456 - train/lr(1e-3):0.012458232318321305
step:2730 - train/loss:0.6238245964050293 - train/lr(1e-3):0.012424740852386797
step:2731 - train/loss:0.5330756902694702 - train/lr(1e-3):0.012391288076546592
step:2732 - train/loss:0.4838868975639343 - train/lr(1e-3):0.01235787402524603
step:2733 - train/loss:0.5223118662834167 - train/lr(1e-3):0.012324498732890533
step:2734 - train/loss:0.49593043327331543 - train/lr(1e-3):0.012291162233845604
step:2735 - train/loss:0.4379195272922516 - train/lr(1e-3):0.012257864562436821
step:2736 - train/loss:0.44371336698532104 - train/lr(1e-3):0.012224605752949785
step:2737 - train/loss:0.45036613941192627 - train/lr(1e-3):0.012191385839630064
step:2738 - train/loss:0.6578531265258789 - train/lr(1e-3):0.012158204856683176
step:2739 - train/loss:0.557754397392273 - train/lr(1e-3):0.012125062838274608
step:2740 - train/loss:0.4900219440460205 - train/lr(1e-3):0.012091959818529636
step:2741 - train/loss:0.4622916579246521 - train/lr(1e-3):0.012058895831533429
step:2742 - train/loss:0.46114957332611084 - train/lr(1e-3):0.012025870911331001
step:2743 - train/loss:0.6546485424041748 - train/lr(1e-3):0.011992885091927048
step:2744 - train/loss:0.491385281085968 - train/lr(1e-3):0.011959938407286097
step:2745 - train/loss:0.5056933760643005 - train/lr(1e-3):0.011927030891332336
step:2746 - train/loss:0.4899778366088867 - train/lr(1e-3):0.011894162577949619
step:2747 - train/loss:0.5860176682472229 - train/lr(1e-3):0.011861333500981447
step:2748 - train/loss:0.5731300115585327 - train/lr(1e-3):0.01182854369423091
step:2749 - train/loss:0.4268799424171448 - train/lr(1e-3):0.011795793191460674
step:2750 - train/loss:0.47212839126586914 - train/lr(1e-3):0.01176308202639293
step:2751 - train/loss:0.477388858795166 - train/lr(1e-3):0.011730410232709354
step:2752 - train/loss:0.5476279258728027 - train/lr(1e-3):0.011697777844051106
step:2753 - train/loss:0.5234984755516052 - train/lr(1e-3):0.011665184894018733
step:2754 - train/loss:0.5030966401100159 - train/lr(1e-3):0.011632631416172247
step:2755 - train/loss:0.5156350135803223 - train/lr(1e-3):0.0116001174440309
step:2756 - train/loss:0.5332112312316895 - train/lr(1e-3):0.011567643011073393
step:2757 - train/loss:0.6059800386428833 - train/lr(1e-3):0.011535208150737648
step:2758 - train/loss:0.44004425406455994 - train/lr(1e-3):0.0115028128964208
step:2759 - train/loss:0.4647845923900604 - train/lr(1e-3):0.011470457281479302
step:2760 - train/loss:0.5537747740745544 - train/lr(1e-3):0.01143814133922872
step:2761 - train/loss:0.5415807366371155 - train/lr(1e-3):0.011405865102943797
step:2762 - train/loss:0.4659259617328644 - train/lr(1e-3):0.011373628605858378
step:2763 - train/loss:0.4581851363182068 - train/lr(1e-3):0.011341431881165405
step:2764 - train/loss:0.5983163714408875 - train/lr(1e-3):0.011309274962016853
step:2765 - train/loss:0.4974271059036255 - train/lr(1e-3):0.011277157881523722
step:2766 - train/loss:0.4442271590232849 - train/lr(1e-3):0.011245080672755987
step:2767 - train/loss:0.5288551449775696 - train/lr(1e-3):0.011213043368742565
step:2768 - train/loss:0.4682329297065735 - train/lr(1e-3):0.01118104600247129
step:2769 - train/loss:0.6340603828430176 - train/lr(1e-3):0.011149088606888874
step:2770 - train/loss:0.5344691872596741 - train/lr(1e-3):0.011117171214900851
step:2771 - train/loss:0.613770604133606 - train/lr(1e-3):0.01108529385937162
step:2772 - train/loss:0.517291784286499 - train/lr(1e-3):0.01105345657312427
step:2773 - train/loss:0.6056743264198303 - train/lr(1e-3):0.011021659388940718
step:2774 - train/loss:0.5654703974723816 - train/lr(1e-3):0.010989902339561554
step:2775 - train/loss:0.6061995029449463 - train/lr(1e-3):0.010958185457685997
step:2776 - train/loss:0.49107441306114197 - train/lr(1e-3):0.010926508775971993
step:2777 - train/loss:0.48983991146087646 - train/lr(1e-3):0.010894872327036032
step:2778 - train/loss:0.5659415125846863 - train/lr(1e-3):0.010863276143453204
step:2779 - train/loss:0.5290318131446838 - train/lr(1e-3):0.010831720257757128
step:2780 - train/loss:0.5205099582672119 - train/lr(1e-3):0.010800204702439937
step:2781 - train/loss:0.47421178221702576 - train/lr(1e-3):0.010768729509952231
step:2782 - train/loss:0.42723238468170166 - train/lr(1e-3):0.010737294712703039
step:2783 - train/loss:0.6112964749336243 - train/lr(1e-3):0.010705900343059856
step:2784 - train/loss:0.43801701068878174 - train/lr(1e-3):0.010674546433348454
step:2785 - train/loss:0.571967601776123 - train/lr(1e-3):0.010643233015852994
step:2786 - train/loss:0.5379600524902344 - train/lr(1e-3):0.010611960122815994
step:2787 - train/loss:0.4563392400741577 - train/lr(1e-3):0.010580727786438131
step:2788 - train/loss:0.4489901065826416 - train/lr(1e-3):0.010549536038878432
step:2789 - train/loss:0.4309985935688019 - train/lr(1e-3):0.010518384912254077
step:2790 - train/loss:0.519324004650116 - train/lr(1e-3):0.01048727443864041
step:2791 - train/loss:0.5716702938079834 - train/lr(1e-3):0.01045620465007095
step:2792 - train/loss:0.5152356624603271 - train/lr(1e-3):0.0104251755785373
step:2793 - train/loss:0.5062762498855591 - train/lr(1e-3):0.010394187255989146
step:2794 - train/loss:0.5815126895904541 - train/lr(1e-3):0.010363239714334206
step:2795 - train/loss:0.5040374994277954 - train/lr(1e-3):0.010332332985438248
step:2796 - train/loss:0.5847479104995728 - train/lr(1e-3):0.010301467101124957
step:2797 - train/loss:0.520164430141449 - train/lr(1e-3):0.010270642093175976
step:2798 - train/loss:0.48956966400146484 - train/lr(1e-3):0.01023985799333092
step:2799 - train/loss:0.515973687171936 - train/lr(1e-3):0.010209114833287182
step:2800 - train/loss:0.5358970165252686 - train/lr(1e-3):0.010178412644700091
step:2801 - train/loss:0.5129349231719971 - train/lr(1e-3):0.010147751459182737
step:2802 - train/loss:0.4613999128341675 - train/lr(1e-3):0.010117131308306005
step:2803 - train/loss:0.4677979648113251 - train/lr(1e-3):0.010086552223598527
step:2804 - train/loss:0.5976399183273315 - train/lr(1e-3):0.010056014236546645
step:2805 - train/loss:0.5384429097175598 - train/lr(1e-3):0.0100255173785944
step:2806 - train/loss:0.4746621251106262 - train/lr(1e-3):0.00999506168114347
step:2807 - train/loss:0.4819439649581909 - train/lr(1e-3):0.009964647175553155
step:2808 - train/loss:0.5589661598205566 - train/lr(1e-3):0.009934273893140335
step:2809 - train/loss:0.5596767663955688 - train/lr(1e-3):0.00990394186517944
step:2810 - train/loss:0.5463095307350159 - train/lr(1e-3):0.009873651122902472
step:2811 - train/loss:0.5558755993843079 - train/lr(1e-3):0.009843401697498822
step:2812 - train/loss:0.5433458089828491 - train/lr(1e-3):0.009813193620115446
step:2813 - train/loss:0.5945246815681458 - train/lr(1e-3):0.00978302692185667
step:2814 - train/loss:0.46487122774124146 - train/lr(1e-3):0.009752901633784184
step:2815 - train/loss:0.5448787808418274 - train/lr(1e-3):0.009722817786917116
step:2816 - train/loss:0.5371066331863403 - train/lr(1e-3):0.009692775412231864
step:2817 - train/loss:0.5346165299415588 - train/lr(1e-3):0.009662774540662146
step:2818 - train/loss:0.5690822601318359 - train/lr(1e-3):0.00963281520309894
step:2819 - train/loss:0.4829806685447693 - train/lr(1e-3):0.009602897430390457
step:2820 - train/loss:0.5090651512145996 - train/lr(1e-3):0.009573021253342112
step:2821 - train/loss:0.5487749576568604 - train/lr(1e-3):0.00954318670271648
step:2822 - train/loss:0.6040225028991699 - train/lr(1e-3):0.009513393809233323
step:2823 - train/loss:0.5051823854446411 - train/lr(1e-3):0.009483642603569433
step:2824 - train/loss:0.3880745470523834 - train/lr(1e-3):0.009453933116358715
step:2825 - train/loss:0.4624905586242676 - train/lr(1e-3):0.009424265378192154
step:2826 - train/loss:0.47019800543785095 - train/lr(1e-3):0.009394639419617667
step:2827 - train/loss:0.6630412340164185 - train/lr(1e-3):0.009365055271140234
step:2828 - train/loss:0.5604584813117981 - train/lr(1e-3):0.009335512963221732
step:2829 - train/loss:0.5510154962539673 - train/lr(1e-3):0.009306012526280973
step:2830 - train/loss:0.5471503734588623 - train/lr(1e-3):0.009276553990693666
step:2831 - train/loss:0.4887893497943878 - train/lr(1e-3):0.009247137386792321
step:2832 - train/loss:0.6592434644699097 - train/lr(1e-3):0.00921776274486636
step:2833 - train/loss:0.572368323802948 - train/lr(1e-3):0.009188430095161931
step:2834 - train/loss:0.38396722078323364 - train/lr(1e-3):0.009159139467881978
step:2835 - train/loss:0.537312924861908 - train/lr(1e-3):0.009129890893186155
step:2836 - train/loss:0.5398495197296143 - train/lr(1e-3):0.009100684401190828
step:2837 - train/loss:0.5205976366996765 - train/lr(1e-3):0.009071520021969027
step:2838 - train/loss:0.5372089147567749 - train/lr(1e-3):0.009042397785550405
step:2839 - train/loss:0.49963170289993286 - train/lr(1e-3):0.009013317721921281
step:2840 - train/loss:0.5197920799255371 - train/lr(1e-3):0.008984279861024453
step:2841 - train/loss:0.5618047118186951 - train/lr(1e-3):0.008955284232759347
step:2842 - train/loss:0.5470512509346008 - train/lr(1e-3):0.00892633086698189
step:2843 - train/loss:0.4619354009628296 - train/lr(1e-3):0.00889741979350443
step:2844 - train/loss:0.6668928265571594 - train/lr(1e-3):0.008868551042095852
step:2845 - train/loss:0.49781501293182373 - train/lr(1e-3):0.008839724642481417
step:2846 - train/loss:0.542834997177124 - train/lr(1e-3):0.008810940624342786
step:2847 - train/loss:0.5763256549835205 - train/lr(1e-3):0.008782199017317971
step:2848 - train/loss:0.4492286443710327 - train/lr(1e-3):0.00875349985100134
step:2849 - train/loss:0.48678600788116455 - train/lr(1e-3):0.00872484315494354
step:2850 - train/loss:0.6174200773239136 - train/lr(1e-3):0.008696228958651481
step:2851 - train/loss:0.5339753031730652 - train/lr(1e-3):0.00866765729158836
step:2852 - train/loss:0.6774638891220093 - train/lr(1e-3):0.008639128183173517
step:2853 - train/loss:0.4431794285774231 - train/lr(1e-3):0.008610641662782493
step:2854 - train/loss:0.5485403537750244 - train/lr(1e-3):0.008582197759747034
step:2855 - train/loss:0.4719511866569519 - train/lr(1e-3):0.008553796503354898
step:2856 - train/loss:0.6289052963256836 - train/lr(1e-3):0.008525437922850033
step:2857 - train/loss:0.5879506468772888 - train/lr(1e-3):0.008497122047432387
step:2858 - train/loss:0.5599916577339172 - train/lr(1e-3):0.008468848906257946
step:2859 - train/loss:0.48947814106941223 - train/lr(1e-3):0.008440618528438703
step:2860 - train/loss:0.6279920935630798 - train/lr(1e-3):0.008412430943042615
step:2861 - train/loss:0.5296819806098938 - train/lr(1e-3):0.008384286179093576
step:2862 - train/loss:0.49974825978279114 - train/lr(1e-3):0.008356184265571382
step:2863 - train/loss:0.42832159996032715 - train/lr(1e-3):0.008328125231411717
step:2864 - train/loss:0.588462233543396 - train/lr(1e-3):0.00830010910550611
step:2865 - train/loss:0.5008431673049927 - train/lr(1e-3):0.008272135916701897
step:2866 - train/loss:0.4603422284126282 - train/lr(1e-3):0.008244205693802248
step:2867 - train/loss:0.5817180275917053 - train/lr(1e-3):0.008216318465566013
step:2868 - train/loss:0.6558930277824402 - train/lr(1e-3):0.008188474260707857
step:2869 - train/loss:0.49456462264060974 - train/lr(1e-3):0.008160673107898092
step:2870 - train/loss:0.4750131666660309 - train/lr(1e-3):0.008132915035762696
step:2871 - train/loss:0.5205963850021362 - train/lr(1e-3):0.00810520007288333
step:2872 - train/loss:0.43478116393089294 - train/lr(1e-3):0.008077528247797235
step:2873 - train/loss:0.5639140009880066 - train/lr(1e-3):0.008049899588997244
step:2874 - train/loss:0.5709764361381531 - train/lr(1e-3):0.008022314124931734
step:2875 - train/loss:0.5390689969062805 - train/lr(1e-3):0.007994771884004626
step:2876 - train/loss:0.46303871273994446 - train/lr(1e-3):0.007967272894575312
step:2877 - train/loss:0.5495994091033936 - train/lr(1e-3):0.007939817184958653
step:2878 - train/loss:0.43269452452659607 - train/lr(1e-3):0.00791240478342498
step:2879 - train/loss:0.4842110872268677 - train/lr(1e-3):0.007885035718199984
step:2880 - train/loss:0.5807225108146667 - train/lr(1e-3):0.007857710017464737
step:2881 - train/loss:0.6226221323013306 - train/lr(1e-3):0.007830427709355724
step:2882 - train/loss:0.512715220451355 - train/lr(1e-3):0.007803188821964652
step:2883 - train/loss:0.38711017370224 - train/lr(1e-3):0.007775993383338603
step:2884 - train/loss:0.5613933801651001 - train/lr(1e-3):0.007748841421479875
step:2885 - train/loss:0.4004092216491699 - train/lr(1e-3):0.007721732964346018
step:2886 - train/loss:0.5794481635093689 - train/lr(1e-3):0.007694668039849778
step:2887 - train/loss:0.5455498099327087 - train/lr(1e-3):0.007667646675859075
step:2888 - train/loss:0.5591942667961121 - train/lr(1e-3):0.007640668900196984
step:2889 - train/loss:0.5597125291824341 - train/lr(1e-3):0.0076137347406416865
step:2890 - train/loss:0.3742336332798004 - train/lr(1e-3):0.007586844224926493
step:2891 - train/loss:0.6091553568840027 - train/lr(1e-3):0.007559997380739714
step:2892 - train/loss:0.6035669445991516 - train/lr(1e-3):0.007533194235724728
step:2893 - train/loss:0.36676478385925293 - train/lr(1e-3):0.007506434817479918
step:2894 - train/loss:0.5878186225891113 - train/lr(1e-3):0.007479719153558623
step:2895 - train/loss:0.5549244284629822 - train/lr(1e-3):0.007453047271469182
step:2896 - train/loss:0.5268447399139404 - train/lr(1e-3):0.007426419198674772
step:2897 - train/loss:0.5295531153678894 - train/lr(1e-3):0.007399834962593533
step:2898 - train/loss:0.5494286417961121 - train/lr(1e-3):0.007373294590598445
step:2899 - train/loss:0.6117004156112671 - train/lr(1e-3):0.007346798110017277
step:2900 - train/loss:0.5376558303833008 - train/lr(1e-3):0.007320345548132679
step:2901 - train/loss:0.6018951535224915 - train/lr(1e-3):0.007293936932182039
step:2902 - train/loss:0.4833142161369324 - train/lr(1e-3):0.007267572289357494
step:2903 - train/loss:0.4814661741256714 - train/lr(1e-3):0.007241251646805913
step:2904 - train/loss:0.5309625267982483 - train/lr(1e-3):0.007214975031628857
step:2905 - train/loss:0.46895158290863037 - train/lr(1e-3):0.007188742470882554
step:2906 - train/loss:0.5347729921340942 - train/lr(1e-3):0.007162553991577847
step:2907 - train/loss:0.4233214855194092 - train/lr(1e-3):0.007136409620680257
step:2908 - train/loss:0.6112077236175537 - train/lr(1e-3):0.007110309385109803
step:2909 - train/loss:0.5633777379989624 - train/lr(1e-3):0.007084253311741101
step:2910 - train/loss:0.5641565322875977 - train/lr(1e-3):0.007058241427403329
step:2911 - train/loss:0.4696604907512665 - train/lr(1e-3):0.007032273758880076
step:2912 - train/loss:0.5747835040092468 - train/lr(1e-3):0.007006350332909495
step:2913 - train/loss:0.6006063222885132 - train/lr(1e-3):0.0069804711761841335
step:2914 - train/loss:0.5736658573150635 - train/lr(1e-3):0.00695463631535096
step:2915 - train/loss:0.7119109034538269 - train/lr(1e-3):0.0069288457770113505
step:2916 - train/loss:0.5554858446121216 - train/lr(1e-3):0.006903099587721024
step:2917 - train/loss:0.5407098531723022 - train/lr(1e-3):0.006877397773990041
step:2918 - train/loss:0.5563395619392395 - train/lr(1e-3):0.006851740362282788
step:2919 - train/loss:0.5697019696235657 - train/lr(1e-3):0.0068261273790179
